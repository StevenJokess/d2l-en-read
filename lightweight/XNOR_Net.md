

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-08 20:19:13
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-10-08 20:24:43
 * @Description:
 * @TODO::
 * @Reference:[1]: https://weread.qq.com/web/reader/86432480718ff649864dc83k3de32dd027d3def184ad06e
 * [2]: https://weread.qq.com/web/reader/86432480718ff649864dc83kec532f2027fec5decca5182
-->

如果能把浮点数乘法变为浮点数加减法，甚至是逻辑运算，就能大大提高运算速度、降低功耗。

二值化网络（XNOR Net）是一种量化技术，通过把权重和激活量化为{+1,-1}，减小了存储空间（原来的1/15）、提高了运算速度（原来的10倍）和减小了功耗（原来的1/30）。

## 权重二值化


由于权重为{+1, -1}，矩阵乘法ai=hi-1wbi变为浮点数加减法，能降低功耗和提高速度。

训练网络时，先计算权重的梯度，然后进行权重更新，而为了使训练过程稳定收敛，权重每次的更新量很小。这样一来，如果训练过程中权重只取+1或-1，由于更新量很小，很难使权重从+1改变为-1，权重值在训练过程中几乎不会发生变化，不能进行学习。为此，在训练过程中需要引入浮点数权重，利用浮点数权重进行更新。二值化权重是对浮点数权重进行二值化得到的，最简单也最常用的二值化函数是符号函数sign，即浮点数权重 wr大于等于0时，二值化权重wb为+1，否则为-1。

需要计算符号函数的偏导数，由于符号函数的偏导数几乎处处为0，导致损失c对权重wr的梯度也几乎处处为0，因此权重wr难以更新。为了解决此问题，引入直通估计（Straight-ThroughEstimator, STE）

仅对权重进行二值化，矩阵乘法变为浮点数加减法，虽然理论上存储量能获得32倍的提升，但提速效果十分有限，不到2倍。

## XNOR网络[2]

假设2个二值化向量为v1=[+1, -1, +1, +1]和v2=[-1, -1, +1, -1]，则点积为(+1)×(-1)+(-1) ×(-1)+(+1)×(+1)+(+1)×(-1)=(-1)+(+1)+(+1)+(-1)=2×num(+1)-length(v1)=0。+1和-1之间的乘法和XNOR一致，同号为+1，异号为-1。

XNOR网络在训练过程和权重二值化网络一样，只是非线性激活函数被符号函数取代，利用公式(13.5)进行激活梯度的传递。

## 权重尺度化

假设浮点数权重向量为wr，对应的二值化向量为wb=sign(wr)，尺度因子为α（1个正浮点数），输入向量为xr，则量化后的点积[插图]要和原始点积[插图]尽量接近，即要求向量差pr-pb的L2范数最小，通过不太复杂的数学运算，得最优α：假设浮点数权重向量为wr，对应的二值化向量为wb=sign(wr)，尺度因子为α（1个正浮点数），输入向量为xr，则量化后的点积[插图]要和原始点积[插图]尽量接近，即要求向量差pr-pb的L2范数最小，通过不太复杂的数学运算，得最优α：

为了进一步提高性能，对激活进行二值化时可以引入尺度因子。这个技巧对性能提升比较小，但引入的运算量和临时存储空间比较大
