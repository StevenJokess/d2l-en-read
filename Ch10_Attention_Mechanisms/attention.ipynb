{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8eee0L1O4ek",
        "outputId": "ded8de45-525c-447d-e4c8-bddbca3074a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U git+https://github.com/d2l-ai/d2l-en.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/d2l-ai/d2l-en.git@master\n",
            "  Cloning https://github.com/d2l-ai/d2l-en.git (to revision master) to /tmp/pip-req-build-g32xovoe\n",
            "  Running command git clone -q https://github.com/d2l-ai/d2l-en.git /tmp/pip-req-build-g32xovoe\n",
            "Requirement already satisfied, skipping upgrade: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (7.5.1)\n",
            "Requirement already satisfied, skipping upgrade: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (4.7.7)\n",
            "Requirement already satisfied, skipping upgrade: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (4.10.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (5.2.0)\n",
            "Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (5.6.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.15.1) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (0.9.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (5.0.8)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.15.1) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.15.1) (3.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (19.0.2)\n",
            "Requirement already satisfied, skipping upgrade: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.15.1) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (1.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->d2l==0.15.1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.15.1) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->jupyter->d2l==0.15.1) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->d2l==0.15.1) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->d2l==0.15.1) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.15.1) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.15.1) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.15.1) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.15.1) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.15.1) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.1) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.1) (0.5.1)\n",
            "Building wheels for collected packages: d2l\n",
            "  Building wheel for d2l (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for d2l: filename=d2l-0.15.1-cp36-none-any.whl size=63507 sha256=2278423ef13dc83aba84c88058bff8bcb60a6e793cc16c0439caa7bb8db56bd0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qdusrjfa/wheels/0f/41/8f/72ece70ede8a0e37eec72c03087eb4604925ba212b804f8cad\n",
            "Successfully built d2l\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT_fkhfyOp59"
      },
      "source": [
        "from d2l import torch as d2l\n",
        "import math\n",
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpVM1oMUOsIj"
      },
      "source": [
        "#@save\n",
        "def masked_softmax(X, valid_len):\n",
        "    \"\"\"Perform softmax by filtering out some elements.\"\"\"\n",
        "    # X: 3-D tensor, valid_len: 1-D or 2-D tensor\n",
        "    if valid_len is None:\n",
        "        return nn.functional.softmax(X, dim=-1)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_len.dim() == 1:\n",
        "            valid_len = torch.repeat_interleave(valid_len, repeats=shape[1],\n",
        "                                                dim=0)\n",
        "        else:\n",
        "            valid_len = valid_len.reshape(-1)\n",
        "        # Fill masked elements with a large negative, whose exp is 0\n",
        "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_len, value=-1e6)\n",
        "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg4bcKXROtuy",
        "outputId": "f2dfbb78-c9c4-4d0e-e709-1d046db0b73a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.6182, 0.3818, 0.0000, 0.0000],\n",
              "         [0.4314, 0.5686, 0.0000, 0.0000]],\n",
              "\n",
              "        [[0.3172, 0.4922, 0.1906, 0.0000],\n",
              "         [0.2735, 0.4507, 0.2758, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfBa_1CFOvMQ",
        "outputId": "a7b20001-4376-4eff-9456-9a133f74d4c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.bmm(torch.ones(2,1,3), torch.ones(2,3,2))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[3., 3.]],\n",
              "\n",
              "        [[3., 3.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfTrdkLMOweL"
      },
      "source": [
        "#@save\n",
        "class DotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # `query`: (`batch_size`, #queries, `d`)\n",
        "    # `key`: (`batch_size`, #kv_pairs, `d`)\n",
        "    # `value`: (`batch_size`, #kv_pairs, `dim_v`)\n",
        "    # `valid_len`: either (`batch_size`, ) or (`batch_size`, xx)\n",
        "    def forward(self, query, key, value, valid_len=None):\n",
        "        d = query.shape[-1]\n",
        "        # Set transpose_b=True to swap the last two dimensions of key\n",
        "        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
        "        return torch.bmm(attention_weights, value)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8AiLZ51Oxxf",
        "outputId": "71ee7c0e-e11a-4b4e-81f1-49cac656cf9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "atten = DotProductAttention(dropout=0.5)\n",
        "atten.eval()\n",
        "keys = torch.ones(2,10,2)\n",
        "values = torch.arange(40, dtype=torch.float32).reshape(1,10,4).repeat(2,1,1)\n",
        "atten(torch.ones(2,1,2), keys, values, torch.tensor([2, 6]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
              "\n",
              "        [[10.0000, 11.0000, 12.0000, 13.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5sXqkEiOzU3"
      },
      "source": [
        "#@save\n",
        "class MLPAttention(nn.Module):\n",
        "    def __init__(self, key_size, query_size, units, dropout, **kwargs):\n",
        "        super(MLPAttention, self).__init__(**kwargs)\n",
        "        self.W_k = nn.Linear(key_size, units, bias=False)\n",
        "        self.W_q = nn.Linear(query_size, units, bias=False)\n",
        "        self.v = nn.Linear(units, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, valid_len):\n",
        "        query, key = self.W_q(query), self.W_k(key)\n",
        "        # Expand query to (`batch_size`, #queries, 1, units), and key to\n",
        "        # (`batch_size`, 1, #kv_pairs, units). Then plus them with broadcast\n",
        "        features = query.unsqueeze(2) + key.unsqueeze(1)\n",
        "        features = torch.tanh(features)\n",
        "        scores = self.v(features).squeeze(-1)\n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
        "        return torch.bmm(attention_weights, value)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18P8dA_rO04-",
        "outputId": "4469adc8-4a5b-4d03-c9ce-137317af4243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "atten = MLPAttention(key_size=2, query_size=2, units=8, dropout=0.1)\n",
        "atten.eval()\n",
        "atten(torch.ones(2, 1, 2), keys, values, torch.tensor([2, 6]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
              "\n",
              "        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}