

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-31 18:33:05
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-31 18:37:44
 * @Description:MT
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_computational-performance/auto-parallelism.html
-->

# 自动并行性

MXNet 在后端自动构造计算图。使用计算图形，系统知道所有的依赖，并可以有选择地执行多个非相互依赖的任务并行，以提高速度。例如，12.2节中的图12.2.2独立地初始化了两个变量。因此，系统可以选择并行执行它们。

通常，单个运算符将使用所有 cpu 或单个 GPU 上的所有计算资源。例如，点操作符将在所有 CPU 上使用所有核(和线程) ，即使在一台机器上有多个 CPU 处理器。同样的道理也适用于单一的 GPU。因此，并行化在单设备计算机上并不是那么有用。有了多种设备，事情就更重要了。虽然并行通常在多个 gpu 之间最为相关，但添加本地 CPU 将略微提高性能。参见，[ Hadjis et al. ，2016]关于结合 GPU 和 CPU 训练计算机视觉模型的论文。有了自动并行化框架的便利，我们可以在几行 Python 代码中完成相同的目标。更广泛地说，我们对自动并行计算的讨论集中在使用 cpu 和 gpu 的并行计算，以及计算和通信的并行化。我们首先导入所需的包和模块。请注意，我们至少需要一个 GPU 来运行本节中的实验。

TODO:CODE

## 基于 cpu 和 gpu 的并行计算

让我们首先定义一个参考工作负载来测试-下面的 run 函数在我们选择的设备上执行10个矩阵乘法，使用分配给两个变量的数据，x _ cpu 和 x _ gpu。

TODO:CODE

现在我们将函数应用于数据。为了确保缓存不会在结果中发挥作用，我们在测量之前对每个设备执行一次预热。

TODO:CODE

如果我们在两个任务之间移除 waitall () ，系统就可以自由地在两个设备上自动并行计算。

TODO:CODE

在上述情况下，总的执行时间小于其部分的总和，因为 MXNet 自动调度 CPU 和 GPU 设备上的计算，而不需要代表用户的复杂代码。

## 并行计算与通信

在许多情况下，我们需要在不同的设备之间移动数据，比如在 CPU 和 GPU 之间，或者在不同的 GPU 之间。例如，当我们想要执行分布式优化，需要在多个加速卡上聚合梯度时，就会发生这种情况。让我们通过在 GPU 上进行计算，然后将结果复制回 CPU 来进行模拟。

TODO:CODE

这有点低效。注意，我们可能已经开始将y的一部分复制到CPU，而列表的其余部分仍在计算中。这种情况会发生，例如，当我们计算一个小批的(backprop)梯度。有些参数的梯度将比其他参数的梯度更早提供。因此，它的工作，我们的优势开始使用PCI-Express总线带宽，而GPU仍在运行。在两个部分之间删除waitall允许我们模拟这个场景。

TODO:CODE

两项操作所需的总时间（如预期的那样）显着少于其各个部分的总和。请注意，此任务与并行计算不同，因为它使用不同的资源：CPU和GPU之间的总线。实际上，我们可以同时在两个设备上进行计算并进行通信。如上所述，计算和通信之间存在依赖关系：必须先计算y [i]，然后才能将其复制到CPU。幸运的是，系统可以在计算y [i]的同时复制y [i-1]以减少总运行时间。

我们以一个简单的两层MLP在CPU和两个GPU上进行训练时的计算图及其依赖性为例进行说明，如图12.3.1所示。手动调度由此产生的并行程序将是非常痛苦的。这是具有基于图形的计算后端进行优化的优势。

图12.3.1一个CPU和两个GPU上的两层MLP

## 小结

* 现代系统有各种各样的设备，比如多个gpu和cpu。它们可以并行、异步地使用。
* 现代系统也有各种各样的通信资源，如PCI Express、存储(通常是SSD或通过网络)和网络带宽。它们可以并行使用以获得最高效率。
* 后端可以通过自动并行计算和通信来提高性能。

## 练习

1. 在本节定义的run函数中执行了10个操作。它们之间没有依赖关系。设计一个实验，看看MXNet是否会自动并行执行它们。
1. 当单个运算符的工作负载足够小时，并行化甚至可以帮助单个CPU或GPU。设计一个实验来验证这一点。
1. 设计一个实验，在CPU和GPU上进行并行计算，并在两个设备之间进行通信。
1. 使用调试器(如NVIDIA的Nsight)来验证代码的有效性。
1. 设计包含更复杂数据依赖项的计算任务，并运行实验，看看在提高性能的同时是否能获得正确的结果。
