

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-14 21:52:09
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-08-30 21:42:30
 * @Description:MT， improve
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_computational-performance/multiple-gpus-concise.html
-->

# 多个 GPU 的简洁实现

接下来，我们使用2个GPU进行训练。与LeNet相比，ResNet-18的模型要复杂得多。这就是并行化显示其优势的地方。计算时间明显大于同步参数的时间。因为并行化的开销不太重要，所以这提高了可伸缩性。

TODO:CODE

## 简单网络

让我们使用一个比上一节中的 LeNet 更有意义的网络，这个网络仍然足够容易和快速地进行训练。我们选择了 ResNet-18变体[ He et al. ，2016a ]。因为输入的图像很小，所以我们稍微修改一下。特别是，与7.6节的不同之处在于，我们在开头使用了较小的卷积内核、跨步和填充。此外，我们删除了最大池层。

TODO:CODE

## 参数初始化和Logistics

Initialize 方法允许我们在我们选择的设备上设置参数的初始默认值。更新参见第4.8节。特别方便的是，它还允许我们同时在多个设备上初始化网络。让我们来试试这在实践中是如何工作的。

TODO:CODE

使用上一节中介绍的 `split_and _load` 函数，我们可以将一小批数据分割并将其复制到上下文变量提供的设备列表中。网络对象自动使用合适的 GPU 计算前向传播的值。和之前一样，我们生成了4个观察结果，并将它们分割在 GPU 上。

TODO:CODE

数据通过网络后，将在数据通过的设备上初始化相应的参数。这意味着初始化是基于每个设备进行的。由于我们选择了GPU 0和GPU 1进行初始化，因此仅在此处而不是在CPU上初始化网络。实际上，参数甚至不存在于设备上。我们可以通过打印出参数并观察可能出现的任何错误来验证这一点。

TODO:CODE

最后，让我们用可以在多个设备上并行工作的代码替换代码来评估准确性。这代替了第6.6节中的`valuate_accuracy_gpu`函数。主要区别在于我们在调用网络之前先拆分了一批。其他所有基本相同。

TODO:CODE

## 训练

和以前一样，训练代码需要执行许多基本功能以实现高效的并行性：

* 网络参数需要在所有设备上初始化。
* 遍历数据集时，迷你批处理将在所有设备上划分。
* 我们跨设备并行计算损耗及其梯度。
* 损失汇总（通过`trainer`方法），并相应地更新参数。

最后，我们计算准确性（再次并行）以报告网络的最终价值。训练例程与上一章中的实现非常相似，不同之处在于我们需要拆分和汇总数据。

TODO:CODE

## 实验

让我们看看这在实践中是如何工作的。作为热身，我们在单个GPU上训练网络。

TODO:CODE

接下来，我们使用2个GPU进行训练。与LeNet相比，ResNet-18的模型要复杂得多。这就是并行化显示其优势的地方。计算时间明显大于同步参数的时间。因为并行化的开销不太重要，所以这提高了可伸缩性。

TODO:CODE

## 小结

* Gluon通过提供上下文列表，为跨多个设备的模型初始化提供了原语。
* 可以在可以找到数据的设备上自动评估数据。
* 在尝试访问该设备上的参数之前，请小心初始化每个设备上的网络。否则，您将遇到错误。
* 优化算法会自动在多个GPU上聚合。

## 练习

1. 本节使用ResNet-18。尝试不同的时期、批处理大小和学习速度。使用更多的gpu进行计算。如果你在一个有16个gpu的p2.16xlarge实例上尝试这个会发生什么?
2. 有时，不同的设备提供不同的计算能力。我们可以同时使用GPU和CPU。我们该如何分配工作?这样的努力值得吗?为什么?为什么不呢?
3. 如果我们删除`npx.waitall()`会发生什么?如何修改训练，使并行性有最多两个步骤的重叠?
