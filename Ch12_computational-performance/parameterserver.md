

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-06-29 15:26:14
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-06-30 17:56:46
 * @Description:translate
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/PR-1088/chapter_computational-performance/parameterserver.html
-->
#
[Smola & Narayanamurthy, 2010]在分布式潜在变量模型的背景下引入了参数服务器的核心思想。然后在[Ahmed et al.， 2012]中描述了推拉语义，在[Li et al.， 2014]中描述了系统和开源库。在下面，我们将推动提高效率所需的组成部分。

## 数据并行训练

让我们回顾一下分布式训练的数据并行训练方法。在本节中，我们将使用此方法来排除其他方法，因为它在实践中实现起来要简单得多。由于gpu现在有大量的内存，所以几乎没有什么用例(除了对图形的深入学习之外)会首选任何其他并行策略。[图12.7.1](http://preview.d2l.ai/d2l-en/PR-1088/chapter_computational-performance/parameterserver.html#fig-parameterserver)描述了我们在上一节中实现的数据并行性的变体。该方法的关键在于在更新的参数重新广播给所有gpu之前，梯度的聚集发生在GPU0上。

回想起来，在GPU0上集合的决定似乎相当特别。毕竟，我们也可以在CPU上进行聚合。事实上，我们甚至可以决定聚合一个GPU上的一些参数和另一个GPU上的一些参数。如果优化算法支持这一点，我们没有真正的理由不能。例如，如果我们有四个参数向量$v1, v4$和相关的梯度$g1, g4$，我们可以在一个GPU上聚合梯度。

##
##
## 键值对(key,value)保存

在实践中实现分布式多gpu训练所需的步骤是很重要的。特别是，考虑到我们可能会遇到许多不同的选择。这就是为什么使用公共抽象(即具有重新定义更新语义的(键、值)存储)是值得的。跨多个服务器和多个gpu的梯度计算可以定义为

这个操作的关键在于它是一种交换约简，也就是说，它将许多向量化为一个，而操作的顺序并不重要。这对于我们的目的很好，因为我们不(需要)有细粒度的控制什么时候接收渐变。请注意，我们有可能分段进行还原。此外，注意这个操作是独立的块ii与不同的参数(和梯度)。

这允许我们定义以下两个操作:push(它积累梯度)和pull(它检索聚合梯度)。因为我们有许多不同的渐变集(毕竟，我们有许多层)，我们需要用一个键ii索引渐变。与(键，值)存储的这种相似性，如在Dynamo [DeCandia et al.， 2007](http://preview.d2l.ai/d2l-en/PR-1088/chapter_references/zreferences.html#decandia-hastorun-jampani-ea-2007)中引入的那种，并不是巧合。它们也满足许多相似的特性，特别是在跨多个服务器分布参数时。

- **pull(key，value)**从公共存储中检索集合参数，例如在合并所有TODO:工作人员的梯度后。
- **pull(key, value)**从公共存储中检索一个聚合参数，例如，在合并所有TODO:工人的梯度之后。

通过隐藏所有关于同步的复杂性背后的一个简单的推拉操作我们可以解耦统计modeler的担忧。他们希望能够表达优化简单来说,系统工程师需要处理分布式同步所固有的复杂性。在下一节中，我们将在实践中试验这种(键、值)存储。

## 小结

- 同步需要高度适应服务器内特定的网络基础设施和连接性。
- 这对同步所需的时间有很大的影响。
- 对于P3和DGX-2服务器，环形同步是最理想的。
- 对其他人来说可能没有那么多。
- 当增加多个参数服务器以增加带宽时，分级同步策略工作得很- 好。
- 异步通信(当计算仍在进行时)可以提高性能。

## 练习

1. 你能进一步增加环形同步吗?提示:您可以在两个方向发送消1. 息。
1. 完全是异步的。一些延迟允许吗?
1. 容错。如何?如果我们丢失了一个服务器怎么办?这是问题吗?
1. 检查点。
1. 树聚合。你能快点吗?
1. 其他缩微(交换半环)。
