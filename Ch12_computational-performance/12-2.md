

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-14 22:13:18
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-14 22:29:50
 * @Description:
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_computational-performance/async-computation.html
-->

# 异步计算

今天的计算机是高度并行的系统，包括多个 CPU 内核(通常每个内核有多个线程) ，每个 GPU 有多个处理元件，每个设备通常有多个 GPU。简而言之，我们可以在同一时间处理许多不同的事情，通常是在不同的设备上。不幸的是，Python 并不是编写并行和异步代码的好方法，至少不需要额外的帮助。毕竟，Python 是单线程的，这在未来不太可能改变。深度学习框架(如 MXNet 和 TensorFlow)利用异步编程模型来提高性能(PyTorch 使用 Python 自己的调度程序导致不同的性能折衷)。因此，了解异步编程的工作原理有助于我们开发更高效的程序，通过前瞻性地减少计算需求和相互依赖。这使我们可以减少内存开销并提高处理器利用率。我们首先导入必要的库。

TODO:CODE

## 通过后端的异步

对于热身，考虑下面的玩具问题——我们想生成一个随机矩阵并将其乘以。让我们用 NumPy 和 MXNet NP 来看看两者的区别。

TODO:CODE

这个数量级更快。至少看起来是这样。因为两者都是在同一个处理器上执行的，所以一定有其他的原因。强制 MXNet 在返回之前完成所有计算显示了之前发生的情况: 计算由后端执行，而前端将控制权返回给 Python。

TODO:CODE

一般来说，MXNet 有一个与用户直接交互的前端，例如，通过 Python，以及系统用来执行计算的后端。后端拥有自己的线程，这些线程不断地收集和执行排队任务。请注意，为了实现这一点，后端必须能够跟踪计算图中各个步骤之间的依赖关系。因此，将不相互依赖的操作并行化是可能的。

如图12.2.1所示，用户可以用各种前端语言编写 MXNet 程序，比如 Python、 r、 Scala 和 c + + 。无论使用哪种前端编程语言，MXNet 程序的执行主要发生在 c + + 实现的后端。由前端语言发出的操作被传递到后端执行。后端管理自己的线程，这些线程不断收集和执行排队任务。请注意，为了实现这一点，后端必须能够跟踪计算图中各个步骤之间的依赖关系。也就是说，不可能将相互依赖的操作并行化。

让我们看看另一个玩具示例，以更好地理解依赖图。

TODO:CODE

上面的代码段也显示在图12.2.2中。每当Python前端线程执行前三个语句之一时，它只会将任务返回到后端队列。当需要打印最后一条语句的结果时，Python前端线程将等待C ++后端线程完成变量z的计算结果。这种设计的一个好处是Python前端线程不需要执行实际的计算。因此，无论Python的性能如何，对程序的整体性能几乎没有影响。图12.2.3说明了前端和后端如何交互。

##

有许多操作会迫使Python等待完成：*最明显的是npx.waitall（）会等到所有计算完成后，无论何时发出计算指令。实际上，除非绝对必要，否则使用此运算符是个坏主意，因为它可能导致性能下降。*如果我们只想等待特定的变量可用，则可以调用z.wait_to_read（）。在这种情况下，MXNet块将返回Python，直到计算出变量z。此后，其他计算可能会继续进行。

##

想象一下一种情况，我们通过在前端执行Python代码来继续将操作插入后端。例如，前端可能会在很短的时间内插入大量的minibatch任务。毕竟，如果Python中没有进行有意义的计算，则可以很快完成。如果可以同时快速启动所有这些任务，则可能会导致内存使用量激增。给定GPU（甚至CPU）上可用的内存量有限，这可能导致资源争用甚至程序崩溃。一些读者可能已经注意到，以前的训练例程使用了同步方法，例如item甚至asnumpy。

我们建议您谨慎使用这些操作，例如，对于每个小型批处理，以平衡计算效率和内存占用量。为了说明发生了什么，让我们为深度网络实现一个简单的训练循环，并测量其内存消耗和时序。下面是模拟数据生成器和深度网络。

TODO:CODE

接下来，我们需要一个工具来测量代码的内存占用量。我们使用一个相对原始的ps调用来完成此操作（请注意，后者仅适用于Linux和MacOS）。要详细了解此处发生的情况，请使用Nvidia的Nsight或英特尔的vTune。

TODO:CODE

在开始测试之前，我们需要初始化网络参数并批量处理。否则，要查看额外的内存消耗是很难的。有关初始化的更多详细信息，请参见第5.3节。

TODO:CODE

为了确保我们不会在后端使任务缓冲区溢出，我们在每个循环的结尾插入一个对loss函数的wait_to_read调用。这迫使前向传播在开始新的前向传播之前完成。请注意，（可能更优雅的）替代方法是在标量变量中跟踪损失并通过item调用强制设置障碍。

TODO:CODE

如我们所见，小批处理的时间与优化代码的整体运行时间非常吻合。此外，内存占用量仅略有增加。现在让我们看看如果在每个小批量结束时降低障碍会发生什么。

TODO:CODE

即使为后端发出指令的时间减少了一个数量级，我们仍然需要执行计算。因此，大量的中间结果无法释放，并且可能堆积在内存中。尽管这在上面的玩具示例中没有引起任何问题，但如果在现实世界中未经检查，可能会导致内存不足的情况。

## 小结

* MXNet将Python前端与执行后端分离。这允许将命令快速异步插入后端​​以及相关的并行性。
* 异步导致响应速度相当快。但是，请注意不要过度填充任务队列，因为这可能导致过多的内存消耗。
* 建议对每个微型批处理进行同步，以使前端和后端保持大致同步。
* 请注意，从MXNet的内存管理到Python的转换将迫使后端等待，直到特定变量准备就绪。print，asnumpy和item都具有此效果。这可能是理想的，但是无心使用同步会破坏性能。
* 芯片供应商提供了复杂的性能分析工具，以更深入地了解深度学习的效率。

## 练习

1. 上面我们提到使用异步计算可以将执行10001000计算所需的总时间减少到t1 + 1000t2 + t3t1 + 1000t2 + t3。为什么要在这里假设1000t2> 999t11000t2> 999t1？
1. 如果您希望每个小批量重叠一次，您将如何修改训练循环？ 即，是否要确保在批处理bt + 2bt + 2开始之前完成批处理btbt？
1. 如果我们要同时在CPU和GPU上执行代码，会发生什么情况？ 在发出每个小批量订单之后，您是否仍要坚持同步？
1. 测量waitall和wait_to_read之间的差异。提示：执行许多指令并进行同步以获得中间结果。
