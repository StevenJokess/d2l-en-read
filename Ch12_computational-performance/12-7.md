

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-08-11 23:55:27
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-10-07 13:11:55
 * @Description:MT
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_computational-performance/parameterserver.html
 *
-->

# 服务器参数
:label:`sec_parameterserver`

当我们从单个gpu转移到多个gpu，然后转移到包含多个gpu的多个服务器时，可能所有这些都分布在多个机架和网络交换机上，我们用于分布式和并行训练的算法需要变得更加复杂。细节很重要，因为不同的互连有非常不同的带宽(例如，NVLink可以提供高达100GB/s的6个链路在适当的设置，PCIe 3.0 16x lane提供16GB/s，而高速100gbe以太网只有10GB/s)。同时，期望统计建模师是网络和系统方面的专家是不合理的。

:cite:`Smola.Narayanamurthy.2010`在分布式潜在变量模型的背景下引入了参数服务器的核心思想。然后在:cite:`Ahmed.Aly.Gonzalez.ea.2012`中描述了推和拉语义，在:cite:`Li.Andersen.Park.ea.2014`中描述了系统和一个开源库。在下面，我们将推动提高效率所需的组成部分。

## 数据并行训练

让我们回顾一下分布式训练的数据并行训练方法。在本节中，我们将使用此方法来排除其他方法，因为它在实践中实现起来要简单得多。由于gpu现在有大量的内存，所以几乎没有什么用例(除了对图形的深入学习之外)会首选任何其他并行策略。图12.7.1描述了我们在上一节中实现的数据并行性的变体。该方法的关键在于在更新的参数重新广播给所有gpu之前，梯度的聚集发生在GPU0上。

![左:单GPU训练;右:多gpu训练的变体。它是这样进行的。(1)计算损耗和梯度，(2)将所有梯度聚合到一个GPU上，(3)进行参数更新并将参数重新分布到所有GPU上。](../img/ps.svg)
:label:`fig_parameterserver`

回想起来，在GPU0上进行聚合的决定似乎是临时的。 毕竟，我们最好还是在CPU上进行聚合。 实际上，我们甚至可以决定将一个GPU上的某些参数聚合到另一个GPU上。 只要优化算法支持这一点，我们就没有理由不这样做。 例如，如果我们有四个参数矢量$\mathbf{v}_1, \ldots, \mathbf{v}_4$，且具有关联的梯度$\mathbf{g}_1, \ldots, \mathbf{g}_4$，我们可以将梯度分别聚集在一个GPU上。

$$\mathbf{g}_{i} = \sum_{j \in \mathrm{GPUs}} \mathbf{g}_{ij}$$

这种推理似乎武断而轻率。毕竟，整个数学过程都是一样的。然而，我们正在处理实际的物理硬件，其中不同的总线具有不同的带宽，如12.4节所讨论的。考虑如图12.7.2所示的一个真正的4路GPU服务器。如果它是特别好的连接，它可能有一个100 GbE网卡。更典型的数字在1-10 GbE范围内，有效带宽为100MB/s到1GB/s。由于cpu有太少的PCIe通道直接连接到所有gpu(例如，消费级英特尔cpu有24通道)，我们需要一个多路复用器。从一个16x Gen3链路的中央处理器的带宽是16GB/s。这也是每个gpu连接到交换机的速度。这意味着设备之间的通信更加有效。

![一个四路GPU服务器。](../img/bw-hierarchy.svg)
:label:`fig_bw_hierarchy`

为了讨论的缘故，让我们假设梯度的“重量”为160MB。在这种情况下，将所有3个剩余gpu的梯度发送到第四个gpu需要30ms(每次传输需要10ms = 160MB / 16gb /s)。再加上30ms将权重向量传送回来，我们总共得到60ms。如果我们将所有的数据发送到CPU，我们将遭受40ms的损失，因为四个gpu中的每个都需要将数据发送到CPU，总共产生80ms。最后，假设我们能够将渐变分成4个部分，每个部分大小为40MB。现在，由于PCIe交换机提供了所有链路之间的全带宽操作，我们可以同时在一个不同的GPU上聚合每个部分。这样做需要7.5ms，而不是30ms，一个同步操作总共需要15ms。简而言之，根据我们同步参数的方式，同一操作可能需要15ms到80ms之间的任何时间。图12.7.3描述了交换参数的不同策略。

图12.7.3同步策略。

请注意，在改进性能方面，我们还有另一个工具:在深度网络中，计算从上到下的所有梯度需要一些时间。我们可以开始同步一些参数组的梯度，即使我们还在忙于为其他参数组计算它们(其中的技术细节有些复杂)。例如，[Sergeev & DelBalso, 2018]了解如何在Horovod中做到这一点。

## 环同步

当涉及到现代深度学习硬件上的同步时，我们经常遇到明显定制的网络连接。例如，AWS P3.16xlarge和NVIDIA DGX-2实例共享图12.7.4的连接结构。每个GPU通过PCIe链路连接到主机CPU，该链路最多运行16gb /s。另外，每个GPU还拥有6个NVLink连接，每个NVLink连接能够双向传输300 Gbit/s。这相当于每个方向的每个链接约18gb /s。简而言之，聚合NVLink带宽明显高于PCIe带宽。问题是如何最有效地利用它。

![8GPU V100服务器上的NVLink连接(图片由NVIDIA提供)。](../img/nvlink.svg)
:label:`fig_nvlink`

结果表明[Wang et al.， 2018]，最优的同步策略是将网络分解成两个环，直接使用它们同步数据。由图12.7.5可知，可以将网络分解为一个具有双NVLink带宽的环(1-2-3-4-5-6-7-8-1)和一个具有规则带宽的环(1-4-6-3-5-8-2-7-1)。在这种情况下，设计一个有效的同步协议是很重要的。

![将NVLink网络分解为两个环。](../img/nvlink-twoloop.svg)
:label:`fig_nvlink_twoloop`

考虑以下思想实验：给定n个计算节点（或GPU）的数量，我们可以将梯度从第一个节点发送到第二个节点。 在那里，它被添加到局部渐变中并发送到第三个节点，依此类推。 在n-1n-1步之后，可以在最后访问的节点中找到聚合梯度。 也就是说，聚集梯度的时间随节点数量线性增长。 但是，如果执行此操作，该算法将效率很低。 毕竟，在任何时候，只有一个节点在通信。 如果我们将梯度分成nn个块并从节点ii开始开始同步块ii，该怎么办？ 由于每个块的大小为1 / n1 / n，所以总时间现在为（n-1）/n≈1（n-1）/n≈1。 换句话说，随着我们增加环的大小，用于聚集渐变的时间不会增加。 这是一个非常惊人的结果。 图12.7.6说明了n = 4n = 4个节点上的步骤顺序。

![跨4个节点的环同步。 每个节点开始将梯度的一部分传输到其左邻居，直到可以在其右邻居中找到组合的梯度为止。](../img/ringsync.svg)
:label:`fig_ringsync`

如果我们使用在8个V100 GPU上同步160MB的相同示例，则大约为2⋅160MB/（3⋅18GB/ s）≈6ms这比使用 PCIe总线，即使我们现在使用8个GPU。 请注意，实际上，这些数字要差很多，因为深度学习框架通常无法将通信组合成大的突发传输。 此外，时间至关重要。 请注意，常见的误解是环同步与其他同步算法根本不同。 唯一的区别是，与简单树相比，同步路径更为复杂。

## 多机训练

在多台机器上进行分布式培训增加了进一步的挑战：我们需要与仅通过相对较低带宽的结构连接的服务器进行通信，在某些情况下，该结构可能会慢一个数量级。 跨设备同步非常棘手。 毕竟，运行训练代码的不同机器的速度会有细微不同。 因此，如果要使用同步分布式优化，则需要对其进行同步。 :numref:`fig_ps_multimachine`说明了如何进行分布式并行训练。

1. 在每台计算机上读取（不同的）一批数据，将其分配给多个GPU，然后传输到GPU内存中。 在每个GPU批次上分别计算预测和梯度。
1. 来自所有本地GPU的梯度都聚集在一个GPU上（或者它的一部分聚集在不同的GPU上）。
1. 渐变将发送到CPU。
1. CPU将梯度发送到中央参数服务器，该服务器汇总所有梯度。
1. 然后，使用聚合梯度来更新权重向量，并将更新后的权重向量广播回各个CPU。
1. 信息被发送到一个（或多个）GPU。
1. 更新的权重向量分布在所有GPU上。

![多机多GPU分布式并行训练。](../img/ps-multimachine.svg)
:label:`fig_ps_multimachine`

这些操作似乎都相当简单。事实上，它们可以在一台机器内有效地进行。但是，在查看多台机器之后，我们可以看到中央参数服务器成为了瓶颈。毕竟，每个服务器的带宽是有限的，因此对于$m$工作者来说，将所有梯度发送到服务器所需的时间是O(m)。我们可以通过增加nn的服务器数量来突破这个障碍。此时，每个服务器只需要存储参数的O(1/n)，因此用于更新和优化的总时间变为O(m/n)。无论我们处理多少工人，匹配这两个数字都会产生恒定的比例。实际上，我们使用相同的机器作为工人和服务器。设计如:numref:`fig_ps_multips`所示。详见:cite:`Li.Andersen.Park.ea.2014`。特别是，确保多台机器在没有不合理的延迟的情况下工作是很重要的。我们省略了barrier的细节，只在下面简要介绍同步和异步更新。

![上-由于带宽有限，单参数服务器是一个瓶颈。下-多参数服务器存储部分参数的聚合带宽](../img/ps-multips.svg)
:label:`fig_ps_multips`

## 键值对存储

在实践中实现分布式多gpu训练所需的步骤是很重要的。特别是，考虑到我们可能会遇到许多不同的选择。这就是为什么使用公共抽象(即具有重新定义更新语义的(键、值)存储)是值得的。跨多个服务器和多个gpu的梯度计算可以定义为

$$\mathbf{g}_{i} = \sum_{k \in \mathrm{workers}} \sum_{j \in \mathrm{GPUs}} \mathbf{g}_{ijk}.$$

这个操作的关键在于它是一种交换约简，也就是说，它将许多向量化为一个，而操作的顺序无关紧要。这对于我们的目的很好，因为我们不(需要)有细粒度的控制什么时候接收渐变。请注意，我们有可能分段进行还原。此外，注意这个操作是独立的块ii与不同的参数(和梯度)。

这允许我们定义以下两个操作:push(它积累梯度)和pull(它检索聚合梯度)。因为我们有许多不同的渐变集(毕竟，我们有许多层)，我们需要用一个键ii索引渐变。与(键，值)存储的这种相似性，如在Dynamo [DeCandia et al.， 2007]中引入的那种，并不是巧合。它们也满足许多相似的特性，特别是在跨多个服务器分布参数时。

* **push(key, value)** 将一个特定的梯度(value)从一个worker发送到一个公共存储。在这里，参数被聚合，例如，通过把它加起来。
* **pull(key, value)** 从公共存储中检索一个聚合参数，例如，在合并所有worker的梯度之后。

通过隐藏所有关于同步的复杂性背后的一个简单的推拉操作我们可以解耦统计modeler的担忧。他们希望能够表达优化简单来说,系统工程师需要处理分布式同步所固有的复杂性。在下一节中，我们将在实践中试验这种(键、值)存储。

## 小结

* 同步需要高度适应特定的网络基础结构和服务器内的连接性。 这可以大大缩短同步时间。
* 环形同步对于P3和DGX-2服务器可能是最佳的。 对于其他人可能没有那么多。
* 当添加多个参数服务器以增加带宽时，分层同步策略效果很好。
* 异步通信（尽管计算仍在进行中）可以提高性能。

## 练习

1. 您能否进一步提高环网同步？ 提示：您可以双向发送消息。
1. 完全异步。 允许一些延误吗？
1. 容错能力。 怎么样？ 如果我们丢失服务器怎么办？ 这有问题吗？
1. 检查点
1. 树聚合。 你可以做得更快吗？
1. 其他减少（可交换半环）。
