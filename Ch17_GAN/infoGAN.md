

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-14 23:10:49
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-12-29 19:07:25
 * @Description:
 * @TODO::
 * @Reference:https://www.zhihu.com/column/c_1186629504699731968
 * https://github.com/znxlwm/pytorch-generative-model-collections
 * [3]: https://www.leiphone.com/news/201701/Kq6FvnjgbKK8Lh8N.html
 * [4]: http://www.tensorinfinity.com/paper_26.html
-->

# Information Maximizing Generative Adversarial Nets

InfoGANæ˜¯ä¼¯å…‹åˆ©å¤§å­¦å’ŒopenAIè”æ‰‹åœ¨NIPS2016å‘è¡¨çš„è®ºæ–‡ï¼Œæœ¬è´¨ä¸Šä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§cGANã€‚ä»å‡ºå‘ç‚¹çœ‹ï¼ŒInfoGANæ˜¯åŸºäºæœ´ç´ GANæ”¹è¿›çš„ã€‚å®ƒå°†åŸå…ˆç”Ÿæˆå™¨ä¸Šè¾“å…¥çš„latent code zæŒ‰ç»´åº¦è¿›è¡Œåˆ†è§£ï¼Œé™¤äº†åŸå…ˆçš„å™ªå£°zä»¥å¤–ï¼Œè¿˜åˆ†è§£å‡ºä¸€ä¸ªè§£è€¦è¡¨ç¤ºcã€‚InfoGANçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œå¦‚æœè¿™ä¸ªcèƒ½è§£é‡Šç”Ÿæˆå‡ºæ¥çš„G(z,c)ï¼Œé‚£ä¹ˆcåº”è¯¥ä¸G(z,c)ç”±é«˜åº¦çš„ç›¸å…³æ€§ã€‚å…¶åœ¨MNISTã€3Däººè„¸å’Œæ¤…å­ã€CelebAã€SVHNæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†ä¸é”™çš„å®éªŒæ•ˆæœã€‚

å…¶ä¸­ï¼š

- cé™¤äº†å¯ä»¥è¡¨ç¤ºç±»åˆ«ä»¥å¤–ï¼Œè¿˜å¯ä»¥åŒ…å«å¤šç§å˜é‡ã€‚ä»¥MNISTæ•°æ®é›†ä¸ºä¾‹ï¼Œè¿˜å¯ä»¥è¡¨ç¤ºè¯¸å¦‚å…‰ç…§æ–¹å‘ï¼Œå­—ä½“çš„å€¾æ–œè§’åº¦ï¼Œç¬”ç”»ç²—ç»†ç­‰ã€‚
- cä»…ä»…åŒ…å«åŸæ¥zä¸­è‹¥å¹²ä¸ªç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦å¯ä»¥æ˜¯ç¦»æ•£çš„ä¹Ÿå¯ä»¥æ˜¯è¿ç»­çš„ï¼Œç”¨æ¥è¡¨ç¤ºæ•°æ®ä¸­çš„è§£è€¦å˜åŒ–å› å­ã€‚ä»¥MNISTæ•°æ®é›†ä¸ºä¾‹ï¼Œå–zä¸­3ä¸ªç»´åº¦ä½œä¸ºcï¼Œ1ä¸ªç¦»æ•£ï¼Œ2ä¸ªè¿ç»­ï¼Œæœ€åä¹ å¾—çš„cï¼Œç¦»æ•£çš„ç»´åº¦è¡¨ç¤ºä¸åŒæ•°å­—ï¼Œè¿ç»­çš„ç»´åº¦åˆ†åˆ«è¡¨ç¤ºäº†æ•°å­—çš„æ—‹è½¬å’Œç²—ç»†

æŸå¤±å‡½æ•°æ”¹è¿›ï¼šé€šè¿‡æœ€å¤§åŒ–éšå˜é‡ä¸è§‚æµ‹æ•°æ®çš„äº’ä¿¡æ¯ï¼Œå¹¶æå‡ºä¸€ä¸ªå¯é«˜æ•ˆä¼˜åŒ–çš„äº’ä¿¡æ¯çš„ä¸‹ç•Œï¼Œä½¿å¾—GANæœ‰äº†å¯è§£é‡Šçš„ç‰¹å¾è¡¨å¾ï¼ˆinterpretable representationï¼‰ã€‚

## äº’ä¿¡æ¯ (Mutual Information)[9]

äº’ä¿¡æ¯æ˜¯ä¸¤ä¸ªéšæœºå˜é‡ä¾èµ–ç¨‹åº¦çš„é‡åº¦, å¯ä»¥è¡¨ç¤ºä¸º:
$$
I(X ; Y)=H(X)-H(X \mid Y)
$$

å…¶ä¸­, $I(X ; Y)$ æ˜¯å½“Yè¢«æ¢ç´¢äº†, å…³äºXçš„ä¸ç¡®å®šæ€§çš„å‡å°‘é‡, æ ¹æ®äº’ä¿¡æ¯ç†è®º, æˆ‘ä»¬å¸Œæœ›å¾—åˆ° $P_{G}(c \mid x)$ æœ‰ä¸€ä¸ªè¾ƒå°çš„ç†µï¼Œç†µä»£è¡¨æƒŠå–œåº¦, è¾ƒå°çš„ç†µè¡¨ç¤ºè¯¥äº‹ä»¶å‘ç”Ÿå¯èƒ½æ€§è¾ƒå¤§, ä¹Ÿå°±æ˜¯è¯´è¯¥æ¦‚ç‡è¾ƒå¤§ï¼Œæœ€ç»ˆçš„InfoGANçš„å®šä¹‰å¼å¦‚ä¸‹:
$$
\min _{G} \max _{D} V_{I}(D, G)=V(D, G)-\lambda I(c ; G(z, c))
$$

è¦å»ç›´æ¥ä¼˜åŒ– $I(c ; G(z, c))$ æ˜¯æå…¶å›°éš¾çš„, å› ä¸ºè¿™æ„å‘³ç€æˆ‘ä»¬è¦èƒ½å¤Ÿè®¡ç®—åéªŒæ¦‚ç‡ï¼ˆposterior
probability) $P(c \mid x),$ ä½†æ˜¯æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªè¾…åŠ©åˆ†å¸ƒ (auxiliary distribution) $Q(c \mid x),$ æ¥è¿‘ä¼¼è¿™ä¸€åéªŒ
æ¦‚ç‡ã€‚è¿™æ ·æˆ‘ä»¬èƒ½å¤Ÿç»™å‡ºäº’ä¿¡æ¯çš„ä¸€ä¸ªä¸‹ç•Œ (lower bounding) $ï¼š$
$$
I(c ; G(z, c)) \geqslant \mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c \mid x)}\left[\log Q\left(c^{\prime} \mid x\right)\right]\right]+H(c)
$$


## äº’ä¿¡æ¯æœ€å¤§åŒ–

è¦å»ç›´æ¥ä¼˜åŒ– $I(c ; G(z, c))$ æ˜¯æå…¶å›°éš¾çš„, å› ä¸ºè¿™æ„å‘³ç€æˆ‘ä»¬è¦èƒ½å¤Ÿè®¡ç®—åéªŒæ¦‚ç‡ï¼ˆposterior
probability) $P(c \mid x),$ æ‰€ä»¥è®ºæ–‡é‡‡ç”¨äº†å˜åˆ†æ¨æ–­çš„æ€æƒ³ï¼Œå®šä¹‰ä¸€ä¸ªè¾…åŠ©åˆ†å¸ƒ(auxiliary distribution) $Q(c \mid x)$æ¥æ¥è¿‘ $P(c \mid x)$
$$
\begin{aligned}
I(c ; G(z, c)) &=H(c)-H(c \mid G(z, c)) \\
&=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c \mid x)}\left[\log P\left(c^{\prime} \mid x\right)\right]\right]+H(c) \\
&=\mathbb{E}_{x \sim G(z, c)}[\underbrace{D_{\mathrm{KL}}(P(\cdot \mid x) \| Q(\cdot \mid x))}_{\geq 0}+\mathbb{E}_{c^{\prime} \sim P(c \mid x)}\left[\log Q\left(c^{\prime} \mid x\right)\right]]+H(c) \\
& \geq \mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c \mid x)}\left[\log Q\left(c^{\prime} \mid x\right)\right]\right]+H(c)
\end{aligned}
$$
è®ºæ–‡å°†H(c)çœ‹åšå¸¸æ•°ï¼Œå¹¶æ ¹æ®å®šç†ï¼š
Lemma 5.1 For random variables $X, Y$ and function $f(x, y)$ under suitable regularity conditions:
$\mathbb{E}_{x \sim X, y \sim Y \mid x}[f(x, y)]=\mathbb{E}_{x \sim X, y \sim Y\left|x, x^{\prime} \sim X\right| y}\left[f\left(x^{\prime}, y\right)\right]$

å¦‚æ­¤å¯ä»¥å®šä¹‰å˜åˆ†ä¸‹ç•Œ

$$
\begin{aligned}
L_{I}(G, Q) &=E_{c \sim P(c), x \sim G(z, c)}[\log Q(c \mid x)]+H(c) \\
&=E_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c \mid x)}\left[\log Q\left(c^{\prime} \mid x\right)\right]\right]+H(c) \\
& \leq I(c ; G(z, c))
\end{aligned}
$$
æœ€ç»ˆInfoGANçš„å®šä¹‰å¼å¦‚ä¸‹:
$$
\min _{G, Q} \max _{D} V_{\operatorname{InfoGAN}}(D, G, Q)=V(D, G)-\lambda L_{I}(G, Q)
$$

## è§£è€¦è¡¨ç¤ºï¼ˆdisentangled representationï¼‰







è¿™æ˜¯æ€»çš„æ¨¡å‹æ¶æ„ï¼Œå…¶ä¸­å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ–‡ç« ç›´æ¥ç”¨åˆ¤åˆ«å™¨ä½œä¸ºå˜åˆ†ç½‘ç»œ [å…¬å¼]ï¼Œæœ€åä¸€å±‚åŒæ—¶è¾“å‡ºcçš„é¢„æµ‹å’ŒçœŸå‡çš„é¢„æµ‹ã€‚

æ€è€ƒ
InfoGANçš„äº’ä¿¡æ¯é¡¹ä½¿latent code cå°½å¯èƒ½åŒ…å«æ›´å¤šçš„å…³äºç”Ÿæˆå›¾åƒçš„ä¿¡æ¯ï¼Œå› æ­¤èƒ½å¤Ÿæ•æ‰ä¸åŒçš„å˜åŒ–å› å­ï¼Œä½†æ˜¯è¿™æ— æ³•è§£é‡Šcå…·æœ‰è§£è€¦çš„èƒ½åŠ›ã€‚æ ¹æ®è¿‘ä¸¤å¹´çš„ä¸€äº›æ–‡ç« ï¼Œå¯ä»¥ä½œå‡ºä¸€äº›çŒœæµ‹ï¼š

1.ç”±äºcæ¯ä¸ªç»´åº¦é—´æ˜¯ç‹¬ç«‹çš„ï¼Œå¹¶ä¸”ä¸€èˆ¬å‡è®¾Q(c|x)ç»´åº¦é—´ç‹¬ç«‹ï¼Œå› æ­¤è¿™æ ·èƒ½å¤Ÿä¿ƒè¿›cçš„ä¸åŒç»´åº¦é—´çš„è§£è€¦ï¼Œä½†æ ¹æ®ICML2019çš„æœ€ä½³è®ºæ–‡å¯çŸ¥ï¼Œè¿™æ ·å¹¶ä¸å¤Ÿã€‚

2.æˆ‘çŒœæµ‹ï¼Œä¸ºä½¿äº’ä¿¡æ¯æœ€å¤§ï¼Œcçš„æ¯ä¸ªç»´åº¦éƒ½åº”æœ€å¤§é™åº¦åœ°æ•æ‰xå˜åŒ–æœ€å¤§ä¸”ç‹¬ç«‹çš„å„ä¸ªæ–¹é¢ï¼Œè€ŒçœŸå®çš„å˜åŒ–å› å­ä¸€èˆ¬æ˜¯æŒ‰ç…§å˜åŒ–æ–¹å·®ä»å¤§åˆ°å°æ’åˆ—çš„ï¼Œç±»ä¼¼PCAï¼Œæ‰€ä»¥è¿™ç§åŒ¹é…ä½¿è§£è€¦æˆä¸ºäº†å¯èƒ½ã€‚

InfoGAN [3]å°è¯•ä½¿ç”¨æ— ç›‘ç£çš„æ–¹å¼å»å­¦ä¹ è¾“å…¥ğ’™çš„å¯è§£é‡Šéšå‘é‡ğ’›çš„è¡¨ç¤ºæ–¹æ³• (Interpretable Representation)ï¼Œå³å¸Œæœ›éšå‘é‡ğ’›èƒ½å¤Ÿå¯¹åº”åˆ°æ•°æ®çš„è¯­ä¹‰ç‰¹å¾ã€‚æ¯”å¦‚å¯¹äº MNIST æ‰‹å†™æ•°å­—å›¾ç‰‡ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºæ•°å­—çš„ç±»åˆ«ã€å­—ä½“å¤§å°å’Œä¹¦å†™é£æ ¼ç­‰æ˜¯å›¾ç‰‡çš„éšè—å˜ é‡ï¼Œå¸Œæœ›æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°è¿™äº›åˆ†ç¦»çš„(Disentangled)å¯è§£é‡Šç‰¹å¾è¡¨ç¤ºæ–¹æ³•ï¼Œä»è€Œå¯ä»¥é€šè¿‡äºº ä¸ºæ§åˆ¶éšå˜é‡æ¥ç”ŸæˆæŒ‡å®šå†…å®¹çš„æ ·æœ¬ã€‚å¯¹äº CelebA åäººç…§ç‰‡æ•°æ®é›†ï¼Œå¸Œæœ›æ¨¡å‹å¯ä»¥æŠŠå‘ å‹ã€çœ¼é•œä½©æˆ´æƒ…å†µã€é¢éƒ¨è¡¨æƒ…ç­‰ç‰¹å¾åˆ†éš”å¼€ï¼Œä»è€Œç”ŸæˆæŒ‡å®šå½¢æ€çš„äººè„¸å›¾ç‰‡ã€‚
åˆ†ç¦»çš„å¯è§£é‡Šç‰¹å¾æœ‰ä»€ä¹ˆå¥½å¤„å‘¢ï¼Ÿå®ƒå¯ä»¥è®©ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§æ›´å¼ºï¼Œæ¯”å¦‚ğ’›åŒ…å«äº†ä¸€ äº›åˆ†ç¦»çš„å¯è§£é‡Šç‰¹å¾ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»…ä»…æ”¹å˜è¿™ä¸€ä¸ªä½ç½®ä¸Šé¢çš„ç‰¹å¾æ¥è·å¾—ä¸åŒè¯­ä¹‰ çš„ç”Ÿæˆæ•°æ®ï¼Œå¦‚å›¾ 13.10 æ‰€ç¤ºï¼Œé€šè¿‡å°†â€œæˆ´çœ¼é•œç”·å£«â€ä¸â€œä¸æˆ´çœ¼é•œç”·å£«â€çš„éšå‘é‡ç›¸ å‡ï¼Œå¹¶ä¸â€œä¸æˆ´çœ¼é•œå¥³å£«â€çš„éšå‘é‡ç›¸åŠ ï¼Œå¯ä»¥ç”Ÿæˆâ€œæˆ´çœ¼é•œå¥³å£«â€çš„ç”Ÿæˆå›¾ç‰‡ã€‚


ä¿¡æ¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(InfoGAN) $^{15}$ æ˜¯GANä¿¡æ¯ç†è®ºçš„ä¸€ä¸ªé‡è¦æ‰©å±•. InfoGANç›¸æ¯”ä¸€èˆ¬çš„GAN, å¼•å…¥ä¸€ä¸ªéšç  $c, c$ è¡¨ç¤ºæ˜¾è‘—ç»“æ„åŒ–éšå±‚éš
æœºå˜é‡ä¸ç‰¹å®šè¯­ä¹‰ç‰¹å¾ä¹‹é—´çš„å…³ç³». ç”Ÿæˆå™¨çš„è¾“å…¥ä¸ºå‘†å£° $z$ å’Œéšç  $c,$ è¾“å‡ºä¸º $G(z, c),$ åœ¨GANä¸­, $P_{G}(x \mid c)=P_{G}(x)$. InfoGANä½¿ç”¨äº’ä¿¡æ¯ $I(c ; G(z, c))$ è¡¨ç¤ºä¸¤ä¸ªæ•°æ®ä¹‹é—´çš„å…³è”æ€§, è€Œéšç  $c$ å’Œç”Ÿæˆåˆ†å¸ƒ $G(z, c)$ ä¹‹é—´æœ‰é«˜çš„äº’ä¿¡æ¯. InfoGANçš„ç›®æ ‡å‡½æ•°å¦‚å¼(6)æ‰€ç¤º:[5]

$$
\min _{G} \max _{D} F_{1}(D, G)=F(D, G)-\lambda I(c ; G(z, c))
$$

$\begin{aligned} L_{D, Q}^{i n f o G A N} &=L_{D}^{G A N}-\lambda L_{I}\left(c, c^{\prime}\right) \\ L_{G}^{i n f o G A N} &=L_{G}^{G A N}-\lambda L_{I}\left(c, c^{\prime}\right) \end{aligned}$

When you apply the bound on the first term, you get a lower bound, and you introduce an auxillary distribution that ends up being called the discriminator. This application of the bound is wrong because it bounds the loss function from the wrong side.
When you apply the bound on the second term, you end up upper bounding the loss function, because of the negative sign. This is a good thing.
The combination of a lower bound and an upper bound means that you don't even know which direction you're bounding or approximating the loss function from anymore, it's neither an upper or a lower bound.


æ½œåœ¨ç¼–ç  latent code c[7]

- åŸæ¥çš„GAN Gçš„è¾“å‡ºä¸º G(z) ç°åœ¨æ”¹ä¸º G(z,c)
- cå¯ä»¥åŒ…å«å¤šç§å˜é‡ï¼Œæ ¹æ®ä¸åŒçš„åˆ†å¸ƒï¼Œæ¯”å¦‚åœ¨MNISTä¸­ï¼Œcå¯ä»¥ä¸€ä¸ªå€¼æ¥è¡¨ç¤ºç±»åˆ«ï¼Œä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å€¼æ¥è¡¨ç¤ºæ‰‹å†™ä½“çš„ç²—ç»†

Qé€šè¿‡ä¸Då…±äº«å·ç§¯å±‚ï¼Œè®¡ç®—èŠ±é”€å¤§å¤§å‡å°‘ã€‚æ­¤å¤–ï¼ŒQæ˜¯ä¸€ä¸ªå˜åˆ†åˆ†å¸ƒï¼Œåœ¨ç¥ç»ç½‘ç»œä¸­ç›´æ¥æœ€å¤§åŒ–ï¼ŒQä¹Ÿå¯ä»¥è§†ä½œä¸€ä¸ªåˆ¤åˆ«å™¨ï¼Œè¾“å‡ºç±»åˆ«cã€‚


InfoGANçš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒé€šè¿‡ä»å™ªå£°zä¸­æ‹†åˆ†å‡ºç»“æ„åŒ–çš„éšå«ç¼–ç cçš„æ–¹æ³•ï¼Œä½¿å¾—ç”Ÿæˆè¿‡ç¨‹å…·æœ‰ä¸€å®šç¨‹åº¦çš„å¯æ§æ€§ï¼Œç”Ÿæˆç»“æœä¹Ÿå…·å¤‡äº†ä¸€å®šçš„å¯è§£é‡Šæ€§ã€‚[8]


[1]: https://www.zhihu.com/column/c_1186629504699731968
[2]: https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book/blob/master/%E3%80%90%E3%80%8ATensorFlow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E3%80%91.pdf 13.4.2
[3]: https://arxiv.org/abs/1606.03657
[4]: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/infogan/infogan.py
[5]: http://www.c-s-a.org.cn/html/2019/11/7156.html#outline_anchor_12
[6]: https://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/
[7]: https://blog.csdn.net/Layumi1993/article/details/52474554
[8]: http://www.tensorinfinity.com/paper_26.html
[9]: https://www.jiqizhixin.com/articles/2020-09-04-15
[10]: https://blog.csdn.net/qq_31239495/article/details/82862660
