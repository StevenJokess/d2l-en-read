

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-08 17:42:09
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-10-17 16:53:28
 * @Description:
 * @TODO::
 * @Reference:
-->



å³ä½¿å¾—ç”Ÿæˆå™¨çš„åˆ†å¸ƒğ‘ğ‘”ä¸çœŸå®åˆ†å¸ƒğ‘ğ‘Ÿä¹‹é—´çš„ EM è·ç¦»è¶Šå°è¶Šå¥½ã€‚è€ƒè™‘åˆ°ğ”¼ğ’™ğ‘Ÿâˆ¼ğ‘ğ‘Ÿ[ğ·(ğ’™ğ‘Ÿ)]ä¸€é¡¹ ä¸ç”Ÿæˆå™¨æ— å…³ï¼Œå› æ­¤ç”Ÿæˆå™¨çš„è®­ç»ƒç›®æ ‡ç®€å†™ä¸º

$\min _{\phi} \mathcal{L}(G, D)=-\mathbb{E}_{x_{f} \sim p_{g}}\left[D\left(x_{f}\right)\right]$
$\quad=-\mathbb{E}_{\mathbf{z} \sim p_{z}(\cdot)}[D(G(\mathbf{z}))]$


```py
def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):
    # è®¡ç®— D çš„æŸå¤±å‡½æ•°     fake_image = generator(batch_z, is_training) # å‡æ ·æœ¬     d_fake_logits = discriminator(fake_image, is_training) # å‡æ ·æœ¬çš„è¾“å‡º     d_real_logits = discriminator(batch_x, is_training) # çœŸæ ·æœ¬çš„è¾“å‡º     # è®¡ç®—æ¢¯åº¦æƒ©ç½šé¡¹     gp = gradient_penalty(discriminator, batch_x, fake_image)
    # WGAN-GP D æŸå¤±å‡½æ•°çš„å®šä¹‰ï¼Œè¿™é‡Œå¹¶ä¸æ˜¯è®¡ç®—äº¤å‰ç†µï¼Œè€Œæ˜¯ç›´æ¥æœ€å¤§åŒ–æ­£æ ·æœ¬çš„è¾“å‡º     # æœ€å°åŒ–å‡æ ·æœ¬çš„è¾“å‡ºå’Œæ¢¯åº¦æƒ©ç½šé¡¹     loss = tf.reduce_mean(d_fake_logits) - tf.reduce_mean(d_real_logits) + 1 0. * gp

    return loss, gp
```
åŒæ ·æ²¡æœ‰äº¤å‰ç†µçš„è®¡ç®—æ­¥éª¤ã€‚ä»£ç å®ç°å¦‚ä¸‹ï¼š
```
def g_loss_fn(generator, discriminator, batch_z, is_training):
    # ç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°     fake_image = generator(batch_z, is_training)     d_fake_logits = discriminator(fake_image, is_training)
    # WGAN-GP G æŸå¤±å‡½æ•°ï¼Œæœ€å¤§åŒ–å‡æ ·æœ¬çš„è¾“å‡ºå€¼     loss = - tf.reduce_mean(d_fake_logits)

    return loss
```

[1]: Gulrajani,  I.,  Ahmed,  F.,  Arjovsky,  M.,  Dumoulin,  V.,  and  Courville,A. C. (2017). Improved training of Wasserstein GANs. InAdvances inNeural Information Processing Systems(pp. 5767-5777).
