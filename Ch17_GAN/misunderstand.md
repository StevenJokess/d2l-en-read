

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-11-18 17:05:22
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-11-18 17:07:35
 * @Description:
 * @TODO::
 * @Reference:https://tisi.org/14419
-->

为此，腾讯研究院、腾讯优图实验室共同完成报告《AI生成内容发展报告2020——“深度合成”（deep synthesis）商业化元年》，并基于该报告总结出了人们对该技术的十个误解，希望通过澄清这些误解，帮助人们更全面地了解深度合成技术的发展和应用情况。


误解1：深度合成技术仅包括AI换脸一种形式。
实际上，现阶段的深度合成技术，除了广为人知的“AI换脸”以外，还包括人脸再现、人脸生成、语音合成等技术，并朝着全身合成、数字虚拟人等方向发展。AI换脸是最早进入公众视野，也是目前应用较多的深度合成形式，可以借助人工智能技术对视频中的人脸进行替换，在一些AI换脸应用中，用户只需上传一张面部照片，就可实现化身电影中的演员、游戏中的角色等效果。除此之外，“人脸再现”涉及对目标人物的脸部表情进行驱动；“人脸合成”涉及创建媲美真实人脸的全新人脸图像；“语音合成”涉及创建特定的声音模型，可以将文字转化成接近真人语调和节奏的声音。同时，深度合成正从局部合成转向全身合成，从二维合成转向3D合成；前者例如对目标人物的全身动作进行操控，后者则以数字虚拟人技术为代表。目前，国内外互联网公司纷纷试水数字虚拟人技术，例如，2018年腾讯携手Epic等企业启动“Siren”虚拟人项目，2019年腾讯AI Lab正式发布首个电竞虚拟人“T.E.G”(天鹅静)，整合3D人脸和人体重建、文本/语音/口型驱动和神经网络渲染等技术，特别是利用生成对抗网络完成人体动作的迁移。随着5G时代的到来，这种捕捉和渲染将会更加灵敏生动，数字虚拟人在游戏、社交、影视、医疗等领域将大有可为。

误解2：任何人都可以制作高质量、高仿真的深度合成内容。
深度合成内容的制作门槛已大为降低，但是高质量、高仿真的深度合成内容的制作还未普遍实现，仍需专业技能和专业工具。相比于PS等传统的图像处理软件，得益于源代码的开放和易用性工具的开发，深度合成技术的使用门槛已大为降低，普通用户在智能手机、电脑等终端设备上，借助深度合成应用程序，即可轻易制作、获取AI换脸、人脸合成、语音合成等娱乐性的深度合成内容。这类合成内容往往较为容易辨别，且存在来源标记，不至以假乱真。因此就目前而言，虽然像FakeApp、ZAO这样的软件已经开始让更多的人接触到深度合成技术，但高质量、高仿真的深度合成内容仍然难以创建，需要掌握专业技能和专业工具的专业人员的大量投入。

误解3：深度合成技术已被大量滥用，用于在社交媒体平台上制作、传播虚假信息。
实际上，无论是在国内还是在国外，社交媒体平台上涉及政治和政治人物的深度合成视频都是很少见的，深度合成性质的虚假信息也很少。此前在国内外引发广泛关注的奥巴马、普京等政治人物的深度合成视频，更多是警示性的和教育性的，意在表明深度合成技术可能出现此类滥用，而非为了传播政治谣言和虚假信息。而且主流社交平台已采取了针对深度合成内容的审核政策，因此深度合成内容并未在社交媒体平台中失控，也并未给公众话语权与社会舆论造成扭曲。但色情性的深度合成视频，是深度合成技术滥用的重灾区，应予以重视，报告显示，2019年12月全网共有14678个深度合成视频，其中96%属于色情性的深度合成视频，主要存在于色情网站。

误解4：快速立法是应对深度合成技术滥用风险的唯一有效方式。
在新技术的治理与风险防范方面，法律规制一直是必不可少的手段，但由于很难识别深度合成内容的来源，立法可能起不到应有的效果，还可能阻碍技术的有益应用与正向发展。因此，立法和监管应当包容审慎，把握合理的限度，避免因矫枉过正而挫伤技术的发展应用从而影响技术的社会经济价值的发挥。更进一步而言，可通过多方参与、风险评估、成本效益分析等机制，确保立法和监管的科学化、精细化、灵活化，并可考虑设立“安全港”规则或者监管例外来鼓励AI应用。当然，立法并非唯一有效的方式，而且具有滞后性，难以跟上技术发展演变的步伐，尤其是对于仍在快速发展的深度合成技术而言；更为合理的路径是，借助鉴别技术、溯源技术等技术措施，要求制作者对深度合成内容进行标记的源头治理，行业公约、标准、最佳实践、伦理指南等行业自律措施，以及公众教育和数字素养的培养等更为敏捷灵活的治理措施，来实现多元治理。

误解5：深度合成内容无法通过技术工具鉴别，只能通过生物特征测试（例如“眨眼测试”）。
实际上，眨眼测试等根据生物特征进行鉴别的方式，是非常低效、不可靠的，只能阶段性地起作用，而且随着深度合成技术的发展进化，生物特征测试越来越难以发挥作用。相反，深度合成内容的检测识别，需要基于AI的鉴别技术，来实现对深度合成内容的自动化检测。目前，随着深度合成技术的进化，学界和业界已在大量投入和支持鉴别技术的开发，但目前的鉴别网络多针对特定的深度合成方法，尚没有通用的鉴别网络，因此AI检测工具需要随时更新。在国内，腾讯优图实验室也在构建人脸合成检测平台——“FaceIn人脸防伪”，并联合腾讯安全平台部AI安全团队Antifakes能力和云鼎实验室的风控和安全能力，在腾讯云慧眼发布了“换脸甄别ATDF”产品，支持对多种换脸方法进行检测，达到了很高的准确率。

误解6：深度合成就是“深度伪造”（deepfake）。
国内媒体一般根据“deepfake”这一合成词，将其背后的技术翻译为“深度伪造”，但“深度伪造”是以偏概全，不足以涵盖所有的深度合成技术和相应的合成内容。追根溯源，deepfake最初只用于描述AI换脸的色情视频，是一种特定的AI换脸技术，后来被媒体拿来泛指所有的深度合成技术，是以偏概全，既不专业，也不科学。因为“深度合成”的内涵更为广泛，意指借助人工智能算法实现语音、音乐、图像、人脸、视频等内容的合成和自动生成，而以“深度伪造”为代表的AI换脸只是其中的一种应用形式而已。此外，“深度伪造”这一不甚科学的术语容易给相应的AI技术造成污名化影响，可能扼杀技术的潜在社会福利，不利于技术发展应用，因为deepfake背后的AI技术具有很大的正向应用价值，如新华社的AI合成主播、网络上的虚拟歌手、社交媒体中的换脸应用等。因此，虽然deepfake的出现让背后的AI技术获得了广泛的关注，但基于技术使用的意图（即deepfake）去定义技术，强调技术的潜在欺骗性或可能带来的负面影响，这一做法并不科学。基于以上考虑，“深度伪造”（deepfake）这一用语实际上并未得到技术社区的广泛认可；相反，使用“深度合成”（deep synthesis）来描述相关的AI技术和合成内容，更为科学合理。

误解7：深度合成是人工智能技术作恶，只会给社会的带来负面影响，没有正向价值。
具备高度仿真能力的深度合成技术，虽然也存在被滥用的风险，但其巨大的正向应用价值将持续带来社会福利，正被广泛应用于影视、娱乐、教育、医疗、社交、电商、内容营销、艺术创作、科研等诸多领域。随着过去几年的发展成熟，深度合成技术在2020年迎来商业化元年，大规模商用成为可能，未来几年将持续涌现创新性的应用形式。例如，在影视作品的后期制作方面，深度合成技术已被用于“数字复活”演员或演员的声音，或者实现多种语言的“数字配音”。亦开始大量涌现AI主播、虚拟歌手、AI换脸、数字虚拟人等社交与内容类应用。在电商领域，深度合成技术可以将用户的脸部换到短的视频片段中，从而让用户在购买前可以实现“数字试穿”。在广告宣传、内容营销等领域，AI合成的人脸和虚拟形象可以替代网红、模特等，既能带来新鲜感，也免去了传统上使用他人肖像的授权。在医疗领域，深度合成技术可以让有失声风险的患者重新获得“自己的声音”，也可以生成与真实影像无异的医学图像来训练AI系统，解决数据不足、病人隐私保护等问题。在语音合成方面，腾讯云上线的语音合成以及实时语音合成技术，可以将任意文本转化为语音，用于新闻、车载导航等个性化语音播报、有声读物制作、机器人发声等。总之，深度合成并非关于“伪造”和“欺骗”的技术，而是极富创造力和突破性的技术，虽然它像其他任何技术一样，也催生了一系列必须面对的难题，但这并不会磨灭这一技术给社会带来的进步。

误解8：互联网行业对深度合成内容呈放任状态。
实际上，互联网行业内的主流网络平台已经着手采取自律措施应对深度合成技术的潜在滥用。谷歌、Facebook等美国主流科技公司已经采取了应对方案，积极开发甄别AI合成内容、对抗深度合成技术滥用的方法和工具，如谷歌开发的“Reality Defender”工具，可扫描用户浏览的图像、视频或其他数字媒介，标记并报告可疑的伪造内容，检测经窜改的人工合成内容；在此基础上降低合成内容的权重，让算法不再为用户推荐被认定为深度合成并可能造成负面影响的内容。利用平台优势，这些科技公司已经在积极构建深度合成数据集，并开放给研究人员免费使用，以此来促进检测技术的研究与开发。同时，各平台之间还携手开展深度合成检测挑战赛，为检测技术的开发提供资金和深度合成数据集，以促进更多检测识别技术的开发。仅2019年，谷歌、Facebook等相继投资此类竞赛，例如Facebook联合微软、美国AI联盟（Partnership on AI）、MIT等九家机构发起的深度合成检测挑战赛（Deepfake Detection Challenge），已取得一定效果。在技术赛道之外，平台也在培训专门的合成内容审查人员，主要目的是增加审核的准确性，特别是在深度合成与戏仿讽刺的界限还难以把握的情况下，需要人工审核的参与，确保内容符合平台的政策要求。在国内，腾讯信息安全团队自研的GFN网络算法鉴别AI换脸，及腾讯优图实验室研发的人脸合成检测技术，对相关深度合成内容的检测都达到了很高的准确率。

误解9： 深度合成已经被国外立法禁止。
实际上，被禁止的不是深度合成技术本身，而是利用此项技术从事色情视频合成、虚假新闻、干扰选举等非法行为。Reddit网站上deepfake论坛关闭、一键裸照应用deepnude下架等事件似乎表明国外对这项技术很不友好，但事实上，国外立法都承认深度合成技术的有益应用和正向价值，没有“一刀切”禁止使用深度合成技术，而是根据使用意图和使用效果进行划分，主要对利用深度合成技术从事的违法行为进行打击，而没有对正常的深度合成技术应用施加过多的限制。例如，美国国会“Deepfakes责任法案”及美国德州、加州、弗吉尼亚州、纽约州的相关法案等只禁止政治干扰、色情报复、假冒身份等目的的深度合成，但没有强制要求平台部署检测识别措施，而是加强源头治理，要求制作者、上传者对深度合成内容添加水印、文字、语音等标记。欧盟则对深度合成技术可能引致的假新闻以及个人信息保护等问题关注度颇高，在考虑用GDPR进行规制的合理性。回到我国，《网络信息内容生态治理规定》第23条、《网络音视频信息服务管理规定》第10-13条、《民法典人格权编（草案）》第799条、《数据安全管理（征求意见稿）》第24条等规定给“深度合成”技术划定了应用边界，同时为行业探索有益应用场景留出了发展空间。

误解10：深度合成会彻底冲击媒体信任。
深度合成技术将如何影响大众的行为和认知，目前还没有足够的研究支持，但是它提示我们，进入人工智能大众化时期，对大众信息分辨能力的培养也是治理的重要一环。以往PS等编辑技术也能进行一定程度的内容合成，但是并未冲击社会的信任，相反社会能很好地适应并使用这一技术。深度合成媒体将比PS等技术更容易操作和使用，随着开源工具的出现，深度合成内容的应用规模和使用范围也将更大，内容的说服力更强。这为识别真实信息与合成内容带来了挑战，在一些报道中，深度合成技术被形容成社会真相的破坏者，认为深度合成技术的存在会导致对媒体信息天然的不信任，公众可以用“deepfake”去怀疑一切他们想怀疑的事物。问题是，在这一技术出现之前，使用传统的音视频剪辑技术，甚至不使用技术手段，通过断章取义等简单方式就可以炮制虚假信息。媒体信任的塑造绝对不仅仅是封杀某一技术可以达到的，而需要从内容的生产、传播、接收等多方面进行规范。深度合成技术的出现已经让我们意识到了眼见不一定为“实”，这是加强公众信息辨别能力的一个重要契机。

注释：文章总结自腾讯研究院、腾讯优图实验室共同完成的报告《AI生成内容发展报告2020——“深度合成”（deep synthesis）商业化元年》。
