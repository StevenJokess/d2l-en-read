

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-12-29 20:48:27
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-12-29 20:51:14
 * @Description:
 * @TODO::
 * @Reference:GAN生成图像综述 - SIGAI的文章 - 知乎
https://zhuanlan.zhihu.com/p/62746494
-->

GAN-图像生成

根据不同的GAN所拥有的生成器和判别器的数量，可以将GAN图像生成的方法概括为三类：直接方法，迭代方法和分层方法[17]。


图三：GAN在图像生成中的三类方法

（1）直接法

早期的GANs都遵循在其模型中使用一个生成器和一个判别器的原理，并且生成器和判别器的结构是直接的，没有分支。如GAN [1]、DCGAN [9]、ImprovedGAN [18]，InfoGAN [15]，f-GAN [19]和GANINT-CLS [20]。这类方法在设计和实现上比较容易，通常也能得到良好的效果。

（2）分层法

分层法的主要思想是将图像分成两部分，如“样式和结构”和“前景和背景”，然后在其模型中使用两个生成器和两个鉴别器，其中不同的生成器生成图像的不同部分，然后再结合起来。两个生成器之间的关系可以是并联的或串联的。

以SS-GAN [21]为例，其使用两个GAN，一个Structure-GAN用于生成表面结构，然后再由Style-GAN补充图片细节，最后生成图片，整体结构如下所示

图四：SS-GAN的分层结构

（3）迭代法

迭代法使用具有相似或甚至相同结构的多个生成器，经过迭代生成从粗到细的图像。

以LAPGAN [22]为例： LAPGAN中的多个生成器执行相同的任务：最低级别的生成器仅将噪声向量作为输入并输出图像，而其他生成器都从前一个生成器获取图像并将噪声矢量作为输入，这些生成器结构的唯一区别在于输入/输出尺寸的大小，每一次迭代后的图像都拥有更多清晰的细节。

图五：LAPGAN的迭代结构

# GAN-图像转换

图像到图像的转换被定义为将一个场景的可能表示转换成另一个场景的问题，例如图像结构图映射到RGB图像，或者反过来。该问题与风格迁移有关，其采用内容图像和样式图像并输出具有内容图像的内容和样式图像的样式的图像。图像到图像转换可以被视为风格迁移的概括，因为它不仅限于转移图像的风格，还可以操纵对象的属性

图像到图像的转换可分为有监督和无监督两大类，根据生成结果的多样性又可分为一对一生成和一对多生成两类：

（1）有监督下图像到图像转换（paired image translation）

如果引入图片作为监督信息，cGAN就可以完成一些paired data才能完成的任务，如把轮廓图转化成真实图片，把mask转化成真实图，把黑白图转化成真实图等。其中最具代表性的工作为pix2pix[23]：

（2）无监督的图像到图像转换（unpaired image translation）
虽然有监督下图像转换可以得到很好的效果，但需要的条件信息以及paired image成为其很大的限制。但如果用无监督学习，学习到的网络可能会把相同的输入映射成不同的输出，这就意味着，我们输入任意 [公式] 并不能得到想要的输出 [公式] 。

CycleGAN [24]、DualGAN [25] 和DiscoGAN [26]突破了这个限制，这几项工作都提出了一致/重构损失（consistent loss），采取了一个直观的思想：即生成的图像再用逆映射生成回去应该与输入的图像尽可能接近。在转换中使用两个生成器和两个判别器，两个生成器 [公式] 和 [公式] 进行相反的转换，试图在转换周期后保留输入图像。

以CycleGAN为例，在CycleGAN中，有两个生成器， [公式] 用于将图像从域X传输到Y，[公式] 用于执行相反的转换。此外，还有两个判别器[公式] 和 [公式] 判断图像是否属于该域。

图九：cycleGAN结构

其Consistent loss由L1进行描述：

（3）从一对一生成到一对多生成（one-to-many translation）

从pix2pix[23]到CycleGAN系列[24][25][26]，再到UNIT[27]，这些方法实现的image-to-image translation不管是有监督的还是无监督的，都是一对一的，也就是说输入一张图片只能产生一种风格，缺乏多样性。但其实大多数情况下，image translation是多对多的，也就是一张图片对应不同风格的转换图片。比如我们设计衣服时，一张轮廓图其实可以设计成不同风格的衣服。再比如同一个场景，不同的光照条件就是一个模式，不一定只有白天和黑夜，还可能有傍晚，清晨等。

BicycleGAN[28]首先对此进行了尝试，其在模型中添加随机噪声，通过随机采样使噪声得到不同的表达，并在输出与潜在空间上添加双向映射。双向映射指的是：不仅仅可以由潜在编码映射得到输出也可以由输出反过来生成对应的潜在编码，这可以防止两个不同的潜在编码生成同样的输出，避免输出的单一性。

但直接用不同的随机噪声来产生多样化的结果，由于mode collapse的存在，很容易训练失败。MUNIT[29]和DRIT[30]在UNIT的基础上，将latent code进一步细化为内容编码 c 和风格编码 s 。不同domain的图像共享内容编码空间 C 而独享风格编码空间 S ，将内容编码c与不同的风格编码s结合起来就能得到更鲁棒的多样性的结果。

