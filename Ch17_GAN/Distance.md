

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-12-26 20:39:05
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-12-26 20:39:28
 * @Description:
 * @TODO::
 * @Reference:https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247484880&idx=1&sn=4b2e976cc715c9fe2d022ff6923879a8&chksm=96e9da50a19e5346307b54f5ce172e355ccaba890aa157ce50fda68eeaccba6ea05425f6ad76&scene=21#wechat_redirect
-->
拟合什么目标呢？我们怎么知道 Y=G(X,θ) 跟指定的分布是很接近的呢？



 4

KL 距离？JS 距离？



让我们把问题再理清楚一下：我们现在有一批服从某个指定分布的数据 Z=(z1,z2,…,zN)，我们希望找到一个神经网络 Y=G(X,θ)，将均匀随机数 X 映射到这个指定分布中来。



需要特别指出，我们是要比较两个分布的接近程度，而不是比较样本之间的差距。通常来说，我们会用 KL 距离来描述两个分布的差异：设 p1(x),p2(x) 是两个分布的概率密度（当然，还有其他距离可以选择，比如 Wasserstein 距离，但这不改变下面要讨论的内容的实质），那么：



图片



如果是离散概率，则将积分换成求和即可。KL 距离并非真正的度量距离，但是它能够描述两个分布之间的差异，当它是 0 时，表明两个分布一致。但因为它不是对称的。有时候将它对称化，得到 JS 距离：



图片



咦？怎么又回到概率密度了？不是说没给出概率密度吗？没办法，公式就是这样，只好估算一下咯。假设我们可以将实数域分若干个不相交的区间 I1,I2,…,IK，那么就可以估算一下给定分布 Z 的概率分布。



图片



其中 #(zj∈Ii) 表示如果 zj∈Ii，那么取值为 1，否则为 0，也就是说大家不要被公式唬住了，上式就是一个简单的计数函数，用频率估计概率罢了。



接着我们生成 M 个均匀随机数 x1,x2,…,xM（这里不一定要 M=N，还是那句话，我们比较的是分布，不是样本本身，因此多一个少一个样本，对分布的估算也差不了多少。），根据 Y=G(X,θ) 计算对应的 y1,y2,…,yM，然后根据公式可以计算：



图片



现在有了 pz(Ii) 和 py(Ii)，那么我们就可以算它们的差距了，比如可以选择 JS 距离：



图片



注意 yi 是由 G(X,θ) 生成的，所以 py(Ii) 是带有参数 θ 的，因此可以通过最小化 Loss 来得到参数 θ 的最优值，从而决定网络 Y=G(X,θ)。



 5

神经距离



假如我们只研究单变量概率分布之间的变换，那上述过程完全够了。然而，很多真正有意义的事情都是多元的，比如在 MNIST 上做实验，想要将随机噪声变换成手写数字图像。要注意 MNIST 的图像是 28*28=784 像素的，假如每个像素都是随机的，那么这就是一个 784 元的概率分布。按照我们前面分区间来计算 KL 距离或者 JS 距离，哪怕每个像素只分两个区间，那么就有 2784≈10236 个区间，这是何其巨大的计算量！



终于，有人怒了：“老子干嘛要用你那逗比的 JS 距离，老子自己用神经网络造一个距离！”于是他写出带参数 Θ 的神经网络：



图片



也就是说，直接将造出来的 yi 和真实的 zi 都放进去这个神经网络一算，自动出来距离，多方便。这个思想是里程碑式的，它连距离的定义都直接用神经网络学了，还有什么不可能学的呢？



我们来看看，要是真有这么个 L 存在，它应该是怎么样的？首先，对于特定的任务来说，图片是给定的，因此它并非变量，我们可以把它当做模型本身的一部分，因此简写成：



图片



接着，别忘记我们是描述分布之间的距离而不是样本的距离，而分布本身跟各个 yi 出现的顺序是没有关系的，因此分布之间的距离跟各个 yi 出现的顺序是无关的，也就是说，尽管 L 是各个 yi 的函数，但它必须全对称的！这是个很强的约束，当然，尽管如此，我们的选择也有很多，比如：



图片



也就是说，我们先找一个有序的函数 D，然后对所有可能的序求平均，那么就得到无序的函数了。当然，这样的计算量是 𝒪(M!)，显然也不靠谱，那么我们就选择最简单的一种：


图片



这便是无序的最简单实现，可以简单的理解为：分布之间的距离，等于单个样本的距离的平均。
