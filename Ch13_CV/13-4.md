

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-07-30 17:45:23
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-07-30 18:34:15
 * @Description:MT
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_computer-vision/anchor.html
-->

# 锚箱

目标检测算法通常对输入图像中的大量区域进行采样，确定这些区域是否包含感兴趣的目标，并调整这些区域的边缘，以便更准确地预测目标的地面真实包围盒。不同的模型可以使用不同的区域抽样方法。在这里，我们介绍一种这样的方法: 它生成多个包围盒不同的大小和宽高比，同时对每个像素中心。这些包围盒叫做锚定盒。我们将在下面的章节中实践基于锚定框的目标检测。

首先，导入本节所需的包或模块。在这里，我们修改了 NumPy 的打印精度。因为打印张量实际上调用了 NumPy 的打印函数，所以本节中打印的张量中的浮点数更简洁。

TODO:CODE

## 生成多个锚定框

假设输入图像的高度为 h，宽度为 w。我们生成以图像的每个像素为中心的不同形状的锚定框。假设尺寸为 s ∈(0,1] ，纵横比为 r > 0，锚箱的宽度和高度分别为 ws √ r 和 hs/√ r。当中心位置给定时，确定已知宽度和高度的锚箱。

下面我们设置一组尺寸 s1，... ，sn 和一组长宽比 r1，... ，rm。如果我们以每个像素为中心，使用所有尺寸和长宽比的组合，输入图像将有个 whnm 锚盒。虽然这些锚盒可能涵盖所有地面真理包围盒，计算的复杂性往往是过度的。因此，我们通常只对包含 s1或 r1大小和长宽比的组合感兴趣，即:

TODO:MATH

也就是说，以同一像素为中心的锚定框的数量为 n + m-1。对于整个输入图像，我们将生成 wh (n + m-1)锚定框。

上述生成锚箱的方法已在 multibox _ prior 函数中实现。我们指定输入、一组大小和一组纵横比，这个函数将返回所有输入的锚定框。

TODO:CODE

我们可以看到返回的锚定框变量 y 的形状是(批量大小，锚定框的数量，4)。将锚定框变量 y 的形状改为(图像高度、图像宽度、以同一像素为中心的锚定框数目，4)后，可以得到所有以指定像素位置为中心的锚定框。在下面的示例中，我们访问以(250,250)为中心的第一个锚定框。它有四个元素: 左上角的 x、 y 轴坐标和锚定框右下角的 x、 y 轴坐标。X 轴和 y 轴的坐标值分别除以图像的宽度和高度，因此该值范围介于0和1之间。

为了描述图像中以一个像素为中心的所有锚定框，我们首先定义 show _ bboxes 函数在图像上绘制多个边界框。

TODO:CODE

就像我们刚刚看到的那样，变量框中xx和yy轴的坐标值已分别除以图像的宽度和高度。绘制图像时，我们需要恢复锚框的原始坐标值，并因此定义变量bbox_scale。现在，我们可以绘制图像中以（250，250）为中心的所有锚点框。如您所见，大小为0.75，宽高比为1的蓝色锚框很好地覆盖了图像中的狗。

TODO:CODE

## 相交除以相并

我们刚刚提到，锚框很好地覆盖了图像中的狗。如果已知目标的真实边界框，那么如何量化“好”呢？ 一种直观的方法是测量锚定框与地面真实边界框之间的相似度。我们知道，Jaccard索引可以衡量两个集合之间的相似性。给定AA和BB集，它们的Jaccard索引是它们的交集大小除以它们的并集大小：

TODO:MATH

实际上，我们可以将边界框的像素区域视为像素的集合。这样，我们可以通过两个边界盒的像素集Jaccard index来衡量它们的相似度。在衡量两个边界盒的相似度时，我们通常将Jaccard index称为相交于并集(cross over union, IoU)，即两个边界盒的相交面积与并集面积之比，如图13.4.1所示。IoU的取值范围在0到1之间，0表示两个边界盒之间没有重叠像素，1表示两个边界盒相等。

图13.4.1 IoU为相交区域与两个边界框合并区域的比率

在本节的剩余部分中，我们将使用IoU来度量锚盒和地面真边界盒之间以及不同锚盒之间的相似性。

## 标签训练设置锚盒

在训练集中，我们将每个锚框作为一个训练例子。为了训练目标检测模型，我们需要为每个锚盒标记两种标签:一是锚盒中所包含目标的类别(category)，二是地真边界盒相对于锚盒的偏移量(offset)。在目标检测中,我们首先生成多个锚盒子,预测每个锚箱的类别和补偿,根据预测调整锚箱位置偏移得到边界框用于预测,最后过滤预测边界框需要输出。

我们知道，在目标检测训练集中，每幅图像都被标记上了地真边界盒的位置和所包含目标的类别。在锚框生成后，我们主要根据与锚框类似的地真边界框的位置和类别信息对锚框进行标签。那么我们如何将地面真值边界盒分配给与之相似的锚盒呢?

假设图像中的锚点框为A1，A2，...，AnaA1，A2，...，Ana，地面真实边界框为B1，B2，...，BnbB1，B2，...，Bnb和na≥nbna≥nb。定义矩阵X∈Rna×nbX∈Rna×nb，其中第i行和第jthjth列中的元素xijxij是锚点框AiAi到地面真相边界框BjBj的IoU。首先，我们在矩阵XX中找到最大的元素，并将该元素的行索引和列索引记录为i1，j1i1，j1。我们将真实边界框Bj1Bj1分配给锚框Ai1Ai1。显然，锚框Ai1Ai1与地面真相边界框Bj1Bj1在所有“锚框-地面真相边界框”配对中具有最高的相似性。接下来，丢弃矩阵XX中第i1i1行和第j1j1列中的所有元素。在矩阵XX中找到最大的剩余元素，并将该元素的行索引和列索引记录为i2，j2i2，j2。我们将真实边界框Bj2Bj2分配给锚定框Ai2Ai2，然后丢弃矩阵XX中第i2i2行和第j2j2列中的所有元素。此时，矩阵XX中两行两列的元素已被丢弃。

我们继续进行，直到矩阵XX中nbnb列中的所有元素都被丢弃。目前，我们已经为每个nbnb锚定框分配了一个真实的边界框。接下来，我们仅遍历其余的na-nbna-nb锚框。给定锚定框AiAi，根据矩阵XX的第i行找到具有最大IoU的边界框BjBj和AiAi，仅当IoU大于预定阈值时才将真相边界框BjBj分配给锚定框AiAi。

如图13.4.2（左）所示，假设矩阵XX中的最大值为x23x23，我们将把真实边界框B3B3分配给锚点框A2A2。然后，我们丢弃矩阵第2行和第3列中的所有元素，找到剩余阴影区域中最大的元素x71x71，并将真相边界框B1B1分配给锚定框A7A7。然后，如：numref：fig_anchor_label（中间）所示，丢弃矩阵第7行和第1列中的所有元素，找到剩余阴影区域中最大的元素x54x54，然后将真实边界框B4B4分配给锚定框A5A5 。最后，如：numref：fig_anchor_label（右）所示，丢弃矩阵第5行和第4列中的所有元素，找到剩余阴影区域中最大的元素x92x92，然后将真实边界框B2B2分配给锚定框A9A9 。之后，我们只需要遍历A1，A3，A4，A6，A8A1，A3，A4，A6，A8的其余锚框，并根据阈值确定是否将地面真相边界框分配给其余锚框。

图13.4.2将地面真值边界盒分配给锚盒。

现在我们可以标记锚框的类别和偏移量。如果将一个锚框AA赋值为地真边界盒BB，则将锚框AA的类别设置为BB的类别。根据BB和AA的中心坐标的相对位置和两个盒子的相对大小来设置AA锚框的偏移量。由于数据集中不同盒子的位置和大小可能不同，这些相对位置和相对大小通常需要一些特殊的转换，以使偏移分布更加统一和更容易适应。假设锚点盒AA及其指定的地真边界盒BB的中心坐标为(xa,ya)、(xb,yb)(xa,ya)、(xb,yb)， AA和BB的宽度分别为wa、wbwa、wb，高度分别为ha、hbha、hb。在这种情况下，一种常见的技术是将AA的偏移量标记为

TODO:MATH

常数的默认值为μx=μy=μw=μh= 0，σx=σy= 0.1，并且σw=σh=0.2μx=μy=μw=μh= 0，σx=σy= 0.1，并且σw=σh= 0.2。如果未为锚定框分配地面真实边界框，则只需将锚定框的类别设置为背景。类别为背景的锚框通常称为负锚框，其余的称为正锚框。

下面我们演示一个详细的示例。我们在读取的图像中为猫和狗定义了地面真相边界框，其中第一个元素是类别（0为dog，1为cat），其余四个元素为左上角的x，yx，y轴坐标 角和x，yx，y轴坐标在右下角（值范围在0和1之间）。在这里，我们构造了五个锚点框，分别用左上角和右下角的坐标标记，分别记录为A0，...，A4A0，...，A4（程序的索引从0开始 ）。首先，在图像中绘制这些锚框和地面真相边界框的位置。

TODO:CODE

我们可以使用multibox_target函数为锚框标记类别和偏移量。此函数将背景类别设置为0，并将目标类别的整数索引从零递增1（对于狗是1，对于猫是2）。我们将示例维添加到锚定框和地面真相边界框，并通过使用expand_dims函数构造形状为（批量大小，类别数（包括背景），锚定框的数量）的随机预测结果。

TODO:CODE

返回结果中有三个项目，所有项目均为张量格式。第三项由标记为锚框的类别表示。

TODO:CODE

我们基于图像中锚点框和地面真实边界框的位置来分析这些标记的类别。首先，在所有“锚定框-地面真相边界框”对中，锚定框A4A4与猫的地面真相边界框的IoU最大，因此锚定框A4A4的类别被标记为cat。在不考虑猫的锚定框A4A4或地面真相边界框的情况下，在其余的“锚定框-地面真相边界框”对中，IoU最大的对是锚定框A1A1和猫的地面真相边界框。狗，因此锚定框A1A1的类别被标记为狗。接下来，遍历其余三个未标记的锚框。IoU最大且锚点框为A0A0的地面真相边界框的类别为dog，但IoU小于阈值（默认值为0.5），因此将该类别标记为背景； IoU最大且锚点框为A2A2的地面真相边界框的类别为cat，且IoU大于阈值，因此将该类别标记为cat； IoU最大且带有锚定框A3A3的地面真相边界框的类别为cat，但是IoU小于阈值，因此将该类别标记为背景。

返回值的第二项是掩码变量，其形状为（批量大小，为锚框数量的四倍）。mask变量中的元素与每个锚点框的四个偏移值一一对应。因为我们不在乎背景检测，所以负类的偏移量不应影响目标函数。通过乘以元素，掩码变量中的0可以在计算目标函数之前滤除负类偏移。

TODO:CODE

返回的第一项是为每个锚框标记的四个偏移值，负类锚框的偏移标记为0。

TODO:CODE

## 预测的边界框

在模型预测阶段，我们首先为图像生成多个锚定框，然后逐一预测这些锚定框的类别和偏移量。然后，我们基于锚框及其预测的偏移量获得预测边界框。当锚框很多时，可以为同一目标输出许多相似的预测边界框。为了简化结果，我们可以删除类似的预测边界框。常用的方法称为非最大抑制（NMS）。

让我们看一下NMS的工作原理。对于预测边界框BB，模型计算每个类别的预测概率。假设最大预测概率为pp，则与该概率对应的类别为BB的预测类别。我们也将pp称为预测边界框BB的置信度。在同一幅图像上，我们按从高到低的置信度对除背景以外的预测类别的预测边界框进行排序，并获得列表LL。从LL中选择具有最高置信度的预测边界框B1B1作为基线，并从I中移除IoU且B1B1大于某个阈值的所有非基准预测边界框。此处的阈值是预设的超参数。此时，LL保留具有最高置信度的预测边界框，并删除与其类似的其他预测边界框。接下来，从LL中选择具有第二高置信度的预测边界框B2B2作为基线，并从LL中删除IoU且B2B2大于特定阈值的所有非基准预测边界框。重复此过程，直到将LL中的所有预测边界框都用作基线为止。此时，LL中的任何一对预测边界框的IoU都小于阈值。最后，输出列表LL中的所有预测边界框。

接下来，我们将看一个详细的示例。首先，构造四个锚框。为了简单起见，我们假设预测的偏移量均为0。这意味着预测边界框是锚点框。最后，我们为每个类别构造一个预测概率。

TODO:CODE

打印预测边框及其在图像上的置信度。

TODO:CODE

我们使用multibox_detection函数来执行NMS，并将阈值设置为0.5。这给输入张量增加了一个维数。我们可以看到返回结果的形状为(批大小，锚框数量，6)，每行的6个元素代表同一个预测边框的输出信息。第一个元素是预测的类别索引，从0开始(0是dog, 1是cat)。值-1表示NMS中的背景或删除。第二个要素是预测边界盒的置信度。其余四个元素分别为预测边框左上角的x、yx、y轴坐标和右下角的x、yx、y轴坐标(取值范围为0 ~ 1)。

TODO:CODE

我们去掉类别-1的预测边框，将NMS保留的结果可视化。

TODO:CODE

在实践中，我们可以在执行NMS之前移除具有较低置信级别的预测边界盒，从而减少NMS的计算量。我们还可以过滤NMS的输出，例如，只保留具有较高可信度的结果作为最终输出。

## 小结

* 我们生成不同大小和长宽比的多个锚定框，以每个像素为中心。
* IoU，也被称为Jaccard指数，衡量两个边界框的相似性。它是两个边界盒的相交面积与并集面积之比。
* 在训练集中，我们为每个锚框标记两种标签:一种是锚框中所包含目标的类别，另一种是地真边界盒相对于锚框的偏移量。
* 在预测时，我们可以使用非最大抑制(NMS)来去除类似的预测边界框，从而简化结果。

## 练习

1. 在multibox_prior函数中更改大小和比率值，并观察对生成的锚框的更改。
1. 构造两个边界框，且IoU为0.5，并观察它们的巧合。
1. 通过标记本节中定义的锚框偏移量来验证偏移量标签[0]的输出（常数为默认值）。
1. 在“标签训练集锚框”和“预测输出边界框”部分中修改变量锚。结果如何变化？
