

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-14 23:03:13
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-14 23:17:30
 * @Description:
 * @TODO::
 * @Reference:
-->

# 在 Kaggle的狗的品种鉴定(ImageNet Dogs)

在这一部分，我们将处理犬种鉴定的挑战在 Kaggle 竞赛。竞赛的网址是

https://www.kaggle.com/c/dog-breed-identification

在这个比赛中，我们试图鉴定120种不同品种的狗。本次比赛使用的数据集实际上是著名的 ImageNet 数据集的子集。与前一节中使用的 CIFAR-10数据集中的图像不同，ImageNet 数据集中的图像越来越高，越来越宽，而且维数不一致。

图13.14.1显示了比赛网页上的信息。为了提交结果，请先在 Kaggle 网站注册一个帐号。

图13.14.1犬种鉴定比赛网站。可点击“数据”标签进入比赛数据集。

首先，导入竞赛所需的软件包或模块。

TODO:CODE

## 获取和组织数据集

将比赛数据分为训练集和测试集。训练集包含10,22210,222张图像，测试集包含10,35710,357张图像。两套图像均为 JPEG 格式。这些图像包含三个 RGB 通道(颜色) ，它们有不同的高度和宽度。在训练集中有120种狗，包括拉布拉多犬、贵宾犬、腊肠犬、萨摩耶犬、爱斯基摩犬、吉娃娃和约克夏梗。

## 下载数据集

登入 Kaggle 后，我们可点击图13.14.1所示的狗只品种鉴定比赛网页上的「资料」标签，然后点击「全部下载」按钮下载数据集。将下载的文件解压缩到。./data，你可以通过以下路径找到整个数据集:

* ../data/dog-breed-identification/labels.csv
* ../data/dog-breed-identification/sample_submission.csv
* ../data/dog-breed-identification/train
* ../data/dog-breed-identification/test

您可能已经注意到，上述结构与第13.13节中的 CIFAR-10竞赛非常相似，其中文件夹分别训练/测试/包含训练和测试狗图像，labels.csv 为训练图像提供标签。

类似地，为了更容易入门，我们提供了上面提到的数据集的小规模样本，“ train _ valid _ test _ tiny”。“ zip”。如果你打算在 Kaggle 竞赛中使用完整的数据集，你还需要将下面的演示变量更改为 False。

## 组织数据集

我们可以像在13.13节中那样组织数据集，即将验证集与训练集分离，并将图像移动到按标签分组的子文件夹中。

下面的 reorg _ dog _ data 函数用于读取培训数据标签、分割验证集和组织培训集。

TODO:CODE

## 图像增强

本节中图像的尺寸大于上一节中的图像。这是一些可能有用的其他图像增强操作。

TODO:CODE

在测试期间，我们仅使用确定的图像预处理操作。

TODO:CODE

## 读取数据集

如上一节所述，我们可以创建一个ImageFolderDataset实例来读取包含原始图像文件的数据集。

TODO:CODE

在此，我们创造了`DataLoader`例，就像在13.13节一样。

TODO:CODE

## 定义模型

该比赛的数据集是ImageNet数据集的子集。因此，我们可以使用第13.2节中讨论的方法来选择在整个ImageNet数据集上进行预训练的模型，并使用它来提取要输入到自定义小规模输出网络中的图像特征。Gluon提供了广泛的预训练模型。在这里，我们将使用预训练的ResNet-34模型。由于比赛数据集是预训练数据集的子集，因此我们只需重复使用预训练模型输出层的输入，即提取的要素即可。然后，我们可以用可以训练的小型自定义输出网络来替换原始输出层，例如一系列中的两个完全连接的层。与第13.2节中的实验不同，在这里，我们不对用于特征提取的预训练模型进行重新训练。这减少了训练时间和存储模型参数梯度所需的内存。

您必须注意，在图像增强期间，我们对整个ImageNet数据集使用三个RGB通道的平均值和标准偏差进行归一化。这与预训练模型的规范化是一致的。

TODO:CODE

在计算损失时，我们首先使用成员变量特征来获取经过预训练的模型输出层的输入，即提取的特征。然后，我们将此功能用作小型自定义输出网络的输入并计算输出。

TODO:CODE

## 定义训练函数

我们将根据模型在验证集上的性能选择模型并调整超参数。模型训练函数只训练小型自定义输出网络。

TODO:CODE

## 训练和验证模型

现在，我们可以训练并验证这个模型。可以调优以下超参数。例如，我们可以增加纪元的数目。因为lr_period和lr_decay分别被设置为10和0.1，所以优化算法的学习率将在每10个epoch之后乘以0.1。

## 对测试集进行分类并在Kaggle上提交结果

获得令人满意的模型设计和超参数后，我们使用所有训练数据集（包括验证集）对模型进行再训练，然后对测试集进行分类。请注意，预测是由我们刚刚训练的输出网络做出的。

TODO:CODE

执行完以上代码后，我们将生成一个“ submission.csv”文件。该文件的格式与Kaggle竞赛要求一致。提交结果的方法类似于4.10节中的方法。

## 小结

* 我们可以使用一个在ImageNet数据集上预先训练好的模型来提取特征，只训练一个小的自定义输出网络。这将允许我们以较低的计算和存储开销对ImageNet数据集的子集进行分类。

## 练习

1. 当使用整个Kaggle数据集时，增加batch_size(批大小)和num_epoch(批数)会得到什么样的结果?
2. 如果你使用更深层次的预训练模型，你会得到更好的结果吗?
3. 扫描二维码访问相关讨论，并与社区交流使用的方法和获得的结果。你能想出更好的方法吗?
