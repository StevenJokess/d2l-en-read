

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-07-30 19:36:57
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-12-21 23:57:19
 * @Description:MT, improve
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_computer-vision/fcn.html
 * http://preview.d2l.ai/d2l-en/PR-1566/chapter_computer-vision/fcn.html
-->

# 全卷积网络(FCN)

我们先前讨论了使用图像中的每个像素进行语义分割的类别预测。一个完全卷积网络(FCN)[ Long et al. ，2015]使用卷积神经网络转换器将图像像素转换为像素类别。与之前介绍的卷积神经网络不同，FCN 通过转换卷积层将中间层特征映射的高度和宽度转换回输入图像的大小，因此预测的空间维度(高度和宽度)与输入图像有一个双射。给定空间维度上的一个位置，通道维度的输出将是与该位置对应的像素的类别预测。

我们将首先导入实验所需的封装或模块，然后解释转置卷积层。

TODO:CODE

## 建立一个模型

在这里，我们演示了一个完全卷积网络模型的最基本的设计。如图13.11.1所示，完全卷积网络首先使用卷积卷积神经网络提取图像特征，然后通过1111卷积层将通道数转换为类别数，最后使用转换卷积层将特征映射的高度和宽度转换为输入图像的大小。模型输出具有与输入图像相同的高度和宽度，并且在空间位置上有一个双射。最终输出通道包含相应空间位置像素的类别预测。

图13.11.1全卷积网络。

下面，我们使用对 ImageNet 数据集进行预训练的 ResNet-18模型来提取图像特征，并将网络实例记录为预训练网。正如您所看到的，模型成员变量特性的最后两层是全局最大池层 GlobalAvgPool2D 和实例扁平化层 Flatten。输出模块包含用于输出的完全连接层。完全卷积网络不需要这些层。

TODO:CODE

接下来，我们创建完全卷积的网络实例网。它复制了除预训练网络的实例成员变量特征的最后两层和预训练后获得的模型参数之外的所有神经层。

TODO:CODE

如果输入的高度和宽度分别为320和480，网的正向计算将把输入的高度和宽度减少到原来的1/321/32，即10和15。

TODO:CODE

接下来，我们通过1×11卷积层将输出通道数转换为Pascal VOC2012(21)的类别数。最后，我们需要将feature map的高度和宽度放大32倍，以将其恢复为输入图像的高度和宽度。回想一下第6.3节中描述的卷积层输出形状的计算方法。由于(320−64+16×2+32)/32=10，(480−64+16×2+32)/32=15，我们构造一个步长为32的转置卷积层，将卷积核的高度和宽度设为64，填充设为16。不难看到,如果跨越党卫军,填充是s / 22(假设s / 2是一个整数),和卷积核的高度和宽度是2s,转置卷积内核将放大两输入的高度和宽度的因素党卫军。

TODO:CODE

## 初始化转置卷积层

我们已经知道，转置卷积层可以放大一个特征图。在图像处理中，有时需要对图像进行放大处理。,upsampling。上采样的方法有很多，最常用的方法是双线性插值。简单地说，为了得到输出图像在坐标(x,y)(x,y)处的像素，首先将坐标映射到输入图像的坐标(x '，y ')(x '，y ')。这可以根据三个输入的大小与输出的大小的比率来完成。映射的值x ' x '和y ' y '通常是实数。然后，我们找到在输入图像上最接近坐标(x '，y ')(x '，y ')的四个像素。最后，根据输入图像上的这四个像素以及它们到(x '，y ')(x '，y ')的相对距离计算输出图像在坐标(x,y)(x,y)处的像素。双线性插值上采样可以通过以下双线性核函数构造的卷积核的转置卷积层来实现。由于篇幅的限制，我们只给出双内核函数的实现，而不讨论算法的原理。

TODO:CODE

现在，我们将用双线性插值上采样进行实验，通过转置卷积层来实现。构造一个转置卷积层，将输入的高度和宽度放大2倍，并用bilinear_kernel函数初始化它的卷积核。

TODO:CODE

读取图像X，将上采样结果记录为y，为了打印图像，我们需要调整通道尺寸的位置。

TODO:CODE

正如你所看到的，卷积层将图像的高度和宽度都放大了2倍。值得一提的是，通过双线性插值放大的图像除了坐标比例不同之外，与13.3中打印的原始图像是相同的。

TODO:CODE

在全卷积网络中，我们初始化了上采样双线性插值的转置卷积层。对于1×1卷积层，我们使用Xavier进行随机初始化。

TODO:CODE

## 读取数据集

我们使用上一节中介绍的方法读取数据集。在这里，我们将随机裁剪的输出图像的形状指定为320×480，因此高度和宽度都可以被32整除。

TODO:CODE

## 训练

现在我们可以开始训练模型了。这里的损失函数和精度计算与图像分类中使用的没有本质区别。因为我们使用了转置卷积层的通道来预测像素类别，所以在SoftmaxCrossEntropyLoss中指定了axis=1(通道维数)选项。另外，模型根据每个像素的预测类别是否正确来计算精度。

TODO:CODE

## 预测

在预测时，我们需要对每个通道的输入图像进行标准化，将其转换为卷积神经网络所需的四维输入格式。

TODO:CODE

为了使每个像素的预测类别可视化，我们将预测类别映射回数据集中它们的标记颜色。

TODO:CODE

测试数据集中图像的大小和形状各不相同。由于模型使用了一个步长为32的转置卷积层，当输入图像的高度或宽度不能被32整除时，转置卷积层输出的高度或宽度偏离了输入图像的大小。为了解决这个问题，我们可以在图像中裁剪多个高度和宽度为32的整数倍数的矩形区域，然后对这些区域中的像素进行正演计算。当合并时，这些区域必须完全覆盖输入图像。当一个像素被多个区域覆盖时，可以将不同区域前向计算中转置卷积层输出的平均值作为softmax操作的输入，用于预测类别。

为了简单起见，我们只读取几张较大的测试图像，然后从图像左上角裁剪一个形状为320×480的区域。只有这个区域用于预测。对于输入图像，我们首先打印裁剪区域，然后打印预测结果，最后打印标注的类别。

TODO:CODE

## 小结

* 完全卷积网络第一次使用卷积神经网络提取图像特征,然后转换频道的数量成类别的数量通过卷积1×11×1层,最后转换的高度和宽度特征映射到输入图像的大小采用转置卷积层输出每个像素的范畴。

* 在全卷积网络中，我们初始化了上采样双线性插值的转置卷积层。

## 练习

1. 如果我们用Xavier随机初始化转置的卷积层，结果会怎样?
1. 你能通过调整超参数来进一步提高模型的准确性吗?
1. 预测测试图像中所有像素的类别。
1. 在全卷积网络[1]中，也使用了卷积神经网络中间层的输出。试着实现这个想法。
