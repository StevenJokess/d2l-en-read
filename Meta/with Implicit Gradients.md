

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-11-08 16:42:42
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-11-08 16:43:27
 * @Description:
 * @TODO::
 * @Reference:
-->

从理论上，我们证明了隐式MAML可以计算精确的元梯度，其内存占用不超过计算单个内循环梯度所需的内存占用，且不增加总计算成本。实验表明，隐式MAML的这些优点可以转化为基于少量样本图像识别基准的经验增益。

[1]: https://taylorliu.com/rl/meta-learning/
[2]: http://arxiv.org/abs/1909.04630
