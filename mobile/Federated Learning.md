

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-19 18:31:53
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-10-19 18:32:23
 * @Description:
 * @TODO::
 * @Reference:
-->

# 联邦学习（Federated Learning）

联邦学习（又称协作学习）是一种机器学习技术， 2016 年由谷歌最先提出，它在多个持有本地数据样本的分散式边缘设备或服务器上训练算法，而不交换其数据样本。这种方法与传统的集中式机器学习技术形成鲜明对比，传统的集中式机器学习技术将所有的数据样本上传到一个服务器上，而更经典的去中心化方法则假设本地数据样本是完全相同分布的。

联邦学习能够使多个参与者在不共享数据的情况下建立一个共同的、强大的机器学习模型，从而解决数据隐私、数据安全、数据访问权限和异构数据的访问等关键问题。其应用遍布国防、电信、物联网或制药等多个行业。

联邦学习原本用于解决安卓手机终端用户在本地更新模型的问题，其设计目标是在保障大数据交换时的信息安全、保护终端数据和个人数据隐私、保证合法合规的前提下，在多参与方或多计算结点之间开展高效率的机器学习。其中，联邦学习可使用的机器学习算法不局限于神经网络，还包括随机森林等重要算法。联邦学习有望成为下一代人工智能协同算法和协作网络的基础。

[1]: https://www.aminer.cn/ai-history
