

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-30 20:29:13
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-08-21 18:47:16
 * @Description:MT, improve
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_recommender-systems/deepfm.html
-->

# 深度因子分解机

学习有效的特征组合对于点进率预测任务的成功至关重要。因子分解机器模型以线性范式表示交互作用(例如，双线性交互)。这通常不足以满足真实世界数据的需要，因为固有的特征交叉结构通常是非常复杂和非线性的。更糟糕的是，在实际的因子分解机器中，二阶特征交互通常被使用。用因子分解机构建高度特征组合在理论上是可行的，但由于数值不稳定和计算复杂度高，一般不采用这种方法。

一个有效的解决方案是使用深层神经网络。深层神经网络在特征表征学习方面非常强大，并且有潜力学习复杂的特征相互作用。因此，将深层神经网络集成到因式分解机器是很自然的。向因子分解机器中添加非线性转换层，使其能够对低阶特征组合和高阶特征组合进行建模。此外，来自输入的非线性固有结构也可以用深层神经网络捕获。在这一部分中，我们将介绍一个具有代表性的模型——深度因子分解机(DeepFM)[Guo et al., 2017] ，它结合了因子分解机和深度神经网络。

## 模型架构

深度因子分解机由因子分解机和深度两部分组成并行结构。FM 组件与用于建模低阶特征交互的双向因子分解机器相同。深度分量是一个多层感知器，用于捕获高阶特征交互和非线性。这两个组件共享相同的输入/嵌入，它们的输出被总结为最终预测。值得指出的是，深度调频的精神类似于宽深结构，既能记忆，又能概括。DeepFM 相对于 Wide & Deep 模型的优势在于，它通过自动识别特征组合，减少了手工特征工程的工作量。

为简便起见，我们省略了 FM 组件的描述，并将输出表示为 y^(FM)。更多细节请参阅最后一节。设 ei∈Rk 为第 i 域的潜在特征向量。深度分量的输入是所有字段的稠密嵌入的串联，这些字段用稀疏的分类特征输入进行查找，表示为:

TODO:MATH

其中 f 是字段的数量，然后将其输入以下神经网络:

TODO:MATH

其中α是激活函数。Wl 和 bl是在第lth层的权重和偏差。令yDNNyDNN表示预测的输出。DeepFM的最终预测是FM和DNN的输出之和。因此，我们有：

TODO:MATH

值得注意的是，深度神经网络并不是将深度神经网络与深度神经网络相结合的唯一途径。我们还可以在特征相互作用上添加非线性层[He & Chua，2017]。

TODO:CODE

## DeepFM 的实现

深度调频的实现与调频的实现相似。我们保持调频部分不变，并使用一个带 激活函数relu 的 MLP 块。Dropout也被用来规则化模型。MLP 的神经元数目可以通过  `mlp_dims` 超参数来调节。

TODO:CODE

## 培训和评估模型

数据加载过程与FM相同。我们将DeepFM的MLP组件设置为金字塔结构的三层密集网络(30-20-10)。所有其他超参数与FM保持相同。

TODO:CODE

与FM相比，DeepFM收敛更快，性能更好。

## 小结

* 将神经网络与FM集成使其能够模拟复杂的高阶交互作用。
* DeepFM在广告数据集上优于原始FM。

## 练习

1. 改变MLP的结构，检查其对模型性能的影响。
1. 将数据集更改为Criteo，并与原始FM模型进行比较。
