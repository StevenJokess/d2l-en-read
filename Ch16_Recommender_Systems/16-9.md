

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-31 17:56:03
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-08-21 18:59:41
 * @Description:MT, improve
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_recommender-systems/fm.html
-->

# 因子分解机器

因子分解机器(FM)[Rendle，2010] ，由 Steffen Rendle 在2010年提出，是一种监督算法，可用于分类，回归和排名任务。它很快引起了人们的注意，并成为一种流行的、有影响力的预测和推荐方法。特别是，它是线性回归模型和矩阵分解模型的推广。此外，它使人联想到支持向量机与多项式核。因子分解机器在线性回归和矩阵分解上的优势是: (1)它可以模拟双向变量的相互作用，其中多项式的次数通常设置为2。(2)与因子分解机器相结合的快速优化算法，可以将多项式计算时间降低到线性复杂度，使其非常有效，特别是对于高维稀疏输入。基于这些原因，因子分解机被广泛应用于现代广告和产品推荐中。技术细节和实现描述如下。

## 双向因子分解机

形式上，x ∈ Rd 表示一个样本的特征向量，y 表示对应的标号，这些标号可以是实值标号，也可以是类标号，如二进制类“点击/不点击”。二次因式分解机的模型定义为:

TODO:MATH

其中 w0∈R 为整体偏差; w ∈ Rd 表示 i-th 变量的权重; v ∈ r d k ∈ Rd k 表示特征嵌入; vi 表示 v 的第 i 行; k 表示潜在因子的维数;   ⟨⋅,⋅⟩为两个向量的点积。⟨vi,vj⟩  模型研究第 i 和第 j 特征之间的相互作用。一些特征交互可以很容易理解，因此可以由专家设计。然而，大多数其他特性交互都隐藏在数据中，难以识别。因此，特征交互的自动建模可以大大减少特征工程的工作量。很明显，前两个术语与线性回归模型相对应，而后一个术语是矩阵分解模型的延伸。如果特性 i 表示一个条目，而特性 j 表示一个用户，那么第三个条目就是介于用户和条目嵌入之间的点积。值得注意的是，FM 也可以推广到更高的阶(阶数 > 2)。然而，数值稳定性可能会削弱这种普遍性。

## 一种有效的最优化准则

用一种直接的方法对因子分解机器进行优化，会导致复杂度为 O(kd2)  ，因为所有的成对相互作用都需要计算。为了解决这个问题，我们可以重新组织调频信号的第三项，这样可以大大减少计算量，从而达到线性时间复杂度 O(kd) 。成对相互作用项的重新表述如下:

TODO:MATH

通过这种重构，模型的复杂度大大降低。此外，对于稀疏特征，只需要计算非零元素，因此总体复杂度与非零特征的数量是线性的。

为了学习 FM 模型，我们可以使用回归任务的 MSE 损失，分类任务的交叉熵损失，以及排序任务的 BPR 损失。像 SGD 和 Adam 这样的标准优化器对于优化是可行的。

TODO:CODE

## 模型实施

下面的代码实现了因数分解机器。可以清楚地看到FM由一个线性回归块和一个有效的特征交互块组成。由于我们将CTR预测视为一项分类任务，因此我们在最终得分上应用了一个s型函数。

## 加载广告的数据集

我们使用上一节中的CTR数据包装器来加载在线广告数据集。

TODO:CODE

## 训练模型

之后，我们训练模型。默认情况下，学习率设置为0.01，嵌入大小设置为20。Adam优化器和SigmoidBinaryCrossEntropyLoss损失用于模型训练。

TODO:CODE

## 小结

* FM是一个通用框架，可以应用于各种任务，例如回归，分类和排名。
* 特征交互/交叉对于预测任务很重要，并且可以使用FM有效地建模双向交互。

## 练习

1. 你能测试FM在其他数据集，如Avazu, MovieLens，和Criteo数据集?
2. 通过改变嵌入大小来检查其对性能的影响，你能观察到与矩阵分解类似的模式吗?
