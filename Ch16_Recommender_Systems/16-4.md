

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-07-02 18:37:33
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-08-21 19:43:43
 * @Description:MT, improve
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/PR-1092/chapter_recommender-systems/autorec.html
-->

# 自动录制: 使用自动编码器进行评级预测

尽管矩阵分解模型在评级预测任务上取得了不错的表现，但它本质上是一个线性模型。因此，这样的模型不能捕捉复杂的非线性和复杂的关系，这些关系可以预测用户的偏好。在这一节中，我们介绍一个非线性神经网络 / 协同过滤模型，AutoRec[Sedhain et al., 2015](http://preview.d2l.ai/d2l-en/PR-1092/chapter_references/zreferences.html#sedhain-menon-sanner-ea-2015)。它用一个自动编码器结构来识别协同过滤，目的是在显式反馈的基础上将非线性变换集成到自动编码器中。神经网络已经被证明能够逼近任何连续函数，使它适合于解决矩阵分解的局限性和丰富矩阵分解的表达能力。

一方面，AutoRec 具有与自动编码器相同的结构，它由输入层、隐藏层和重构(输出)层组成。自动编码器是一种神经网络，它学习将输入复制到输出，以便将输入编码到隐藏(通常是低维)表示中。在 AutoRec 中，它不是显式地将用户 / 项嵌入到低维空间，而是使用交互矩阵的列 / 行作为输入，然后在输出层重新构造交互矩阵。

另一方面，AutoRec 不同于传统的自动编码器: AutoRec 关注于学习 / 重构输出层，而不是学习隐藏表示。它使用部分观察到的交互矩阵作为输入，旨在重建一个完整的评级矩阵。同时，为了推荐的目的，通过重构在输出层中填补输入的缺失项。

Autorec 有两个变体: 基于用户的和基于项目的。为了简短起见，这里我们只介绍基于项的自动记录。可以相应地派生出基于用户的 AutoRec。

## 模型

让R∗i表示评价矩阵的ith列，其中未知的评价默认设置为零。神经结构定义为:

TODO:MATH

其中 f (·) 和 g(·)代表激活函数，$W$ 和 $V$代表权重矩阵，$μ$和$b$代表偏差。设 h (·) 表示 AutoRec 的整个网络。输出TODO:MATH$h (R_*i)$是评分矩阵第 i 列的重构。

以下目标函数旨在最小化重构误差:

TODO:MATH

这里面 ∥⋅∥O 表示仅考虑观察到的额定值的贡献，即，在反向传播期间仅更新与观察到的输入关联的权重。

TODO:CODE

## 实现模型

典型的自动编码器由编码器和解码器组成。编码器将输入投影到隐藏表示，解码器将隐藏层映射到重构层。我们按照这种做法，并创建了密集层（dense layers）的编码器和解码器。编码器的激活默认设置为`sigmoid`，解码器不激活。在编码转换之后包括dropout，以减少过度拟合。未观测输入的梯度被掩盖，以确保只有观测到的评分有助于模型学习过程。

TODO:CODE

## 重新实现评估器

由于输入和输出已更改，因此我们需要重新实现评估功能，同时我们仍将RMSE用作准确性度量。

TODO:CODE

## 训练和评估模型

现在，让我们在MovieLens数据集上训练和评估AutoRec。我们可以清楚地看到，测试RMSE低于矩阵分解模型，证实了神经网络在评级预测任务中的有效性。

TODO:CODE

## 总结

- 我们可以使用自动编码器构建矩阵分解算法，同时集成非线性层和丢包正则化。
- 在MovieLens 100K数据集上的实验表明，AutoRec的性能优于矩阵分解。

## 练习

1. 改变AutoRec的隐藏维度，看看它对模型性能的影响。
2. 尝试添加更多的隐藏层。这是否有助于提高模型性能？
3. 你能找到一个更好的解码器和编码器激活函数的组合吗？
