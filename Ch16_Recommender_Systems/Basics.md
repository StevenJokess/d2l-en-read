

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-12-27 14:11:59
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-12-27 14:12:22
 * @Description:
 * @TODO::
 * @Reference:https://amylewis.github.io/2020/07/21/Rec_sys_book_reading/index.html
-->

传统推荐模型的发展主要经历了四个阶段：

协同过滤 CF 算法阶段 ：只需用户物品共现矩阵就可以构建推荐系统，根据相似度取值对象可分为 itemCF 和 userCF 两类，优势是简单易实现。CF 的问题是泛化能力弱，无法应对稀疏矩阵，而矩阵分解作为协同过滤的进化版，克服了 CF 的缺点。
逻辑回归 LR 阶段 ：综合利用用户、物品、上下文等多种不同的特征，假设用户是否点击广告服从伯努利分布，将推荐问题转化为点击率预估 (CTR) 问题，预测正样本概率对物品进行排序。其数学形式是各个特征的加权和经过 sigmoid 函数，得到用户点击物品的概率。LR 的优势是可解释性强、易于并行化、模型简单、训练开销小。其局限性在于表达能力不强，需要大量具有业务背景知识的人工特征筛选与交叉。
因子分解机 FM 阶段 ：为每个特征学习一个隐向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。虽然 FM 相比 POLY2 的完全交叉 + 单一权重记忆能力略弱，但解决了特征交叉过程中交叉特征对应的数据过于稀疏无法充分学习权重的问题。FFM 引入特征域进一步增强了模型的表达能力，做特征交叉时，每个特征选择与对方域对应的隐向量的内积作为交叉特征的权重，但 FFM 的计算复杂度也由 kn 上升到 kn*n。
组合模型阶段 ：这一阶段主要是为了进一步提高特征交叉的维度，同时融合多个模型的优点。GBDT+LR 是组合模型的代表方案，GBDT 自动进行特征筛选和组合得到新的离散特征向量输入 LR 模型。GBDT+LR 的组合方式开启了特征工程模型化的趋势，真正实现端到端训练。

---

推荐系统「模型部分」是推荐系统的主题，一般由「召回层」「排序」「补充策略与算法层」组成。

召回层：利用高效的召回规则、算法或简单模型，快速从海量的候选集召回用户可能感兴趣的物品
排序层：利用排序模型对初筛的候选集进行精排序
补充策略与算法：也被称为再排序层，在推荐列表返回用户之前，兼顾结果的多样性、流行度、新鲜度等指标，结合一些补充的策略和算法对推荐列表进行一定的调整，最终形成用户可见的推荐里列表。
