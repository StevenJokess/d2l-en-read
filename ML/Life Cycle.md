

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-12-06 18:27:08
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-12-06 18:34:47
 * @Description:
 * @TODO::
 * @Reference:https://learning.oreilly.com/library/view/agile-ai/9781492074984/ch02.html#the_machine_learning_life_cycle
-->

在我们构建了机器学习模型之后，必须针对预期的用例部署它。有时，这涉及到将模型作为微服务部署并扩展以满足客户需求。这可能涉及Kubernetes、自动缩放、负载平衡和其他网络工程工作。其他时候，我们必须直接在智能手机和其他移动设备上运行机器学习模型。为此，我们需要在将模型加载到嵌入式硬件之前使用模型压缩。在任何一种情况下，都有用于管理模型部署和监视生产中的模型性能的工具。

一个称为MLOps的新领域正在出现，用于管理整个端到端机器学习生命周期所需的操作工作。换句话说，操作的定义必须改变以满足机器学习的需要。还要注意的是，AI领域充满了试图在工具中拥有不同部分或步骤的供应商。许多公司都有完整管道的观点，以及适应存储、模型培训和模型评估的解决方案。评估供应商是超出了本电子书的范围;在这里，我们只是提供我们的观点，员工和构建一个人工智能管道的最低要求。

## 部署

数据科学生命周期的第二部分是部署，其中经过训练的模型必须是可消费的。数据科学和构建人工智能解决方案是一种强大的实践，但如果不能消耗培训过程的结果，那么它对你的业务几乎没有价值。围绕您的模型构建基础设施有很多方法，但是因为我们已经讨论了工具，所以我们将转而讨论过程的目标和原则。

模型部署是您的数据科学家、数据工程师和DevOps团队共同工作的一个步骤，以API的形式公开机器学习模型。API可以采取多种形式，但通常情况下，在AI领域API是作为REST服务提供的。像REST这样的web协议要求并定义了一种标准化的消费模式。通过遵循标准的通信协议，您可以使业务中的开发人员(可能还有外部开发人员)更容易地使用您的数据产品。你训练和部署的每一个人工智能模型都是一个数据产品，如果很难使用，人们不会成为客户。(有些模型作为批处理部署访问，因此具有稍微不同的体系结构。尽管记住它们很重要，但我们不在这里讨论它们。)

经过训练的模型只是AI团队负责创建的部署的一个单一组件。考虑到数据科学家在他们的数据探索、特性工程和培训之后提供了模型，但是模型需要数据工程师为模型构建管道。数据工程团队负责管理或标准化模型数据的输入和输出，处理模型期望的数据特性的路由，然后返回模型生成的预测。从本质上说，数据工程师为进出预测管道的数据建立更持久的持久性，这既是为了提高效率，也是为了进行再培训。


## 运行

数据科学生命周期的最后一步是运行您的模型以评估结果，这就是使您的应用程序可使用的地方。传统上，在这个步骤中，DevOps团队采用数据工程师和数据科学家构建的软件应用程序，并创建一个标准来部署它，并使其在应用程序和生产中可用。软件应用程序需要可维护性和可伸缩性。只有易于部署和维护的应用程序才是成功的。

过去，运行软件应用程序要复杂得多。每个应用程序都需要在许多不同的应用程序服务器上由负载平衡器处理路由。对于许多web规模的应用程序部署来说，这仍然是一种情况，但是我们所讨论的各种解决方案的当代设计都利用了容器和容器编排框架的优势。

容器只是一个标准单元(您的模型和REST应用程序)，它将您所有的配置和依赖项打包到一个对象中，从而允许跨运行时环境的灵活性和便利性。将预测模型和路由应用程序绑定在一起后，DevOps团队会根据需要协调容器的成长和崩溃环境。在这些现代设计中，它们不需要为持续的正常运行时间或维护单个web服务器集群和各自的单个REST应用程序而烦恼。这些架构具有更强的可扩展性和更少的开销，允许开发团队敏捷地进行迭代。

我们已经触及了数据科学团队创建什么类型的解决方案(培训)，他们在工程(部署)和DevOps的对手如何处理他们的数据产品(运行)，以及其中的一些原因。当涉及到运行时设计(DevOps团队的责任)时，请对这些建议持保留态度。有许多方法可以处理运行时环境，并且随着这一领域的创新速度，在您阅读本文时，容器编排可能看起来像刚刚流行的时尚。


分布式工作负载和混合环境

数据科学是一种古老的实践，但是今天使用的大量数据是新的，这就是为什么数据存储和计算是重大变化和令人兴奋的趋势的基础。

过去，数据存储由几个供应商拥有，这些供应商能够以很高的可靠性和速度为用户提供数据。它们的盈利能力取决于它们返回客户信息的可靠性;顾客想要储存的信息越多，花费就越多。为了处理更多的数据，企业必须学会如何更有效地存储数据。随着HDFS的出现，存储变得更便宜了。

Apache Hadoop是雅虎出于存储网络规模数据的需要而诞生的一个项目。其前提是，公司应该能够使用可能会失败的廉价商用硬件，而不是使用大型供应商提供的昂贵硬件。如果您可以通过复制数据来解释硬件故障，那么您可以使用更便宜的硬件。硬件越便宜，可以使用的硬件就越多，因此可以存储的数据也就越多。数据科学团队开始存储越来越多的数据，并承诺不再需要采样，因为他们现在可以随心所欲地使用数据。由于存储的这种可承受性，数据湖变得流行起来。

为了应对不断增长的存储和计算解决方案需求，以处理这些数据湖中的巨大存储库，供应商提供了房屋和分析客户数据。过去十年中出现的对分布式计算和存储的需求使得云产品(简化了数据分析和建模管道的一部分)成为现代应用程序架构的前沿。作为逻辑衍生品，现在的趋势似乎是构建依赖于无服务器架构的应用程序，在这种架构中没有静态虚拟化环境，只有负责计算资源的系统。

Serverless架构(Function-as-a-Service或FaaS),而虚拟化环境通常认为是“基础架构即服务”(IaaS),不要把责任在开发商保持一个环境,但允许他们利用计算能力,否则他们不会的。作为一个例子,如果我们的应用程序是负责计算部件生产地板上在任何一个时间,我们会发送实际应用serverless服务,应用程序将运行,我们会收取的平台即服务(PaaS)供应商对我们的应用程序需要的时间返回我们最后的小部件。

无服务器架构的用途与软件应用程序的用途一样多，但是对于那些不想承担管理或协调计算环境的责任的数据科学家和他们的团队也有明显的吸引力——在这些地方，他们可以分担诸如模型培训之类的长时间运行的任务。事实上，FaaS产品有可能成为我们所有模型培训需求的实际环境。我们需要提供的只是对存储在私有云或公共云中的数据和需要执行的应用程序的访问。我们会发送我们的培训脚本(其访问凭据我们的小部件的生产历史数据),负责数据清理程序,模型训练,和交叉验证需求,然后serverless服务将收取我们的时间我们的模型需要训练和旨在。这是负责Apache Spark项目的同一个小组撰写的论文和项目的基础，该项目彻底改变了数据科学家在其应用程序中使用大数据的方式。

这符合云服务领域更广泛的行业趋势:我们看到一些公司跨越公共和私有云，利用来自不同云提供商的多种云。从易用性的角度来看，几乎没有什么技术比云产品上的这些变种更有前景、更可伸缩。我们很高兴看到它们如何影响当代和未来的应用程序设计。
