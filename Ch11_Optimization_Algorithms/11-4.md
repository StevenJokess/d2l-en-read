


<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-06 20:29:13
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-10-07 00:55:06
 * @Description:MT 3/4
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_optimization/sgd.html
 * https://zh.d2l.ai/chapter_optimization/gd-sgd.html
-->

# 随机梯度下降（stochastic gradient descent）
:label:`sec_sgd`

在这一节中，我们将介绍随机梯度下降（stochastic gradient descent）的基本原理。

## 随机梯度更新

在深度学习中，目标函数通常是训练数据集中每个示例的损失函数的平均值。 我们假设fi（x）fi（x）是训练数据集的损失函数，具有nn个示例，索引为ii，参数向量为xx，则我们有目标函数

$$f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n f_i(\mathbf{x}).$$

目标函数在$\mathbf{x}$处的梯度计算为

$$\nabla f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x}).$$

如果使用梯度下降，则每个自变量迭代的计算成本为$\mathcal{O}(n)$，它随$n$线性增长。 因此，当模型训练数据集很大时，每次迭代的梯度下降成本将非常高。

随机梯度下降（SGD）降低了每次迭代的计算成本。 在随机梯度下降的每次迭代中，我们随机地为数据示例统一采样索引$i\in\{1,\ldots, n\}$，并计算梯度$\nabla f_i(\mathbf{x})$更新$\mathbf{x}$：

$$\mathbf{x} \leftarrow \mathbf{x} - \eta \nabla f_i(\mathbf{x}).$$

在此，ηη是学习率。 我们可以看到，每次迭代的计算成本都从梯度下降的O（n）O（n）降至常数O（1）O（1）。 我们应该提到，随机梯度∇fi（x）∇fi（x）是梯度∇f（x）∇f（x）的无偏估计。

$$\mathbb{E}_i \nabla f_i(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x}) = \nabla f(\mathbf{x}).$$

这意味着，平均而言，随机梯度是对梯度的良好估计。

现在，我们将通过向梯度中添加平均值为0，方差为1的随机噪声来模拟SGD，将其与梯度下降进行比较。

TODO:CODE

正如我们所看到的，SGD中变量的轨迹比我们在上一节中观察到的梯度下降的轨迹噪声更大。这是由于梯度的随机性。也就是说，即使在接近最小值的时候，我们仍然受到了由$\eta \nabla f_i(\mathbf{x})$注入的瞬时梯度的不确定性的影响。即使经过50步，质量仍然不是很好。更糟糕的是,它不会提高额外的步骤之后(我们鼓励读者与大量的实验步骤自己证实了这一点)。这给我们留下了唯一的选择——改变学习速度$\eta$。然而，如果我们选择的太小，我们将不会取得任何有意义的进展。另一方面，如果我们选择太大，我们将不会得到一个好的解决方案，如上所示。解决这些冲突目标的唯一方法是随着优化的进展动态地降低学习率。

这也是增加的原因学习速率函数lr sgd阶跃函数。在上面的例子中，任何用于学习速率调度的功能都处于休眠状态，因为我们将相关的lr函数设置为常量，即`lr = (lambda: 1)`。

## 动态学习速率

用一个依赖时间的学习率的优化算法来代替最优优化，增加了优化算法控制收敛的复杂性。特别是，需要弄清楚它的腐烂速度。如果它太快，我们就会过早地停止优化。如果我们降低速度太慢，就会在优化上浪费太多时间。随着时间的推移，有一些基本的策略用于调整资产管理(我们将在后面的章节讨论更高级的策略):

$$
\begin{aligned}
    \eta(t) & = \eta_i \text{ if } t_i \leq t \leq t_{i+1}  && \mathrm{piecewise~constant} \\
    \eta(t) & = \eta_0 \cdot e^{-\lambda t} && \mathrm{exponential} \\
    \eta(t) & = \eta_0 \cdot (\beta t + 1)^{-\alpha} && \mathrm{polynomial}
\end{aligned}
$$

在第一种情况下，我们降低了学习率，例如，每当优化的进展停滞时。这是训练深度网络的常见策略。或者，我们可以通过指数衰减的方式更积极地降低它。不幸的是，这导致在算法收敛之前过早停止。一个普遍的选择是多项式衰减与次幂$\alpha = 0.5$。在凸优化的情况下有很多的证据表明,这种速度的表现。让我们看看实际情况是怎样的。

TODO:CODE

正如预期的那样，参数中的差异显著减少。但是，这样做的代价是不能收敛到最优解$\mathbf{x} = (0, 0)$。即使在1000步之后，我们仍然离最佳解决方案很远。实际上，该算法根本无法收敛。另一方面，如果我们使用一个多项式衰减当学习速率随着阶数的平方根的倒数而衰减收敛是好的。

TODO:CODE

对于如何设置学习率有更多的选择。例如，我们可以从一个小速率开始，然后迅速上升，然后再次下降，尽管速度更慢。我们甚至可以在更小和更大的学习率之间进行交替。存在着各种各样的这样的时间表。现在，让我们集中在学习率计划，这是一个全面的理论分析是可能的，即，在凸设置的学习率。对于一般的非凸问题，由于一般情况下最小化非线性非凸问题是NP困难的，因此很难得到有意义的收敛保证。关于调查，请参见2015年Tibshirani的优秀[演讲笔记](https://www.stat.cmu.edu/~ryantibs/convexopt-F15/lectures/26-nonconvex.pdf)。

## 凸目标的收敛分析

下面的选项是可选的，主要是为了传达更多关于这个问题的直觉。我们限制自己在一个最简单的证明，如描述的:cite:`Nesterov.Vial.2000`。更先进的证明技术存在,例如,当目标函数表现得尤其好。:cite:`Hazan.Rakhlin.Bartlett.2008`表明,强凸函数,也就是说,从下面可以有界函数,用$\mathbf{x}^\top \mathbf{Q} \mathbf{x}$,可以减少他们在一个小数量的步骤,同时减少了学习速率像$\eta(t) = \eta_0/(\beta t + 1)$。不幸的是，这种情况在深度学习中从未真正发生过，我们在实践中所面临的下降速度要慢得多。

考虑这种情况
$$\mathbf{w}_{t+1} = \mathbf{w}_{t} - \eta_t \partial_\mathbf{w} l(\mathbf{x}_t, \mathbf{w}).$$

$$
l(\mathbf{x}_t, \mathbf{w}^*) \geq l(\mathbf{x}_t, \mathbf{w}_t) + \left\langle \mathbf{w}^* - \mathbf{w}_t, \partial_{\mathbf{w}} l(\mathbf{x}_t, \mathbf{w}_t) \right\rangle.
$$

利用这两个不等式并将其代入上面的式子中，我们得到了t+1时刻参数间距离的界，如下所示:

$$\|\mathbf{w}_{t} - \mathbf{w}^*\|^2 - \|\mathbf{w}_{t+1} - \mathbf{w}^*\|^2 \geq 2 \eta_t (l(\mathbf{x}_t, \mathbf{w}_t) - l(\mathbf{x}_t, \mathbf{w}^*)) - \eta_t^2 L^2.$$

这意味着只要当前损失和最优损失之间的预期差额大于$\eta_t L^2$，我们就会取得进展。由于前者必然收敛于$0$，因此学习速率$\eta_t$也需要消失。

接下来我们对这个表达式进行期望。这个收益率

$$E_{\mathbf{w}_t}\left[\|\mathbf{w}_{t} - \mathbf{w}^*\|^2\right] - E_{\mathbf{w}_{t+1}\mid \mathbf{w}_t}\left[\|\mathbf{w}_{t+1} - \mathbf{w}^*\|^2\right] \geq 2 \eta_t [E[R[\mathbf{w}_t]] - R^*] -  \eta_t^2 L^2.$$

最后一步是在$t \in \{t, \ldots, T\}$的不等式求和。因为总和是缩进的，去掉下面的项，我们就得到

$$\|\mathbf{w}_{0} - \mathbf{w}^*\|^2 \geq 2 \sum_{t=1}^T \eta_t [E[R[\mathbf{w}_t]] - R^*] - L^2 \sum_{t=1}^T \eta_t^2.$$

注意，我们利用了$\mathbf{w}_0$的给定，因此可以删除期望。最后一个定义

$$\bar{\mathbf{w}} := \frac{\sum_{t=1}^T \eta_t \mathbf{w}_t}{\sum_{t=1}^T \eta_t}.$$

然后通过凸性得出

$$\sum_t \eta_t E[R[\mathbf{w}_t]] \geq \sum \eta_t \cdot \left[E[\bar{\mathbf{w}}]\right].$$

把这个代入上面的不等式就得到了边界

$$
\left[E[\bar{\mathbf{w}}]\right] - R^* \leq \frac{r^2 + L^2 \sum_{t=1}^T \eta_t^2}{2 \sum_{t=1}^T \eta_t}.
$$

这里$r^2 := \|\mathbf{w}_0 - \mathbf{w}^*\|^2$ 是参数的初始选择和最终结果之间的距离的界限。 简而言之，收敛速度取决于损失函数通过Lipschitz常数$ L $变化的速度以及初始值$ r $与最优值的距离。 请注意，边界是用$ \ bar {\ mathbf {w}} $而不是$ \ mathbf {w} _T $表示的。 这是因为$ \ bar {\ mathbf {w}} $是优化路径的平滑版本。 现在让我们分析 $\eta_t$ 的一些选择。

* **已知的时间范围。**当r、Lr、L和TT已知时，我们可以选择:猥亵=r/LT - - -√猥亵=r/LT。得到的上界为rL(1+1/T)/2T−−√<rL/T−−√rL(1+1/T)/2T<rL/T。即以O(1/T - -√)O(1/T)的速率收敛到最优解。
* **未知的时间范围。**无论何时我们想要对任何时间的$T$有一个好的解决方案，我们可以选择:$\eta = \mathcal{O}(1/\sqrt{T})$这个费用我们额外的对数的因素,它会导致一个上界形式$\mathcal{O}(\log T / \sqrt{T})$。

注意,强烈凸损失 $l(\mathbf{x}, \mathbf{w}') \geq l(\mathbf{x}, \mathbf{w}) + \langle \mathbf{w}'-\mathbf{w}, \partial_\mathbf{w} l(\mathbf{x}, \mathbf{w}) \rangle + \frac{\lambda}{2} \|\mathbf{w}-\mathbf{w}'\|^2$，我们可以设计更快速融合为一体的优化调度。事实上,一个指数衰减ηη导致绑定表单的O $\mathcal{O}(\log T / T)$。

## 随机梯度和有限样本

到目前为止，讲到随机梯度下降时，我们讲得有点快也有点松。我们假设我们绘制典型带有$y_i$标签的实例$x_i$，通常从一些分布$p(x, y)$，并且我们使用它以某种方式更新权重$w$。特别地，对于有限的样本容量，我们认为离散分布$p(x, y) = \frac{1}{n} \sum_{i=1}^n \delta_{x_i}(x) \delta_{y_i}(y)$允许我们对其执行SGD。

然而，这并不是我们真正所做的。在本节的玩具示例中，我们只是在非随机梯度中添加了噪声，即，我们假设有对$(x_i, y_i)$。事实证明，这在这里是合理的(详细讨论请参阅练习)。更令人不安的是，在以前的所有讨论中，我们显然没有这样做。相反，我们对所有实例只迭代一次。为了了解为什么这是可取的，考虑相反的情况，也就是说，我们从离散分布中采样$n$的观察值。随机选择元素$i$的概率是$N^{-1}$。因此选择它至少一次是可行的

$$P(\mathrm{choose~} i) = 1 - P(\mathrm{omit~} i) = 1 - (1-N^{-1})^N \approx 1-e^{-1} \approx 0.63.$$

类似的推理表明，精确抽取一次样本的概率为${N \choose 1} N^{-1} (1-N^{-1})^{N-1} = \frac{N-1}{N} (1-N^{-1})^{N} \approx e^{-1} \approx 0.37$。这导致了与不进行替换的抽样相比，方差的增加和数据效率的降低。因此，在实践中我们执行后者(这是贯穿全书的默认选择)。最后注意，重复通过数据集遍历它在一个不同的随机顺序。

## 总结

* 对于凸问题，我们可以证明在学习速率选择范围较广的情况下，随机梯度下降将收敛于最优解。
* 对于深度学习来说，通常不是这样的。然而，凸问题的分析给我们提供了如何接近优化的有用的见解，即逐步降低学习率，尽管不是太快。
* 当学习率太小或太大时，就会出现问题。在实践中，通常只有经过多次实验才能找到合适的学习率。
* 当训练数据集中的例子越多，计算梯度下降的每次迭代的代价就越大，因此在这些情况下，SGD是首选。
* 最优保障SGD一般没有凸情况下由于局部最小值的数量,需要检查可能是指数。

## 练习

1. 采用不同的学习速率和不同的迭代次数对SGD进行实验。特别地，将距离最优解(0,0)(0,0)的距离绘制成迭代次数的函数。
1. 证明对于函数$f(x_1, x_2) = x_1^2 + 2 x_2^2$，在梯度上添加正常噪声等价于最小化一个损失函数$l(\mathbf{x}, \mathbf{w}) = (x_1 - w_1)^2 + 2 (x_2 - w_2)^2$，其中$x$是从正态分布中提取的。
     * 推导$\mathbf{x}$分布的均值和方差。
     * 显示这个属性拥有一般目标函数$f(\mathbf{x}) = \frac{1}{2} (\mathbf{x} - \mathbf{\mu})^\top Q (\mathbf{x} - \mathbf{\mu})$ for $Q \succeq 0$。
1. 比较在$\{(x_1, y_1), \ldots, (x_m, y_m)\}$中有替换采样和无替换采样时SGD的收敛性。
1. 如果某个梯度(或与之相关的某个坐标)始终大于所有其他梯度，你将如何改变SGD求解器?
1. 假设$f(x) = x^2 (1 + \sin x)$。$f$有多少局部最小值?你能改变$f$使其最小化需要计算所有的局部最小值吗?
