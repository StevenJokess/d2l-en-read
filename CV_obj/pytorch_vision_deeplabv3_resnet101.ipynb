{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_vision_deeplabv3_resnet101.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df38e480184149c78f2d1cf17dbefe4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1d387d0b4de47aa9853d264255d2ea8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3153c36824148edb0864eefd40a241a",
              "IPY_MODEL_8ea7b295b4ea48518e89c7e0cc143a10"
            ]
          }
        },
        "e1d387d0b4de47aa9853d264255d2ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3153c36824148edb0864eefd40a241a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_064ab544485e49a69f739f07bec07fff",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 178728960,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 178728960,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efe12224b40b4f34ab9fd167a7926790"
          }
        },
        "8ea7b295b4ea48518e89c7e0cc143a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f3e53a5d2fd42008c1701e113afb4b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170M/170M [00:06&lt;00:00, 29.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b94f9dee75a54badb7d847df84e48031"
          }
        },
        "064ab544485e49a69f739f07bec07fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efe12224b40b4f34ab9fd167a7926790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f3e53a5d2fd42008c1701e113afb4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b94f9dee75a54badb7d847df84e48031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b37bfb9fa60d4d9a880a32a007022ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_483a9a1e69bb4a239e56cb03d7061c2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88ce5a3b226c451fbb1c4a2d63e33d05",
              "IPY_MODEL_331973850509483d9518144b197621e0"
            ]
          }
        },
        "483a9a1e69bb4a239e56cb03d7061c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88ce5a3b226c451fbb1c4a2d63e33d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8e3a46f647c48df8327d415d879cca9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244545539,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244545539,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea9e4d9dc5ff412b91cf801b83ff07df"
          }
        },
        "331973850509483d9518144b197621e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_131ff98a058f4e66a0fcedc6cd9c2048",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:01&lt;00:00, 150MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9dc134439582483ea5fd8630f64f9ba9"
          }
        },
        "e8e3a46f647c48df8327d415d879cca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea9e4d9dc5ff412b91cf801b83ff07df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "131ff98a058f4e66a0fcedc6cd9c2048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9dc134439582483ea5fd8630f64f9ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7txrmTK1hXsn"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Deeplabv3-ResNet101\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**DeepLabV3 model with a ResNet-101 backbone**\n",
        "\n",
        "_ | _\n",
        "- | -\n",
        "![alt](https://pytorch.org/assets/images/deeplab1.png) | ![alt](https://pytorch.org/assets/images/deeplab2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df38e480184149c78f2d1cf17dbefe4a",
            "e1d387d0b4de47aa9853d264255d2ea8",
            "f3153c36824148edb0864eefd40a241a",
            "8ea7b295b4ea48518e89c7e0cc143a10",
            "064ab544485e49a69f739f07bec07fff",
            "efe12224b40b4f34ab9fd167a7926790",
            "8f3e53a5d2fd42008c1701e113afb4b0",
            "b94f9dee75a54badb7d847df84e48031",
            "b37bfb9fa60d4d9a880a32a007022ecb",
            "483a9a1e69bb4a239e56cb03d7061c2e",
            "88ce5a3b226c451fbb1c4a2d63e33d05",
            "331973850509483d9518144b197621e0",
            "e8e3a46f647c48df8327d415d879cca9",
            "ea9e4d9dc5ff412b91cf801b83ff07df",
            "131ff98a058f4e66a0fcedc6cd9c2048",
            "9dc134439582483ea5fd8630f64f9ba9"
          ]
        },
        "id": "WTXEwld8hXsv",
        "outputId": "7ba08015-3ad8-4dca-b53e-55a36e97f35b"
      },
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df38e480184149c78f2d1cf17dbefe4a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=178728960.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b37bfb9fa60d4d9a880a32a007022ecb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244545539.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepLabV3(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): DeepLabHead(\n",
              "    (0): ASPP(\n",
              "      (convs): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (3): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (4): ASPPPooling(\n",
              "          (0): AdaptiveAvgPool2d(output_size=1)\n",
              "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (3): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux_classifier): FCNHead(\n",
              "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-U8I2iThXsw"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(N, 3, H, W)`, where `N` is the number of images, `H` and `W` are expected to be at least `224` pixels.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "The model returns an `OrderedDict` with two Tensors that are of the same height and width as the input Tensor, but with 21 classes.\n",
        "`output['out']` contains the semantic masks, and `output['aux']` contains the auxillary loss values per-pixel. In inference mode, `output['aux']` is not useful.\n",
        "So, `output['out']` is of shape `(N, 21, H, W)`. More documentation can be found [here](https://pytorch.org/docs/stable/torchvision/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1iypnw4hXsw"
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h91P1NHJhXsx"
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)['out'][0]\n",
        "output_predictions = output.argmax(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JwdjQ6bhXsx"
      },
      "source": [
        "The output here is of shape `(21, H, W)`, and at each location, there are unnormalized probabilities corresponding to the prediction of each class.\n",
        "To get the maximum prediction of each class, and then use it for a downstream task, you can do `output_predictions = output.argmax(0)`.\n",
        "\n",
        "Here's a small snippet that plots the predictions, with each color being assigned to each class (see the visualized image on the left)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "GAUkBWGLhXsx",
        "outputId": "570a33a0-d208-4de5-baea-5f3fed6c6133"
      },
      "source": [
        "# create a color pallette, selecting a color for each class\n",
        "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
        "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
        "colors = (colors % 255).numpy().astype(\"uint8\")\n",
        "\n",
        "# plot the semantic segmentation predictions of 21 classes in each color\n",
        "r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_image.size)\n",
        "r.putpalette(colors)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(r)\n",
        "# plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6b141c5668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYAvTYkYh4Lf"
      },
      "source": [
        "# Download an example image from the pytorch website\r\n",
        "import urllib\r\n",
        "url, filename = (\"https://n.sinaimg.cn/sports/2_img/upload/ce3d62b9/29/w1080h1349/20190801/37b1-iaqfzyv6347266.jpg\", \"meinv.jpg\")\r\n",
        "try: urllib.URLopener().retrieve(url, filename)\r\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RzTE6cfh40Y"
      },
      "source": [
        "# sample execution (requires torchvision)\r\n",
        "from PIL import Image\r\n",
        "from torchvision import transforms\r\n",
        "input_image = Image.open(filename)\r\n",
        "preprocess = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n",
        "])\r\n",
        "\r\n",
        "input_tensor = preprocess(input_image)\r\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\r\n",
        "\r\n",
        "# move the input and model to GPU for speed if available\r\n",
        "if torch.cuda.is_available():\r\n",
        "    input_batch = input_batch.to('cuda')\r\n",
        "    model.to('cuda')\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    output = model(input_batch)['out'][0]\r\n",
        "output_predictions = output.argmax(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00RkKl7diM5y",
        "outputId": "ab4974b9-bb52-40f0-8346-bd478990b45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# create a color pallette, selecting a color for each class\r\n",
        "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\r\n",
        "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\r\n",
        "colors = (colors % 255).numpy().astype(\"uint8\")\r\n",
        "\r\n",
        "# plot the semantic segmentation predictions of 21 classes in each color\r\n",
        "r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_image.size)\r\n",
        "r.putpalette(colors)\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.imshow(r)\r\n",
        "# plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6b14095208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji_iLo7FhXsy"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Deeplabv3-ResNet101 is constructed by a Deeplabv3 model with a ResNet-101 backbone.\n",
        "The pre-trained model has been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
        "\n",
        "Their accuracies of the pre-trained models evaluated on COCO val2017 dataset are listed below.\n",
        "\n",
        "|    Model structure  |   Mean IOU  | Global Pixelwise Accuracy |\n",
        "| ------------------- | ----------- | --------------------------|\n",
        "| deeplabv3_resnet101 |   67.4      |   92.4                    |\n",
        "\n",
        "### Resources\n",
        "\n",
        " - [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)"
      ]
    }
  ]
}