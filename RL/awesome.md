

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-19 18:56:46
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-11-11 21:16:16
 * @Description:
 * @TODO::
 * @Reference:
-->

[1]: https://stepneverstop.github.io/rl-rough-reading.html
[2]: https://stepneverstop.github.io/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.html
[3]: https://github.com/RITCHIEHuang/DeepRL_Algorithms
[4]: http://rail.eecs.berkeley.edu/deeprlcourse/
[5]: https://github.com/berkeleydeeprlcourse/homework_fall2020
[6]: https://blog.csdn.net/gsww404/article/details/103074046
[7]: https://github.com/NeuronDance/DeepRL/tree/master/A-Guide-Resource-For-DeepRL
[8]: https://news.berkeley.edu/2015/05/21/deep-learning-robot-masters-skills-via-trial-and-error/
[9]: https://gym.openai.com/docs/
[10]: DeepMind开源强化学习库TRFL https://www.jiqizhixin.com/articles/2018-10-18-15?from=synced&keyword=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0
[11]: http://incompleteideas.net/book/code/code2nd.html
[12]: https://github.com/ShangtongZhang

---
Atari games: Q-learning: V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, et al. “Playing Atari with Deep Reinforcement Learning”. (2013). Policy gradients: J. Schulman, S. Levine, P. Moritz, M. I. Jordan, and P. Abbeel. “Trust Region Policy Optimization”. (2015). V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. P. Lillicrap, et al. “Asynchronous methods for deep reinforcement learning”. (2016).
Real-world robots: Guided policy search: S. Levine*, C. Finn*, T. Darrell, P. Abbeel. “End-to-end training of deep visuomotor policies”. (2015). Q-learning: D. Kalashnikov et al. “QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation”. (2018).
Beating Go champions: Supervised learning + policy gradients + value functions + Monte Carlo tree search: D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, et al. “Mastering the game of Go with deep neural networks and tree search”. Nature (2016).
