

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-07-25 13:34:05
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-08-08 10:46:57
 * @Description:MT
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_appendix-mathematics-for-deep-learning/statistics.html
-->

# 统计学

毫无疑问，作为一个顶级的深度学习实践者，培养最先进和高精度模型的能力是至关重要的。然而，当改进是显著的，或者仅仅是训练过程中的随机波动的结果时，通常是不清楚的。为了能够讨论估计值的不确定性，我们必须学习一些统计学知识。

最早的统计学的参考可以追溯到9世纪的阿拉伯学者金迪，他详细描述了如何使用统计和频率分析破译加密信息。经过800年的发展，现代统计学起源于18世纪的德国，当时的研究者主要集中在人口和经济数据的收集和分析上。今天，统计学是一门涉及数据的收集、处理、分析、解释和可视化的科学。此外，统计学的核心理论在学术界、工业界和政府部门的研究中得到了广泛的应用。

更具体地说，统计学可以分为描述统计学和推论统计学。前者侧重于总结和说明观测数据集的特点，即所谓的样本。样本取自一个总体，表示与我们的实验兴趣相似的个体、项目或事件的总集合。与描述统计学相反，基于样本分布可以在一定程度上复制种群分布的假设，推论统计学进一步从给定的样本推断种群的特征。

你可能会问: “机器学习和统计学之间的本质区别是什么? ”从根本上讲，统计主要关注推断问题。这类问题包括建模变量之间的关系，例如因果推断，以及测试模型参数的统计意义，例如 A/B 测试。相比之下，机器学习强调做出准确的预测，而没有明确地编程和理解每个参数的功能。

在本节中，我们将介绍三种统计推断方法: 评估和比较估计量、进行假设检验和构造置信区间。这些方法可以帮助我们推断给定总体的特征，即真实参数。为简便起见，我们假设给定总体的真实参数是一个标量值。直接扩展到矢量或张量的情况是很简单的，因此我们在讨论中忽略了它。

## 评估和比较估计量

在统计学中，估计量是用于估计真参数的给定样本的函数。我们将把 ^ n = f ^ (x1，... ，xn) ^ n = f ^ (x1，... ，xn)写成观察样本{ x1，x2，... ，xn x1，x2，... ，xn }后的估计。

在第18.7节中，我们已经看到了一些简单的估计量的例子。如果你有一个贝努利随机变量的样本数，那么最大似然估计的概率随机变量是一，可以通过计算的观察到的数目，除以总样本数。类似地，一个练习要求你展示给定一定数量样本的高斯平均值的最大似然估计，是由所有样本的平均值给出的。这些估计几乎不会给出参数的真实值，但是对于大量的样本来说，理想的估计值是接近的。

作为一个例子，我们显示下面的真实密度的高斯随机变量的均值为零和方差为一，以及收集样本的高斯。我们构造了 y 坐标，这样每个点都是可见的，并且与原始密度的关系更加清晰。

TODO:CODE

有很多方法可以计算参数  θ^n的估计值。在本节中，我们将介绍三种常用的评估和比较估计量的方法:均方误差、标准差和统计偏差。

### 均方误差

也许用来评估估计量的最简单的度量是估计量的平均平方误差(MSE)(或l2l2损失)可以定义为

(18.10.1)

MSE(θ^ n,θ)= E[(θ^ n−θ)2]。

这允许我们量化与真实值的平均平方偏差。MSE总是非负的。如果你读过3.1节，你会发现它是最常用的回归损失函数。作为评估估计值的一种度量，估计值的值越接近于零，估计值越接近真实参数。

### 统计偏差

MSE提供了一个自然的度量，但我们可以很容易地想象多种不同的现象，可能使它变大。两个最重要的是由于数据集的随机性导致估计器产生的波动，以及由于估计过程导致估计器产生的系统误差。

首先，让我们测量系统误差。对于一个估计量，统计偏差的数学说明可以定义为

(18.10.2)¶

偏见(θ^ n) = E(θ^ n−θ)= E(θ^ n)−θ。

注意，当bias（θ^ n）= 0bias（θ^ n）= 0时，估计量θ^nθ^ n的期望等于参数的真实值。 在这种情况下，我们说θ^n是一个无偏估计量。 通常，无偏估计量要优于有偏估计量，因为其期望值与真实参数相同。

但是，值得注意的是，有偏估计量在实践中经常使用。 在某些情况下，没有进一步的假设就不会存在无偏估计量，或者很难进行估计。 这似乎是估计器中的一个重大缺陷，但是在实践中遇到的大多数估计器至少在渐近无偏的意义上说，随着可用样本的数量趋于无穷大，偏差趋于零：limn→∞bias（θ^ n）= 0

### 差异和标准差

其次，让我们测量估计器中的随机性。 回想一下第18.6节，标准偏差（或标准误差）定义为方差的平方根。 我们可以通过测量估计量的标准偏差或方差来测量估计量的波动程度。

（18.10.3）

σθ^ n = Var（θ^ n）= E [（θ^ n-E（θ^ n））2]。

将（18.10.3）与（18.10.1）进行比较很重要。 在此等式中，我们不与真实总体值θθ进行比较，而是与预期样本均值E（θ^ n）E（θ^ n）进行比较。 因此，我们不是在测量估算器与真实值之间的距离，而只是在测量估算器本身的波动。

### 偏见方差的权衡

直观地看，这两个主要成分导致了均方误差。令人震惊的是，我们可以证明，这实际上是均值平方误差分解为这两个贡献加上第三个贡献。也就是说，均值平方误差可以写成偏差，方差和不可约误差的平方之和。

TODO:MATH

我们将上述公式作为偏方差权衡。均方误差可分为三种误差来源:高偏差误差、高方差误差和不可约误差。偏置误差在简单模型(如线性回归模型)中很常见，不能提取出特征与输出之间的高维关系。如果一个模型存在高偏差误差，我们通常会说它不拟合或缺乏泛化，如(4.4节)中所介绍的。高的方差通常是由过于复杂的模型导致的，它会过度拟合训练数据。因此，过拟合模型对数据中的小波动很敏感。如果一个模型存在高方差，我们经常说它是过拟合和缺乏灵活性，正如在(4.4节)中介绍的那样。不可减少的误差是由噪声本身造成的。

## 进行假设检验

统计推断中最常遇到的主题是假设检验。 尽管假设检验在20世纪初期很流行，但最早的使用可以追溯到1700年代的John Arbuthnot。 约翰在伦敦追踪了80年的出生记录，得出的结论是，每年出生的男性多于女性。 之后，现代重要性检验是卡尔·皮尔森发明了p值和皮尔逊卡方检验的智力传承，威廉姆·戈塞特是学生t分布的父亲，罗纳德·费舍尔则提出了原假设和重要性检验。 。

假设检验是一种根据有关人口的默认陈述评估某些证据的方法。 我们将默认语句称为零假设H0，我们尝试使用观察到的数据来拒绝该假设。 在这里，我们以H0作为统计显着性检验的起点。 替代假设HA（或H1）是与原假设相反的陈述。 无效假设通常以陈述性形式陈述，在变量之间存在联系。 它应该尽可能简短地反映摘要，并且可以通过统计理论进行检验。

假设您是一名化学家。 在实验室中花费了数千小时后，您将开发出一种新药，该药可以显着提高人们对数学的理解能力。 要显示其魔力，您需要对其进行测试。 当然，您可能需要一些志愿者来服药，看看它是否可以帮助他们更好地学习数学。 你是如何开始的？

首先，您将需要仔细随机选择两组志愿者，以使他们的数学理解能力之间通过某些指标衡量没有差异。 这两组通常称为测试组和对照组。 测试组（或治疗组）是一组将使用该药物的个人，而对照组则代表被设置为基准的一组用户，即除了服用该药物外，在相同的环境中。 以这种方式，除了自变量在治疗中的影响之外，所有变量的影响被最小化。

其次，在服药一段时间后，您需要使用相同的指标来衡量两组的数学理解，例如让志愿者在学习新的数学公式后进行相同的测试。 然后，您可以收集它们的性能并比较结果。 在这种情况下，我们的零假设将是两组之间没有区别，而我们的替代假设将是存在。

这仍然不完全正式。 您必须仔细考虑许多细节。 例如，什么标准适合测试他们的数学理解能力？ 有多少志愿者为您进行测试，以便您有信心声称自己的药物有效？ 您应该运行多长时间？ 您如何确定两组之间是否存在差异？ 您是否只关心平均表现，还是分数的变化范围？ 等等。

这样，假设检验为实验设计和观察结果确定性的推理提供了框架。 如果现在我们可以证明原假设不可能成立，那么我们可以放心地拒绝它。

为了完成有关如何进行假设检验的故事，我们现在需要引入一些附加术语，并使我们的某些概念超越形式。

### 统计学意义

统计显着性用于衡量不应该拒绝零假设H0H0的概率，即当不拒绝零假设H0H0时，

（18.10.5）

统计显着性= 1−α = 1-P（拒绝H0∣H0为真）。

统计显着性统计显着性=1-α= 1-P（拒绝拒绝H0∣H0是真的是真的）。

也称为I型错误或误报。 αα称为显着性水平，其常用值为5％5％，即1-α= 95％1-α= 95％。 显着性水平可以解释为当我们拒绝真实的零假设时我们愿意承担的风险水平。

图18.10.1显示了在两个样本的假设检验中观察值和给定正态分布的概率。 如果观察数据示例位于95％95％阈值之外，则在原假设假设下，这将是非常不可能的观察。 因此，原假设可能存在问题，我们将予以拒绝。

图18.10.1统计学显著性。

### 统计功效

统计功效（或敏感性）衡量应否决原假设H0H0的可能性，即

（18.10.6）

统计功效= 1−β = 1−P（拒绝H0 rejectH0失败）。

statistics power统计功率= 1−β = 1−P（拒绝失败不拒绝H0∣H0是假是假的）。

回想一下，I类错误是由否定原假设为真而导致的错误，而II类错误是由拒绝原假设为假时未能拒绝而导致的。 II型错误通常表示为ββ，因此相应的统计功效为1-β1-β。

直观地，统计能力可以解释为我们的测试在期望的统计显着性水平上检测到最小最小幅度的真实差异的可能性。 80％80％是常用的统计功效阈值。 统计能力越高，我们越有可能检测出真正的差异。

统计功效的最常见用途之一是确定所需的样本数量。 否定虚假假设时您否定虚假假设的可能性取决于虚假假设的程度（称为效应大小）和样本数量。 如您所料，较小的效应大小将需要非常高的概率检测大量样本。 作为示例，尽管超出了本简短附录的范围，但希望能够拒绝原假设，即我们的样本来自均值零方差一个高斯，并且我们认为样本的均值实际上接近于1。 ，我们可以以可接受的错误率（样本数量仅为88个）进行操作。 但是，如果我们认为样本总体的真实均值接近0.010.01，那么我们需要接近8000080000的样本量来检测差异。

我们可以将电源想象成一个滤水器。 以此类推，高功率假设检验就像高质量的水过滤系统一样，它将尽可能减少水中的有害物质。 另一方面，较小的差异就像是劣质滤水器，其中一些相对较小的物质很容易从间隙中逸出。 同样，如果统计功效不够高，则检验可能不会发现较小的差异。

### 检验统计量

检验统计量T(x)是一个标量，它总结了样本数据的某些特征。定义这样一个统计数据的目的是，它应该允许我们区分不同的分布，并进行我们的假设检验。回想一下我们的化学家的例子，如果我们想要证明一个群体比另一个表现更好，用平均值作为测试统计量是合理的。检验统计量的不同选择会导致统计检验的统计力有很大差异。

通常，T(X)(原假设下检验统计量的分布)至少近似地遵循一个常见的概率分布，如原假设下的正态分布。如果我们可以明确地推导出这样一个分布，然后在数据集上度量我们的测试统计量，那么如果统计量远远超出我们预期的范围，我们就可以安全地拒绝零假设。使这种定量使我们得到pp值的概念。

### p值

pp值(或概率值)是在零假设成立的前提下，T(X)至少与观察到的检验统计量T(X)一样极端的概率，即:

(18.10.7)

假定值= PH0 (T (X)≥T (X))。

假定值——价值= PH0 (T (X)≥T (X))。

如果p-value小于或等于预定义的固定的统计显著性水平，我们可能会拒绝原假设。否则，我们会认为我们缺乏证据来拒绝原假设。对于给定的总体分布，拒绝区域是p值小于统计显著性水平的所有点所包含的区间。

### 单侧测试和双侧测试

一般有两种显著性检验:单侧检验和双侧检验。当原假设和备择假设只有一个方向时，适用单侧检验(单侧检验)。例如，null假设可能声明真实的参数传回传回小于或等于c的值。备择假设是，“25.0”大于“c”也就是说，拒绝区域只在抽样分布的一边。与单侧检验相反，当拒绝区域位于抽样分布的两侧时，可采用双侧检验(或双尾检验)。在这种情况下，一个例子可能有一个null假设状态，即真正的参数宵宵令等于一个值c。备择假设是，这一结果不等于c。

### 假设检验的一般步骤

在熟悉了上述概念之后，让我们来看看假设检验的一般步骤。

1. 陈述问题并建立一个无效假设H0。
1. 设置统计显著性水平(subr)和统计能力(1−xr)。
1. 通过实验获取样本。所需的样本数量将取决于统计能力和预期效应大小。
1. 计算测试统计量和p值。
1. 根据p值和统计显著性水平的预测值，决定是否保留原假设。

为了进行假设检验，我们首先定义无效假设和我们愿意承担的风险水平。 然后，我们以极高的测试统计值作为对原假设的证据，计算样本的测试统计量。 如果检验统计量在拒绝区域内，我们可能会拒绝原假设，而选择另一种假设。

假设测试适用于多种情况，例如临床试验和A / B测试。

## 构造置信区间

当估计一个参数的值时，点估计器，如，因为它们不包含不确定性的概念，所以效用有限。相反，如果我们能够产生一个包含高概率真参数的区间会好得多。如果你在一个世纪前对这类想法感兴趣，那么你一定会兴奋地阅读Jerzy Neyman [Neyman, 1937]的《基于经典概率理论的统计估计理论大纲》，他在1937年首次引入了置信区间的概念。

对于给定的确定性程度，置信区间应该尽可能小。让我们看看如何推导它。

### 定义

在数学上，真实参数θθ的置信区间是从样本数据计算出的区间CnCn

（18.10.8）

Pθ（Cn∋θ）≥1-α，∀θ。

在这里，α∈（0,1和1-α被称为置信度或区间的覆盖度。 这与我们上面讨论的显着性水平相同。

注意（18.10.8）与变量CnCn有关，而不与固定θ有关。 为了强调这一点，我们写Pθ（Cn∋θ）而不是Pθ（θ∈Cn）。

### 解释

我们很容易将95%置信区间解释为一个你可以95%确信真实参数存在的区间，但不幸的是，事实并非如此。true参数是固定的，间隔是随机的。因此，一个更好的解释是，如果你用这个程序生成了大量的置信区间，95%生成的区间将包含真参数。

这可能看起来有点迂腐，但对结果的解释却有实际的意义。特别是，我们可以通过构造几乎肯定不包含真值的区间来满足(18.10.8)，只要我们很少这样做。我们通过提供三个诱人但不真实的陈述来结束这一节。对这些观点的深入讨论可以在[Morey et al.， 2016]中找到。

* 谬论1。狭窄的置信区间意味着我们可以准确地估计参数。
* 谬论2。置信区间内的值比区间外的值更有可能是真实值。
* 谬论3。一个特定观察到的置信区间包含真值的概率是。

可以这么说，置信区间是很微妙的东西。然而，如果你能保持清晰的解释，它们可以成为强大的工具。

## 一个Gaussian的例子

让我们讨论一个最经典的例子，一个未知均值和方差的高斯均值的置信区间。假设我们从我们的高斯N(沉降，uscl2)N(沉降，uscl2)中收集了{xi}ni=1{xi}i=1n样本。我们可以通过取，计算均值和标准差的估计量

对该分布进行了很好的研究，例如，已知n→∞n→∞近似为标准高斯分布，因此可以通过查找高斯c.d.f的值来确定。 在表中，我们可以得出结论：至少有95％的时间，TT的值在[-1.96,1.96]区间内。 对于n的有限值，间隔需要稍大一些，但是众所周知并且在表中已预先计算。

因此，我们可以得出结论，对于大n，

TODO:MATH

重新安排通过两边乘以σ^ n / n−−√σ^ n / n,然后添加μ^ nμ^ n,我们获得

TODO:MATH

因此我们知道我们已经找到了95%置信区间:

TODO:MATH

可以肯定地说(18.10.13)是统计学中最常用的公式之一。让我们通过实现它来结束对统计的讨论。为了简单起见，我们假设我们在渐近范围内。NN的小值应该包括通过编程或从tt表获得的t_star的正确值。

TODO:CODE

## 小结

* 统计专注于推理问题，而深度学习则强调在没有明确编程和理解的情况下做出准确的预测。
* 共有三种常用的统计推断方法：评估和比较估计量，进行假设检验以及构建置信区间。
* 共有三种最常见的估算器：统计偏差，标准差和均方误差。
* 置信区间是可以通过给定样本来构造的真实总体参数的估计范围。
* 假设检验是一种根据人口的默认陈述评估某些证据的方法。

## 练习

令X1,X2，…，Xn∼iidUnif(0，θ)，其中iid表示独立同分布。考虑以下对“观后感”的估计:

(18.10.14)

θ^ = max {X1, X2,…, Xn};

(18.10.15)

θ~ 2 n = 2 xn¯=∑nxi i = 1。


求出统计偏差、标准差和均方误差。

哪个估计量更好?

对于我们介绍中的化学家的例子，你能推导出进行双面假设检验的5个步骤吗?考虑到统计学显著性水平，因此，受试者的统计能力为:1−漠视=0.81−漠视=0.8。

对于100个独立生成的数据集，使用N=2和subrev =0.5运行置信区间代码，并绘制结果区间(在本例中t_star = 1.0)。你会看到几个非常短的间隔，它们离真正的平均值0很远。这是否与置信区间的解释相矛盾?您觉得使用短的间隔来表示高精度的估计合适吗?
