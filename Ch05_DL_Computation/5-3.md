

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-07-23 00:11:55
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-07-23 00:20:32
 * @Description:translate by machine
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_deep-learning-computation/deferred-init.html
 * https://zh.d2l.ai/chapter_deep-learning-computation/deferred-init.html
-->

# 模型参数的延后初始化

到目前为止，我们似乎没有因为草率地建立我们的网络而受到惩罚。具体来说，我们做了下面这些违反直觉的事情，这些事情看起来似乎不应该起作用:

* 我们定义了网络结构，但没有指定输入维度。
* 我们添加了层，但没有指定前一层的输出尺寸。
* 我们甚至在提供足够的信息来确定我们的模型应该包含多少参数之前“初始化”这些参数。

您可能会对我们的代码能够运行感到惊讶。毕竟，MXNet 和 TensorFlow 不可能知道网络的输入维度是什么。这里的诀窍是，两个框架都推迟初始化，直到我们第一次通过模型传递数据时，才动态推断每个层的大小。

随后，当使用卷积神经网络时，这种技术将变得更加方便，因为输入维度(即图像的分辨率)将影响每个后续层的维度。因此，在编写代码时，无需知道维数是什么，就可以设置参数，从而大大简化指定和随后修改模型的任务。接下来，我们将更深入地讨论初始化的机制。

如果做了上一节练习，你会发现模型net在调用初始化函数initialize之后、在做前向计算net(X)之前时，权重参数的形状中出现了0。虽然直觉上initialize完成了所有参数初始化过程，然而这在Gluon中却是不一定的。我们在本节中详细讨论这个话题。

## 实例化一个网络

首先，让我们实例化一个 MLP。

TODO:CODE

此时，网络不可能知道输入层权重的大小，因为输入层的大小仍然是未知的。因此框架还没有初始化任何参数。我们尝试访问下面的参数来确认。

TODO:CODE

注意，虽然参数对象存在，但是每个层的输入维度都列为 -1。MXNet 使用特殊值-1表示参数维度仍然未知。此时，尝试访问 net [0]。Data ()将触发一个运行时错误，指出必须在访问参数之前初始化网络。现在让我们看看当我们尝试通过 initialize 方法来初始化参数时会发生什么。

TODO:CODE

如我们所见，一切都没有改变。当输入维度未知时，对初始化的调用不会真正初始化参数。取而代之的是，我们希望(并且可选地，根据哪个分布)初始化参数的 MXNet 的这个呼叫寄存器。

一旦我们知道了输入维度x∈R20，框架就可以识别第一层的权重矩阵的形状，即W1∈R256×20。识别出第一层形状后，框架将前进至第二层，其尺寸为10×256，依此类推，直到计算出所有形状为止。请注意，在这种情况下，仅第一层需要延迟初始化，但是框架按顺序进行初始化。一旦知道所有参数形状，框架就可以最终初始化参数。

## 小结

* 延迟初始化很方便，允许框架自动推断参数形状，使修改架构变得容易，并消除一个常见的错误来源。

## 练习

1. 如果您指定了第一层的输入尺寸，但没有指定后续层的尺寸，会发生什么?是否立即进行初始化?
1. 如果指定了不匹配的维度会发生什么?
1. 如果输入是不同维度的，你需要做什么?提示:查看参数绑定。
