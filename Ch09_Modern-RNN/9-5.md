

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-29 21:34:28
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-29 21:41:14
 * @Description:Machine translation (MT)
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_recurrent-modern/machine-translation-and-dataset.html
-->

# 机器翻译和数据集

到目前为止，我们已经了解了如何将递归神经网络用于语言模型，其中我们根据文章中的所有先前标记来预测下一个标记。现在让我们看一下另一种应用程序，机器翻译，其预测输出不再是单个标记，而是一个标记列表。

机器翻译（MT）是指将一段文本从一种语言自动翻译为另一种语言。用神经网络解决这个问题通常称为神经机器翻译（NMT）。与语料库只包含一种语言的语言模型（第8.3节）相比，机器翻译数据集至少具有两种语言，即源语言和目标语言。另外，将源语言中的每个句子映射到目标语言中的相应翻译。因此，机器翻译数据的数据预处理与语言模型的数据预处理不同。本节专门演示如何预处理这样的数据集，然后将其加载到一组迷你批处理中。

TODO:CODE

## 读取和预处理数据集

我们首先下载一个数据集，其中包含一组带有相应法语翻译的英语句子。可以看到，每一行包含一个英语句子及其法语翻译，由一个制表符分隔。

TODO:CODE

我们对原始文本数据执行了几个预处理步骤，包括忽略大小写、用空格替换UTF-8非断行空格以及在单词和标点符号之间添加空格。

TODO:CODE

## 标记化

与第8.3节中使用字符标记不同，此处标记是单词或标点符号。以下函数标记文本数据以返回源和目标。每个是令牌列表的列表，其中source [i]是源语言中的第ith个句子，而target [i]是目标语言中的第ith个句子。为了使后面的训练更快，我们对前num_examples个句子对进行采样。

TODO:CODE

在下面的图中，我们将每个句子的标记数的柱状图可视化。可以看出，一个句子平均包含5个记号，大多数句子的记号少于10个。

TODO:CODE

## 词汇表

由于源语言中的标记可能与目标语言中的标记不同，因此我们需要为每个标记构建一个词汇表。由于我们使用单词而不是字符作为标记，这使得词汇表的大小非常大。这里，我们将出现少于3次的每个令牌映射到<unk>令牌节8.2中。此外，我们还需要其他特殊的标记，比如填充和句子开头。

## 加载数据集

在语言模型中，每个示例都是来自语料库的num_steps长度序列，它可能是句子的一个片段，也可能跨越多个句子。在机器翻译中，一个例子应该包含一对源句和目标句。这些句子可能有不同的长度，而我们需要相同长度的例子来组成一个小批。

解决这个问题的一种方法是，如果一个句子比num_steps长，我们就修剪它的长度，否则用特殊的<pad>标记填充以满足长度。因此，我们可以将任何句子转换为固定长度。

TODO:CODE

现在我们可以将一个句子列表转换为一个(num_example, num_steps)索引数组。我们还记录没有填充标记的每个句子的长度，称为有效长度，这可能被一些模型使用。此外，我们在目标句中添加特殊的“<bos>”和“<eos>”符号，使我们的模型能够知道开始和结束预测的信号。

TODO:CODE

然后我们可以基于这些数组构造小批量。

## 汇总一切

最后，我们定义函数load_data_nmt来返回带有源语言和目标语言词汇表的数据迭代器。

TODO:CODE

让我们来读第一批。

TODO:CODE

## 总结

机器翻译(MT)是指将一段文本从一种语言自动翻译到另一种语言。

我们从源语言和目标语言中读取、预处理和标记数据集。

## 练习

在线找到一个机器翻译数据集并处理它。
