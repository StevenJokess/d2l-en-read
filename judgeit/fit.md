

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-10-09 14:02:10
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-10-09 14:37:37
 * @Description:
 * @TODO::
 * @Reference:[1]: https://www.cnblogs.com/nxf-rabbit75/p/10152099.html
 * [2]: https://machine-learning-from-scratch.readthedocs.io/zh_CN/latest/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98.html#id46
-->

## 泛化能力

泛化能力指的是训练得到的模型对未知数据的预测能力。我们建模的目的是让模型不仅对已知数据，而且对未知数据都能有较好的预测能力。对模型预测能力的评估，可以通过样本上的训练误差和测试误差来估计。这里有三个概念：

损失函数：度量预测错误程度的函数
训练误差：训练数据集上的平均损失，虽然有意义，但本质不重要
测试误差：测试数据集上的平均损失，反应了模型对未知数据的预测能力
我们通常利用最小化训练误差的原则来训练模型，但真正值得关心的是测试误差。一般情况下我们通过测试误差来近似估计模型的泛化能力。对于一个好的模型，其训练误差约等于泛化误差。


3. Bias-Variance
3.1 偏差和方差
偏差：the difference between your model’s expected predictions and the true values. 衡量了模型期望输出与真实值之间的差别，刻画了模型本身的拟合能力。

方差：refers to your algorithm’s sensitivity to specific sets of training data. High variance algorithms will produce drastically different models depending on the training set. 度量了训练集的变动所导致的学习性能的变化，刻画了模型输出结果由于训练集的不同造成的波动。

_images/偏差方差1.png
高偏差，低方差的算法在不同训练集上训练得到的模型基本一致，但预测值与真实值差距较大；高方差，低偏差的算法得到的模型的预测值和真实值差距小，但在不同训练集上得到的模型输出波动大。

噪音：度量了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度。

3.2 误差分解
_images/误差分解.png
如上图，泛化误差可以分解为偏差、方差和噪声之和。

偏差-方差分解表明：泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度共同决定的。

偏差、方差与模型容量有关。用 MSE 衡量泛化误差时，增加容量会增加方差、降低偏差。

偏差降低，是因为随着容量的增大，模型的拟合能力越强：对给定的训练数据，它拟合的越准确。
方差增加，是因为随着容量的增大，模型的随机性越强：对不同的训练集，它学得的模型可能差距较大。
一般来说，偏差和方差是由冲突的，这称作偏差-方差窘境 bias-variance dilemma 。

给定学习任务：

在训练不足时模型的拟合能力不够强，训练数据的扰动不足以使模型产生显著变化，此时偏差主导了泛化误差。
随着训练程度的加深，模型的拟合能力逐渐增强，训练数据发生的扰动逐渐被模型学习到，方差逐渐主导了泛化误差。
在训练充分后模型的拟合能力非常强，训练数据发生的轻微扰动都会导致模型发生显著变化。
若训练数据自身的、非全局的特性被模型学到了，则将发生过拟合。
3.3 误差诊断
偏差-方差可以反映模型的过拟合与欠拟合。
D
高偏差对应于模型的欠拟合：模型过于简单，以至于未能很好的学习训练集，从而使得训练误差过高。例如，用 linear regression 去拟合非线性的数据集。此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。
高方差对应于模型的过拟合：模型过于复杂，以至于将训练集的细节都学到，将训练集的一些细节当做普遍的规律，从而使得测试集误差与训练集误差相距甚远。例如，不做任何剪枝的决策树，可以在任何训练集上做到极高的准确率。此时模型预测的偏差较小，表示预测较准确。但是模型预测的方差较大，表示预测较不稳定。
通过训练误差和测试误差来分析模型是否存在高方差、高偏差。

如果训练误差较高：说明模型的方差较大，模型出现了欠拟合。
如果训练误差较低，而训练误差较高：说明模型的偏差较大，出现了过拟合。
如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。
如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。
上述分析的前提是：训练集、测试集的数据来自于同一个分布，且噪音较小。

3.4 误差缓解
过拟合和欠拟合的解决方法很多，并且针对不同算法有不同的方法。有时间系统的梳理一遍，这里只是简单罗列一些方法。

_images/过拟合欠拟合4.png
如果模型存在高偏差（欠拟合），则通过以下策略可以缓解：

选择一个容量更大、更复杂的模型。
增加更多有预测能力的强特征。
如果模型存在高方差（过拟合），则通过以下策略可以缓解：

数据清洗，避免由于噪音数据导致的模型问题。
增加更多的训练数据。它通过更多的训练样本来对模型参数增加约束，会降低模型容量。
使用正则化。在模型的优化目标里加入正则化项来对模型参数增加约束，以此降低模型复杂度。
神经网络中，可以增加 Dropout层，即让一部分的神经元以一定概率不工作。
神经网络中，还可以通过 Early Stopping 避免过拟合。在神经网络的训练过程中我们会初始化权值参数，此时模型的拟合能力较弱，通过迭代训练来提高模型的拟合能力。当验证集上的误差没有进一步改善时，算法提前终止。
集成学习，利用多个学习器组合在一起做出决策，弱化每个单独模型的特性。
对于决策树算法，剪枝是有效的防止过拟合手段。预剪枝通过在训练过程中控制树深、叶子节点数、叶子节点中样本的个数等来控制树的复杂度。后剪枝则是在训练好树模型之后，采用交叉验证的方式进行剪枝以找到最优的树模型。



7.过拟合与欠拟合
问题1：在模型评估过程中，过拟合和欠拟合具体是指什么现象？
过拟合是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练集上的表现很好，但在测试集和新数据上的表现较差；

欠拟合指的是模型在训练和预测时表现到不好的情况。



问题2：能否说出几种降低过拟合和欠拟合风险的方法？
降低“过拟合”的方法：

（1）获得更多的训练数据

（2）降低模型复杂度

（3）正则化方法

（4）集成学习方法

降低“欠拟合”风险的方法：

（1）添加新特征

（2）增加模型复杂度

（3）减小正则化系数
