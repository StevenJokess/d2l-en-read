{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-DCGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6GHBthrdrU7",
        "outputId": "ffeef45b-7716-464e-f09c-e138a9de074f"
      },
      "source": [
        "!pip install -q git+https://github.com/d2l-ai/d2l-en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for d2l (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZd3ry8Ld0lv"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from d2l import tensorflow as d2l"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA11pSUld24B",
        "outputId": "607d9d42-7273-4dda-c1e0-0c5c741b26dc"
      },
      "source": [
        "#@save\n",
        "d2l.DATA_HUB['pokemon'] = (d2l.DATA_URL + 'pokemon.zip',\n",
        "                           'c065c0e2593b8b161a2d7873e42418bf6a21106c')\n",
        "\n",
        "data_dir = d2l.download_extract('pokemon')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ../data/pokemon.zip from http://d2l-data.s3-accelerate.amazonaws.com/pokemon.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z045j-STeEHj"
      },
      "source": [
        "batch_size = 256"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "JuzcCbXteHiG",
        "outputId": "12461594-ca47-47e5-c3ad-ceebdc42821f"
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8e92e93ce06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2jL-0T5eNRK",
        "outputId": "8303fd1d-d452-418c-8494-e936b97d46de"
      },
      "source": [
        "pip install -q tensorflow_addons"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 28.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 33.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 36.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 36.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 38.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 29.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 28.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 25.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 26.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 26.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phOEyosmeXvf"
      },
      "source": [
        "https://www.tensorflow.org/addons/api_docs/python/tfa/image/transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6TgzhS1fF8U"
      },
      "source": [
        "In TF 2.0 whole tf.contrib.* is dropped.\n",
        "\n",
        "For instance, I was using those in my custom augmentation mechanisms to add rotation and shear transforms (along with all zooms, shifts, flips, etc). And in TF 2.0 I see no way to perform those.\n",
        "\n",
        "I tried to implement such a functionality with numpy+opencv instead of TF. However when I tried injecting such a functionality to tf.dataset.map() pipeline tensors seemed not to have .nupmy() method yet.\n",
        "\n",
        "https://github.com/tensorflow/tensorflow/issues/33335"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXrHGDrRhhZx"
      },
      "source": [
        "https://www.tensorflow.org/s/results?q=resize\n",
        "tf.image.resize(image, [3,5])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03WO9awlh0kQ"
      },
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "CH5u4fM_iEwr",
        "outputId": "18b783e3-b086-4605-bb94-4fc442f117ea"
      },
      "source": [
        "pokemon_folder = tfds.folder_dataset.ImageFolder(data_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f2b800fad7c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpokemon_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-qwGWmNiG_u"
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lORDroHNiIr6"
      },
      "source": [
        "pokemon_folder = tfds.folder_dataset.ImageFolder(data_dir)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHbYsrlui13_",
        "outputId": "f505e226-2250-4fcc-917e-94899ef1e6ca"
      },
      "source": [
        "dir(pokemon_folder)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BUILDER_CONFIGS',\n",
              " 'MANUAL_DOWNLOAD_INSTRUCTIONS',\n",
              " 'RELEASE_NOTES',\n",
              " 'SUPPORTED_VERSIONS',\n",
              " 'VERSION',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__cached_canonical_version',\n",
              " '__cached_info',\n",
              " '__cached_supported_versions',\n",
              " '__cached_versions',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_as_dataset',\n",
              " '_build_data_dir',\n",
              " '_build_single_dataset',\n",
              " '_builder_config',\n",
              " '_create_builder_config',\n",
              " '_data_dir',\n",
              " '_data_dir_root',\n",
              " '_download_and_prepare',\n",
              " '_image_dtype',\n",
              " '_image_shape',\n",
              " '_info',\n",
              " '_log_download_bytes',\n",
              " '_log_download_done',\n",
              " '_make_download_manager',\n",
              " '_original_state',\n",
              " '_pick_version',\n",
              " '_relative_data_dir',\n",
              " '_should_cache_ds',\n",
              " '_split_examples',\n",
              " '_version',\n",
              " 'as_dataset',\n",
              " 'builder_config',\n",
              " 'builder_configs',\n",
              " 'canonical_version',\n",
              " 'code_path',\n",
              " 'data_dir',\n",
              " 'download_and_prepare',\n",
              " 'info',\n",
              " 'name',\n",
              " 'supported_versions',\n",
              " 'url_infos',\n",
              " 'version',\n",
              " 'versions']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cceU25Jah5rb"
      },
      "source": [
        "transformer = keras.Sequential(\n",
        "    [\n",
        "     preprocessing.Resizing(64, 64),\n",
        "     tf.convert_to_tensor\n",
        "     preprocessing.Normalization(mean = 0.5, variance = 0.5),\n",
        "    ])\n",
        "transformer.adapt(pokemon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B4gKN5VeFV8"
      },
      "source": [
        "transformer = "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}