

<!--
 * @version:
 * @Author:  StevenJokess https://github.com/StevenJokess
 * @Date: 2020-07-16 23:02:43
 * @LastEditors:  StevenJokess https://github.com/StevenJokess
 * @LastEditTime: 2020-07-16 23:24:41
 * @Description:translate by machine
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_convolutional-modern/alexnet.html
-->


# 深度卷积神经网络(AlexNet)

虽然卷积神经网络在 LeNet 引入后，在计算机视觉和机器学习领域已经广为人知，但它们并没有立即在这一领域占据统治地位。虽然 LeNet 在早期的小数据集上取得了良好的效果，但是在更大、更真实的数据集上训练卷积网络的性能和可行性还有待于进一步研究。事实上，从20世纪90年代初到2012年的分水岭结果期间的大部分时间里，神经网络经常被其他机器学习方法超越，比如支持向量机。

对于计算机视觉来说，这种比较也许是不公平的。也就是说，虽然卷积网络的输入是由原始或轻度处理的像素值组成(例如，通过居中) ，但是从业者绝不会将原始像素输入到传统模型中。相反，典型的计算机视觉管道由人工工程特征提取管道组成。而不是学习功能，功能是精心制作的。大部分的进步来自于对特性有了更聪明的想法，而学习算法往往被放在事后考虑。

虽然一些神经网络加速器在20世纪90年代已经出现，但它们还不够强大，不足以构成具有大量参数的深多通道、多层卷积神经网络。此外，数据集仍然相对较小。除了这些障碍，训练神经网络的关键技巧，包括参数初始化启发法，随机梯度下降的巧妙变体，非挤压激活函数，以及有效的正规化技术仍然缺失。

因此，经典的管道系统看起来更像这样，而不是端到端(像素到分类)系统的培训:

1. 获取一个有趣的数据集。在早期，这些数据集需要昂贵的传感器(当时，100万像素的图像是最先进的)。
1. 基于一些光学、几何学、其他分析工具的知识，偶尔基于幸运的研究生偶然的发现，用手工制作的特征对数据集进行预处理。
1. 通过一组标准的特性提取器提供数据，比如 SIFT、尺度不变特征转换、 SURF、加速稳健特征或者其他任何手工调优的管道。

如果你和机器学习的研究人员交谈，他们认为机器学习既重要又美好。优雅的理论证明了各种量词的性质。机器学习领域蓬勃发展，严谨而且非常有用。然而，如果你和计算机视觉研究人员交谈，你会听到一个完全不同的故事。他们会告诉你，图像识别的肮脏真相是，推动进步的是特征，而不是学习算法。计算机视觉研究人员无可非议地认为，对于最终的准确性来说，一个稍微大一点或者更干净一点的数据集或者一个稍微改进的特征提取流水线要比任何学习算法重要得多。

## 学习特征表示

另一种描述事态的方式是管道中最重要的部分是代表性。直到2012年，这一比例还是机械计算的。实际上，设计一套新的特征函数，改进结果，并编写该方法是一个突出的论文体裁。SIFT，SURF，HOG，袋子的视觉文字和类似的特征提取器占据了主导地位。

另一组研究人员，包括扬 · 勒昆、杰夫 · 欣顿、约舒亚 · 本吉奥、安德鲁 · 吴、山市顺一和尤尔根 · 施密德胡贝尔，有着不同的计划。他们认为特征本身应该被学习。此外，他们认为，为了使特征相当复杂，应该由多个联合学习的层次分层次地组成，每个层次都有可学习的参数。对于图像，最低的图层可能用来检测边缘、颜色和纹理。事实上，Krizhevsky 等人在2012年提出了一个新的卷积神经网络的变体，它在 ImageNet 的挑战中取得了优异的性能。

有趣的是，在网络的最底层，模型学习了类似于传统过滤器的特性提取器。图7.1.1是从本文中复制的，并描述了较低层次的图像描述符。

网络中的更高层可能建立在这些表示之上，以代表更大的结构，如眼睛、鼻子、草叶等等。甚至更高的层可能代表整个物体，如人，飞机，狗，或飞盘。最终，最终的隐藏状态学习图像的紧凑表示形式，该表示形式汇总了图像的内容，从而使属于不同类别的数据易于分离。

虽然多层卷积网络的最终突破出现在2012年，但一个核心研究小组致力于这个想法，多年来一直试图学习视觉数据的分层表示。2012年的最终突破可以归功于两个关键因素。

### 缺失的原料-数据

具有多层次的深度模型需要大量的数据，以便进入它们明显优于基于凸优化的传统方法(如线性方法和核方法)的阶段。然而，考虑到计算机有限的存储容量、传感器相对昂贵的费用以及20世纪90年代相对紧张的研究预算，大多数研究依赖于微小的数据集。许多论文讨论了 UCI 数据集的收集，其中许多只包含数百或(少数)数千图像捕获在非自然的设置低分辨率。

2009年，ImageNet 数据集发布，挑战研究人员从100万个例子中学习模型，每个例子1000个不同类别的对象。由李领导的研究人员引入了这个数据集，利用谷歌图像搜索对每个类别的大型候选集进行预过滤，并使用亚马逊土耳其机器人众包管道来确认每张图片是否属于相关类别。这种规模是前所未有的。相关的竞赛，被称为 ImageNet 挑战，推动了计算机视觉和机器学习的研究向前发展，挑战研究人员，以确定哪些模型表现最好，在一个更大的规模比学者以前考虑的。

### 缺失的原料-硬件

深度学习模型是计算周期的贪婪消费者。训练可能需要数百个时代，每次迭代都需要通过许多层次的计算代价昂贵的线性代数操作来传递数据。这就是为什么在90年代和2000年代早期，基于更有效地优化凸目标的简单算法会受到青睐的主要原因之一。

图形处理单元(gpu)被证明是使深度学习成为可能的游戏规则改变者。这些芯片早已被开发用于加速图形处理以利于电脑游戏。特别是，它们针对高吞吐量的4x4矩阵向量产品进行了优化，而这些产品是许多计算机图形学任务所需要的。幸运的是，这种数学方法与计算卷积层所需的数学方法惊人地相似。在那个时候，NVIDIA 和 ATI 已经开始为一般的计算操作优化 gpu，甚至将它们作为通用 gpu (GPGPU)推向市场。

为了提供一些直觉，考虑一下现代微处理器(CPU)的核心。每个核心都以高时钟频率运行，并运行大型缓存(最高可达几 MB 的 L3)。每个核心都非常适合执行广泛的指令，具有分支预测器、深层管道和其他使其能够运行大量程序的附加功能。然而，这种表面上的优势也是它的致命弱点: 通用型核心的制造成本非常昂贵。它们需要大量的芯片面积，复杂的支持结构(内存接口、内核之间的缓存逻辑、高速互连等) ，而且它们在任何单一任务上都相对较差。现代笔记本电脑有多达4个内核，甚至高端服务器也很少超过64个内核，这仅仅是因为它不划算。

相比之下，GPU由100-1000个小型处理元件组成（NVIDIA，ATI，ARM和其他芯片供应商之间的细节有所不同），通常分为较大的组（NVIDIA称其为翘曲）。尽管每个内核都相对较弱，有时甚至以低于1GHz的时钟频率运行，但正是这些内核的总数使GPU的速度比CPU快了几个数量级。例如，NVIDIA的最新一代Volta可以为每个芯片提供多达120 TFlops的专用指令（对于通用指令则可以提供24 TFlops），而到目前为止，CPU的浮点性能没有超过1 TFlop。做到这一点的原因实际上很简单：首先，功耗趋于随时钟频率呈二次方增长。因此，对于运行速度提高4倍（典型值）的CPU内核的功率预算，您可以以1/4的速度使用16个GPU内核，从而获得16 x 1/4 = 4倍的性能。此外，GPU内核要简单得多（实际上，很长时间以来，它们甚至无法执行通用代码），这使它们更加节能。最后，深度学习中的许多操作都需要高存储带宽。同样，GPU在这里的亮点在于总线的宽度至少是许多CPU的10倍。

回到2012年。AlexKrizhevsky和Ilya Sutskever实现了可以在GPU硬件上运行的深度卷积神经网络，这是一个重大突破。他们意识到，CNN的计算瓶颈（卷积和矩阵乘法）都是可以在硬件中并行化的操作。他们使用两个具有3GB内存的NVIDIA GTX 580，实现了快速卷积。代码cuda-convnet足够好，几年来一直是行业标准，并推动了深度学习热潮的头几年。

AlexNet和LeNet的设计理念非常相似，但也有很大的不同。首先，AlexNet比规模相对较小的LeNet5更深层次。AlexNet由8层组成:5个卷积层，两个完全连接的隐藏层和一个完全连接的输出层。其次，AlexNet使用ReLU而不是sigmoid作为激活函数。让我们深入下面的细节。

## 架构

在AlexNet的第一层中，卷积窗口形状为11×11。由于ImageNet中的大多数图像比MNIST图像高和宽十倍以上，因此ImageNet数据中的对象往往会占据更多像素。因此，需要更大的卷积窗口来捕获对象。第二层中的卷积窗口形状减小为5×5，然后减小为3×3。另外，在第一，第二和第五卷积层之后，该网络添加了最大池化层，其窗口形状为3×3，跨度为2。此外，AlexNet的卷积通道数是LeNet的十倍。

在最后一个卷积层之后，有两个具有4096个输出的完全连接的层。这两个巨大的全连接层产生近1 GB的模型参数。由于早期GPU的内存有限，原始的AlexNet使用双重数据流设计，因此两个GPU的每个只能负责存储和计算模型的一半。幸运的是，GPU内存现在相对充足，因此，如今我们几乎不需要在GPU上分解模型（在这方面，我们的AlexNet模型版本与原始论文有所不同）。

## 激活函数

其次，AlexNet将S形激活功能更改为更简单的ReLU激活功能。一方面，ReLU激活函数的计算更简单。例如，它没有在S型激活函数中发现的幂运算。另一方面，当使用不同的参数初始化方法时，ReLU激活功能使模型训练更加容易。这是因为，当S型激活函数的输出非常接近0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新某些模型参数。相反，ReLU激活函数在正区间中的梯度始终为1。因此，如果未正确初始化模型参数，则S型函数可能会在正区间中获得几乎为0的梯度，因此模型不能 有效地训练。

## 复杂度控制和预处理

AlexNet通过丢弃控制完全连接层的模型复杂性（第4.6节），而LeNet仅使用权重衰减。为了进一步增强数据，AlexNet的训练循环添加了大量图像增强功能，例如翻转，剪切和颜色更改。这使模型更加健壮，并且更大的样本数量有效地减少了过度拟合。我们将在13.1节中更详细地讨论数据增强。

TODO:CODE

我们构建一个高度和宽度都为224的单通道数据点来观察每一层的输出形状。它与上面的图表相匹配。

TODO:CODE

## 读取数据集

尽管AlexNet在本文中使用ImageNet，但我们在这里使用Fashion-MNIST，因为即使在现代GPU上训练ImageNet模型来收敛也可能需要数小时或数天。直接在Fashion-MNIST上应用AlexNet的问题之一是，我们的图像比ImageNet图像的分辨率更低（28×28像素）。为了使事情正常进行，我们将它们升采样到224×224224×224（通常不是明智的做法，但是我们在这里这样做是为了忠实于AlexNet架构）。我们使用load_data_fashion_mnist中的resize参数执行此大小调整。

TODO:CODE

## 训练

现在，我们可以开始训练AlexNet。与上一节中的LeNet相比，这里的主要变化是使用更小的学习速率和更慢的训练，这是因为网络更深入，更广泛，图像分辨率更高以及卷积代价更高。

TODO:CODE

## 小结

* AlexNet具有与LeNet类似的结构，但是使用了更多的卷积层和更大的参数空间来适应大规模数据集ImageNet。
* 今天，AlexNet已经被更有效的架构超越，但它是一个关键的一步，从浅到深的网络，现在使用的。
* 虽然在AlexNet的实现中似乎只比LeNet多几行代码，但学术界花了许多年时间来接受这种概念上的改变，并利用其出色的实验结果。这也是由于缺乏有效的计算工具。
* Dropout, ReLU和预处理是在计算机视觉任务中取得优异表现的其他关键步骤。

## 练习

1. 试着增加纪元的数目。和莱内相比，结果有什么不同?为什么?
1. AlexNet对于时尚专家数据集来说可能太复杂了。
   1. 尽量简化模型，使训练速度更快，同时确保准确性不会显著下降。
   1. 你能设计一个更好的模型直接在28×2828×28的图像上工作吗?
1. 修改批大小，并观察在准确性和GPU内存的变化。
. 风格:
   1. 什么是占主导地位的内存足迹的AlexNet?
   1. 在AlexNet中计算的主导部分是什么?
   1. 当计算结果时内存带宽如何?
1. 对LeNet5应用dropout和ReLU。改善吗?预处理怎么样?
