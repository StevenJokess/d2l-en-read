

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-17 00:36:46
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-17 00:52:52
 * @Description:
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/master/chapter_convolutional-modern/googlenet.html
 * https://zh.d2l.ai/chapter_convolutional-neural-networks/googlenet.html
-->

# 含并行连结的网络（GoogLeNet）

在2014年，[ Szegedy 等人，2015]赢得了 ImageNet 挑战赛，提出了一个结构，结合了 NiN 和重复模块的优势。本文的一个重点是解决大小卷积内核最佳的问题。毕竟，以前流行的网络选择的范围小到1111，大到11111111。本文中的一个观点是，有时使用不同大小的内核的组合是有利的。在本节中，我们将介绍 GoogLeNet，提出原模型的一个稍微简化的版本ーー我们省略了一些为了稳定培训而添加的特殊功能，但是现在已经有了更好的培训算法，这些功能是不必要的。

## Inception 块

GoogLeNet 的基本卷积块被称为“盗梦空间块”(Inception block) ，这个名字很可能是引用了电影《盗梦空间》(Inception)中的一句话(“ We Need To Go Deeper”) ，这句话引发了一场病毒式的文化迷因。

Inception块的结构

由上图所示，Inception块里有4条并行的线路。前3条线路使用窗口大小分别是 1×1 、 3×3 和 5×5 的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做 1×1 卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用 3×3 最大池化层，后接 1×1 卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结，并输入接下来的层中去。

TODO:CODE

为了获得一些直觉为什么这个网络工作得这么好，考虑一下过滤器的组合。他们在不同的范围内探索图像。这意味着不同程度的细节可以被不同的过滤器有效地识别。同时，我们可以为不同的范围分配不同数量的参数(例如，对于短范围分配更多的参数，但不能完全忽略长范围)。

Inception块中可以自定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。
和以前一样，我们使用Fashion-MNIST数据集训练模型。 在调用训练程序之前，我们将其转换为96×96像素分辨率。

TODO:CODE

## GoogLeNet模型

Net 和 LeNet 相同，堆栈的块是继承自 VGG 和全局平均池避免堆栈的完全连接的层结束。建筑如下图所示。

GoogLeNet跟VGG一样，在主体卷积部分中使用5个模块（block），每个模块之间使用步幅为2的 3×3 最大池化层来减小输出高宽。第一模块使用一个64通道的 7×7 卷积层。

TODO:CODE

第二模块使用2个卷积层：首先是64通道的 1×1 卷积层，然后是将通道增大3倍的 3×3 卷积层。它对应Inception块中的第二条线路

TODO:CODE

第三模块串联2个完整的Inception块。第一个Inception块的输出通道数为 64+128+32+32=256 ，其中4条线路的输出通道数比例为 64:128:32:32=2:4:1:1 。其中第二、第三条线路先分别将输入通道数减小至 96/192=1/2 和 16/192=1/12 后，再接上第二层卷积层。第二个Inception块输出通道数增至 128+192+96+64=480 ，每条线路的输出通道数之比为 128:192:96:64=4:6:3:2 。其中第二、第三条线路先分别将输入通道数减小至 128/256=1/2 和 32/256=1/8 。

TODO:CODE

第四模块更加复杂。它串联了5个Inception块，其输出通道数分别是 192+208+48+64=512 、 160+224+64+64=512 、 128+256+64+64=512 、 112+288+64+64=528 和 256+320+128+128=832 。这些线路的通道数分配和第三模块中的类似，首先是含 3×3 卷积层的第二条线路输出最多通道，其次是仅含 1×1 卷积层的第一条线路，之后是含 5×5 卷积层的第三条线路和含 3×3 最大池化层的第四条线路。其中第二、第三条线路都会先按比例减小通道数。这些比例在各个Inception块中都略有不同。

TODO:CODE

第五模块有输出通道数为 256+320+128+128=832 和 384+384+128+128=1024 的两个Inception块。其中每条线路的通道数的分配思路和第三、第四模块中的一致，只是在具体数值上有所不同。需要注意的是，第五模块的后面紧跟输出层，该模块同NiN一样使用全局平均池化层来将每个通道的高和宽变成1。最后我们将输出变成二维数组后接上一个输出个数为标签类别数的全连接层。

TODO:CODE

GoogLeNet模型的计算复杂，因此修改通道数不如VGG那样容易。 为了在Fashion-MNIST上有合理的培训时间，我们将输入的高度和宽度从224减少到96。这简化了计算。 下面说明了各个模块之间输出形状的变化。

TODO:CODE

## 训练模型

像之前一样，我们用Fashion-MNIST数据集训练我们的模型。在调用训练程序之前，我们将其转换为96×96像素分辨率。

TODO:CODE

## 小结

* Inception块相当于一个有四个路径的子网。它通过不同窗口形状的卷积层和最大池层并行提取信息。1×11×1卷积在每像素级别上降低信道维数。最大池降低了分辨率。
* GoogLeNet将多个精心设计的Inception模块与其他层串联起来。在ImageNet数据集上进行大量实验，得到初始块中分配的通道数的比值。
* GoogLeNet及其后续版本是ImageNet上最高效的模型之一，在较低的计算复杂度下提供了类似的测试精度。

## 练习

1. GoogLeNet有好几个版本。尝试实现并运行它们。其中一些包括以下内容:
1. 添加批处理归一化层[Ioffe & Szegedy, 2015]，如7.5节稍后所述。
1. 对盗梦空间区块进行调整[Szegedy等人，2016]。
1. 使用“标签平滑”对模型进行正则化[Szegedy等人，2016]。
1. 将其包括在剩余连接中[Szegedy等人，2017]，如第7.6节稍后所述。
1. GoogLeNet的最小图像尺寸是多少?
1. 比较AlexNet、VGG、NiN和GoogLeNet的模型参数大小。后两种网络架构如何显著减少模型参数的大小?1. 为什么一开始我们需要大范围的卷积?
